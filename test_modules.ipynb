{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea126987-59aa-4f76-b926-6d632887c30b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# This notebook is designed for teaching/testing purposes to help you visualize the tensor shapes that go through each module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f833b1f8-ea91-4ae5-b3a3-73e08e4c8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you prolly won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c2c04f-2dbd-4020-8d91-cc0e4e8511b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConfig(dim=4, device='mps', linear_bias=False, out_weight_share=True, max_seq_len=7, pos_enc_type='RoPE', theta=10000, tokenizer='bpe_tinyStories', vocab_len=2048, num_layers=2, second_resid_norm=False, mlp_hidden_mult=2, mlp_nonlinearity='SiLU', mlp_gated=True, num_q_heads=2, num_kv_heads=1, head_dim=2, scale_first_resid=True, norm_type='RMSNorm', norm_affine=True, norm_bias=True, eps=1e-06)\n",
      "TrainConfig(model_name='2024-09-21|18-14-17', dataset_name='noanabeshima/TinyStoriesV2', data_subset=None, streaming=True, micro_batch_size=3, grad_accum_steps=2, max_iters=20, eval_interval=2, eval_samples=1, checkpoint_interval=None, beta1=0.9, beta2=0.95, epsilon=1e-08, weight_decay=0.05, grad_clip=1.0, lr_init=1e-06, lr_max=0.01, lr_min=0.0001, warmup_iters=2, final_flat_iters=1, anneal_type='cos', num_restarts=0, T_mult=2)\n"
     ]
    }
   ],
   "source": [
    "# config file\n",
    "from config import ModelConfig, TrainConfig\n",
    "cfg = ModelConfig()\n",
    "tcfg = TrainConfig()\n",
    "print(cfg)\n",
    "print(tcfg)\n",
    "\n",
    "# import the tokenizer specified by cfg\n",
    "from tools import import_from_nested_path\n",
    "imported_objects = import_from_nested_path(['tokenizers', cfg.tokenizer], 'tokenizer', ['get_tokenizer'])\n",
    "get_tokenizer = imported_objects.get('get_tokenizer')\n",
    "tokenizer = get_tokenizer(size = 512) # assuming 'bpe_tinyStories', size options are 512, 1024 and 2048\n",
    "\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c12e3b-dc63-4479-ad55-b05d96364d1f",
   "metadata": {},
   "source": [
    "# Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3debc7b1-a7ec-4fb3-98cb-d16edf7c71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.norm import Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "627969e9-9017-43f3-90ec-9a485abef26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.01K\n",
      "Norm()\n",
      "\n",
      "====================Entering Norm.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.561/2.554\n",
      "\n",
      "====================Entering Norm.RMSNorm====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.561/2.554\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.869/1.779\n",
      "====================Exiting Norm.RMSNorm====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.869/1.779\n",
      "====================Exiting Norm.forward====================\n",
      "CPU times: user 67.9 ms, sys: 89.4 ms, total: 157 ms\n",
      "Wall time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### RMSNorm\n",
    "\n",
    "# Create an instance of RMSNorm\n",
    "module = Norm(cfg.dim, 'RMSNorm').to(cfg.device)\n",
    "\n",
    "# let's take a look\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "\n",
    "# Initially, logging is disabled by default\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('CosineNorm')\n",
    "#module.disable_function_logging('LayerNorm')\n",
    "#module.disable_function_logging('RMSNorm')\n",
    "\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(x)\n",
    "\n",
    "# Disable logging. \n",
    "# This isn't actually necessary since we won't be using this object again but that's how you'd do it\n",
    "module.disable_logging()\n",
    "\n",
    "# clearing up ram jic we're training later\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64020a96-205a-45b7-ae56-a3555d2b3719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================Entering Norm.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.527/2.251\n",
      "Full tensor content:\n",
      "tensor([[[-0.5230, -0.9381,  0.2263,  0.3828],\n",
      "         [-0.0262, -1.1933,  0.5411,  0.0104],\n",
      "         [ 0.3228, -0.1952, -0.0802, -0.5512],\n",
      "         [-0.8007,  1.1186,  0.0894, -0.4256],\n",
      "         [ 0.2103,  1.4038,  0.5134, -1.2763],\n",
      "         [-0.3193,  0.8299, -1.4546,  0.3746],\n",
      "         [ 0.3534,  0.5855, -1.6108, -0.2388]],\n",
      "\n",
      "        [[ 0.0135, -1.2019, -0.0754,  1.0510],\n",
      "         [-1.0081,  1.4370,  1.4895,  0.1814],\n",
      "         [ 1.4942,  0.1192, -0.7754, -0.1897],\n",
      "         [ 1.8967, -0.5758,  0.1719,  1.6467],\n",
      "         [-0.2362,  0.8676,  1.0817, -1.0754],\n",
      "         [ 0.3650, -0.1457, -0.8078,  0.2125],\n",
      "         [-0.2432, -0.8513, -0.8021,  0.8021]],\n",
      "\n",
      "        [[ 0.0959, -0.0041,  1.6662, -0.0043],\n",
      "         [ 0.4034, -0.7618,  0.4126,  0.2836],\n",
      "         [-1.6668, -1.8566, -0.2972, -0.5777],\n",
      "         [ 1.2674, -0.0179, -0.1527, -0.0807],\n",
      "         [ 0.4712,  1.1951,  0.1424,  0.2783],\n",
      "         [ 2.2512,  0.1260, -2.5267, -0.3967],\n",
      "         [-1.9328, -0.4773, -0.6821,  1.1181]]], device='mps:0')\n",
      "\n",
      "====================Entering Norm.LayerNorm====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.527/2.251\n",
      "Full tensor content:\n",
      "tensor([[[-0.5230, -0.9381,  0.2263,  0.3828],\n",
      "         [-0.0262, -1.1933,  0.5411,  0.0104],\n",
      "         [ 0.3228, -0.1952, -0.0802, -0.5512],\n",
      "         [-0.8007,  1.1186,  0.0894, -0.4256],\n",
      "         [ 0.2103,  1.4038,  0.5134, -1.2763],\n",
      "         [-0.3193,  0.8299, -1.4546,  0.3746],\n",
      "         [ 0.3534,  0.5855, -1.6108, -0.2388]],\n",
      "\n",
      "        [[ 0.0135, -1.2019, -0.0754,  1.0510],\n",
      "         [-1.0081,  1.4370,  1.4895,  0.1814],\n",
      "         [ 1.4942,  0.1192, -0.7754, -0.1897],\n",
      "         [ 1.8967, -0.5758,  0.1719,  1.6467],\n",
      "         [-0.2362,  0.8676,  1.0817, -1.0754],\n",
      "         [ 0.3650, -0.1457, -0.8078,  0.2125],\n",
      "         [-0.2432, -0.8513, -0.8021,  0.8021]],\n",
      "\n",
      "        [[ 0.0959, -0.0041,  1.6662, -0.0043],\n",
      "         [ 0.4034, -0.7618,  0.4126,  0.2836],\n",
      "         [-1.6668, -1.8566, -0.2972, -0.5777],\n",
      "         [ 1.2674, -0.0179, -0.1527, -0.0807],\n",
      "         [ 0.4712,  1.1951,  0.1424,  0.2783],\n",
      "         [ 2.2512,  0.1260, -2.5267, -0.3967],\n",
      "         [-1.9328, -0.4773, -0.6821,  1.1181]]], device='mps:0')\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.723/1.729\n",
      "Full tensor content:\n",
      "tensor([[[-0.5732, -1.3408,  0.8124,  1.1016],\n",
      "         [ 0.2221, -1.6197,  1.1176,  0.2799],\n",
      "         [ 1.4389, -0.2221,  0.1466, -1.3634],\n",
      "         [-1.1036,  1.5570,  0.1303, -0.5837],\n",
      "         [-0.0026,  1.2339,  0.3115, -1.5428],\n",
      "         [-0.2055,  1.1291, -1.5240,  0.6004],\n",
      "         [ 0.6810,  0.9531, -1.6210, -0.0131]],\n",
      "\n",
      "        [[ 0.0836, -1.4405, -0.0278,  1.3847],\n",
      "         [-1.4907,  0.8869,  0.9379, -0.3341],\n",
      "         [ 1.5982, -0.0515, -1.1247, -0.4221],\n",
      "         [ 1.0842, -1.3269, -0.5978,  0.8405],\n",
      "         [-0.4543,  0.8132,  1.0591, -1.4180],\n",
      "         [ 1.0157, -0.1143, -1.5796,  0.6782],\n",
      "         [ 0.0458, -0.8682, -0.7942,  1.6166]],\n",
      "\n",
      "        [[-0.4824, -0.6232,  1.7292, -0.6235],\n",
      "         [ 0.6494, -1.7227,  0.6679,  0.4054],\n",
      "         [-0.8430, -1.1251,  1.1925,  0.7755],\n",
      "         [ 1.7263, -0.4633, -0.6929, -0.5701],\n",
      "         [-0.1245,  1.6588, -0.9345, -0.5997],\n",
      "         [ 1.4051,  0.1545, -1.4065, -0.1531],\n",
      "         [-1.3271,  0.0150, -0.1739,  1.4860]]], device='mps:0')\n",
      "====================Exiting Norm.LayerNorm====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.723/1.729\n",
      "Full tensor content:\n",
      "tensor([[[-0.5732, -1.3408,  0.8124,  1.1016],\n",
      "         [ 0.2221, -1.6197,  1.1176,  0.2799],\n",
      "         [ 1.4389, -0.2221,  0.1466, -1.3634],\n",
      "         [-1.1036,  1.5570,  0.1303, -0.5837],\n",
      "         [-0.0026,  1.2339,  0.3115, -1.5428],\n",
      "         [-0.2055,  1.1291, -1.5240,  0.6004],\n",
      "         [ 0.6810,  0.9531, -1.6210, -0.0131]],\n",
      "\n",
      "        [[ 0.0836, -1.4405, -0.0278,  1.3847],\n",
      "         [-1.4907,  0.8869,  0.9379, -0.3341],\n",
      "         [ 1.5982, -0.0515, -1.1247, -0.4221],\n",
      "         [ 1.0842, -1.3269, -0.5978,  0.8405],\n",
      "         [-0.4543,  0.8132,  1.0591, -1.4180],\n",
      "         [ 1.0157, -0.1143, -1.5796,  0.6782],\n",
      "         [ 0.0458, -0.8682, -0.7942,  1.6166]],\n",
      "\n",
      "        [[-0.4824, -0.6232,  1.7292, -0.6235],\n",
      "         [ 0.6494, -1.7227,  0.6679,  0.4054],\n",
      "         [-0.8430, -1.1251,  1.1925,  0.7755],\n",
      "         [ 1.7263, -0.4633, -0.6929, -0.5701],\n",
      "         [-0.1245,  1.6588, -0.9345, -0.5997],\n",
      "         [ 1.4051,  0.1545, -1.4065, -0.1531],\n",
      "         [-1.3271,  0.0150, -0.1739,  1.4860]]], device='mps:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "====================Exiting Norm.forward====================\n",
      "CPU times: user 104 ms, sys: 39.7 ms, total: 144 ms\n",
      "Wall time: 244 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# LayerNorm\n",
    "module = Norm(cfg.dim, 'LayerNorm').to(cfg.device)\n",
    "module.enable_logging()\n",
    "\n",
    "# you can also have it optionally print out all tensors in full\n",
    "module.enable_full_tensor_printing()\n",
    "# i recommend only doing this with very small toy values for your hyperparameters, otherwise this gets too big\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('CosineNorm')\n",
    "#module.disable_function_logging('LayerNorm')\n",
    "#module.disable_function_logging('RMSNorm')\n",
    "\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "output = module(x)\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e190f3de-37fd-442b-bfb1-6a090115fc75",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a89e1e8f-cedd-4885-ad50-934827ed045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.attention import SelfAttention, PrecomputeRotaryFrequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d71c1-288f-4859-8a88-8063c9b16b5e",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e8f27b4-6d1f-4fcd-99b0-2284e65d6b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.05K\n",
      "SelfAttention(\n",
      "  (Wq): Linear(in_features=4, out_features=4, bias=False)\n",
      "  (Wk): Linear(in_features=4, out_features=2, bias=False)\n",
      "  (Wv): Linear(in_features=4, out_features=2, bias=False)\n",
      "  (Wo): Linear(in_features=4, out_features=4, bias=False)\n",
      ")\n",
      "\n",
      "====================Entering SelfAttention.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.444/2.281\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Other-type 'kv_cache': Type=NoneType, Value=None\n",
      "Bool 'training': Value=True\n",
      "\n",
      "====================Entering SelfAttention.apply_rotary_pos_emb====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.657/1.310\n",
      "Tensor 'k' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.975/0.601\n",
      "Tensor 'sin' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'cos' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.657/1.310\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.310/1.657\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.975/0.601\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.811/0.975\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.489/0.991\n",
      "Tensor 'output[1]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.795/0.803\n",
      "====================Exiting SelfAttention.apply_rotary_pos_emb====================\n",
      "\n",
      "====================Entering SelfAttention.match_headcount====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.795/0.803\n",
      "Tensor 'v' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.822/1.069\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.795/0.803\n",
      "Tensor 'output[1]' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.822/1.069\n",
      "====================Exiting SelfAttention.match_headcount====================\n",
      "\n",
      "====================Entering SelfAttention.flash_attention====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 2, 7, 2]), dtype: torch.float32, device: mps:0, min/max: -1.489/0.991\n",
      "Tensor 'k' shape: torch.Size([3, 2, 7, 2]), dtype: torch.float32, device: mps:0, min/max: -0.795/0.803\n",
      "Tensor 'v' shape: torch.Size([3, 2, 7, 2]), dtype: torch.float32, device: mps:0, min/max: -0.822/1.069\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 2, 7, 2]), dtype: torch.float32, device: mps:0, min/max: -0.583/0.525\n",
      "====================Exiting SelfAttention.flash_attention====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.587/0.546\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "====================Exiting SelfAttention.forward====================\n",
      "CPU times: user 202 ms, sys: 33.7 ms, total: 235 ms\n",
      "Wall time: 273 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# first up let's look at training\n",
    "\n",
    "# Create an instance of multi-head self-attention\n",
    "module = SelfAttention(cfg.dim, cfg.head_dim, cfg.num_q_heads, cfg.num_kv_heads, cfg.max_seq_len, cfg.linear_bias, device=cfg.device)\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "\n",
    "# Initially, logging is disabled by default\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('splice_specific_frequencies')\n",
    "#module.disable_function_logging('apply_rotary_pos_emb')\n",
    "#module.disable_function_logging('rotate_half')\n",
    "#module.disable_function_logging('implement_kv_caching')\n",
    "#module.disable_function_logging('update_kv_cache')\n",
    "#module.disable_function_logging('use_kv_cache')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('flash_attention')\n",
    "#module.disable_function_logging('regular_attention')\n",
    "#module.disable_function_logging('adjust_inference_mask')\n",
    "#module.disable_function_logging('project_values')\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "if cfg.pos_enc_type == 'RoPE':\n",
    "    precompute_freqs = PrecomputeRotaryFrequencies(cfg.head_dim, cfg.max_seq_len, cfg.theta, cfg.device)\n",
    "    freqs = precompute_freqs()\n",
    "else:\n",
    "    precompute_freqs = None\n",
    "    freqs = None\n",
    "mask = torch.ones(cfg.max_seq_len, cfg.max_seq_len, dtype=torch.bool, device=cfg.device).tril()\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(x, freqs, mask, training=True)\n",
    "\n",
    "# clearing up ram jic we're training later\n",
    "del module, precompute_freqs, freqs, mask, x, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82707fa2-4af3-4a71-a664-80fdbe82c919",
   "metadata": {},
   "source": [
    "## inference \n",
    "full kv-caching process with variable sequence length initial prompts in batch and then single-vector auto-regressive inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e23306f-de70-448a-80f9-75c200a804ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask:\n",
      " tensor([[ True, False, False],\n",
      "        [ True,  True, False],\n",
      "        [ True,  True,  True]], device='mps:0')\n",
      "cache_len:\n",
      " tensor([1, 2, 3], device='mps:0') torch.Size([3])\n",
      "\n",
      "====================Entering SelfAttention.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -2.958/1.779\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 1.000/3.000\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "Bool 'training': Value=False\n",
      "\n",
      "====================Entering SelfAttention.splice_specific_frequencies====================\n",
      "Inputs:\n",
      "Integer 'seq_len': Value=3\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Integer 'batch_size': Value=3\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 1.000/3.000\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([1, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.909\n",
      "Tensor 'output[1]' shape: torch.Size([1, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.416/1.000\n",
      "====================Exiting SelfAttention.splice_specific_frequencies====================\n",
      "\n",
      "====================Entering SelfAttention.apply_rotary_pos_emb====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.974/1.110\n",
      "Tensor 'k' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.173/0.995\n",
      "Tensor 'sin' shape: torch.Size([1, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.909\n",
      "Tensor 'cos' shape: torch.Size([1, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.416/1.000\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.974/1.110\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.974/1.110\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.173/0.995\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.173/0.670\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -2.224/0.919\n",
      "Tensor 'output[1]' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.183/0.580\n",
      "====================Exiting SelfAttention.apply_rotary_pos_emb====================\n",
      "\n",
      "====================Entering SelfAttention.implement_kv_caching====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.183/0.580\n",
      "Tensor 'v' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.609/1.193\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 1.000/3.000\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "\n",
      "====================Entering SelfAttention.update_kv_cache====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.183/0.580\n",
      "Tensor 'v' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.609/1.193\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 1.000/3.000\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'max_new_tokens' shape: torch.Size([]), dtype: torch.int64, device: mps:0, min/max: 3.000/3.000\n",
      "\n",
      "Outputs:\n",
      "Dict 'output':\n",
      "    Tensor 'output[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'output[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.update_kv_cache====================\n",
      "\n",
      "====================Entering SelfAttention.use_kv_cache====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.183/0.580\n",
      "Tensor 'v' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.609/1.193\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Tensor 'max_new_tokens' shape: torch.Size([]), dtype: torch.int64, device: mps:0, min/max: 3.000/3.000\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'output[1]' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.use_kv_cache====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'output[1]' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Dict 'output[2]':\n",
      "    Tensor 'output[2][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'output[2][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.implement_kv_caching====================\n",
      "\n",
      "====================Entering SelfAttention.match_headcount====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'v' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'output[1]' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.match_headcount====================\n",
      "\n",
      "====================Entering SelfAttention.flash_attention====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 2, 3, 2]), dtype: torch.float32, device: mps:0, min/max: -2.224/0.919\n",
      "Tensor 'k' shape: torch.Size([3, 2, 3, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'v' shape: torch.Size([3, 2, 3, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=False\n",
      "\n",
      "====================Entering SelfAttention.adjust_inference_mask====================\n",
      "Inputs:\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Integer 'num_heads': Value=2\n",
      "Integer 'q_seq_len': Value=3\n",
      "Integer 'k_seq_len': Value=3\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 2, 3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "====================Exiting SelfAttention.adjust_inference_mask====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 2, 3, 2]), dtype: torch.float32, device: mps:0, min/max: -0.039/0.691\n",
      "====================Exiting SelfAttention.flash_attention====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -0.291/0.239\n",
      "Dict 'output[1]':\n",
      "    Tensor 'output[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'output[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.forward====================\n",
      "mask:\n",
      " tensor([[ True,  True, False, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [ True,  True,  True,  True]], device='mps:0')\n",
      "cache_len:\n",
      " tensor([2, 3, 4], device='mps:0') torch.Size([3])\n",
      "\n",
      "====================Entering SelfAttention.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -0.245/0.202\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 4]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 2.000/4.000\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Bool 'training': Value=False\n",
      "\n",
      "====================Entering SelfAttention.splice_specific_frequencies====================\n",
      "Inputs:\n",
      "Integer 'seq_len': Value=1\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Integer 'batch_size': Value=3\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 2.000/4.000\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.141/0.909\n",
      "Tensor 'output[1]' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/0.540\n",
      "====================Exiting SelfAttention.splice_specific_frequencies====================\n",
      "\n",
      "====================Entering SelfAttention.apply_rotary_pos_emb====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 1, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.095/0.206\n",
      "Tensor 'k' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.061/0.141\n",
      "Tensor 'sin' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.141/0.909\n",
      "Tensor 'cos' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/0.540\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.095/0.206\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 1, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.108/0.206\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.061/0.141\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.070/0.141\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.215/0.168\n",
      "Tensor 'output[1]' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.107/0.128\n",
      "====================Exiting SelfAttention.apply_rotary_pos_emb====================\n",
      "\n",
      "====================Entering SelfAttention.implement_kv_caching====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.107/0.128\n",
      "Tensor 'v' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.067/0.096\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 2.000/4.000\n",
      "Tensor 'mask' shape: torch.Size([3, 4]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "\n",
      "====================Entering SelfAttention.update_kv_cache====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.107/0.128\n",
      "Tensor 'v' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.067/0.096\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 2.000/4.000\n",
      "Tensor 'mask' shape: torch.Size([3, 4]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'max_new_tokens' shape: torch.Size([]), dtype: torch.int64, device: mps:0, min/max: 4.000/4.000\n",
      "\n",
      "Outputs:\n",
      "Dict 'output':\n",
      "    Tensor 'output[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'output[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.update_kv_cache====================\n",
      "\n",
      "====================Entering SelfAttention.use_kv_cache====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.107/0.128\n",
      "Tensor 'v' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.067/0.096\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Tensor 'max_new_tokens' shape: torch.Size([]), dtype: torch.int64, device: mps:0, min/max: 4.000/4.000\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 4, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'output[1]' shape: torch.Size([3, 4, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.use_kv_cache====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 4, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'output[1]' shape: torch.Size([3, 4, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Dict 'output[2]':\n",
      "    Tensor 'output[2][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'output[2][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.implement_kv_caching====================\n",
      "\n",
      "====================Entering SelfAttention.match_headcount====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 4, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'v' shape: torch.Size([3, 4, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 4, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'output[1]' shape: torch.Size([3, 4, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.match_headcount====================\n",
      "\n",
      "====================Entering SelfAttention.flash_attention====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 2, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.215/0.168\n",
      "Tensor 'k' shape: torch.Size([3, 2, 4, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'v' shape: torch.Size([3, 2, 4, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Tensor 'mask' shape: torch.Size([3, 4]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=False\n",
      "\n",
      "====================Entering SelfAttention.adjust_inference_mask====================\n",
      "Inputs:\n",
      "Tensor 'mask' shape: torch.Size([3, 4]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Integer 'num_heads': Value=2\n",
      "Integer 'q_seq_len': Value=1\n",
      "Integer 'k_seq_len': Value=4\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 2, 1, 4]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "====================Exiting SelfAttention.adjust_inference_mask====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 2, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.067/0.384\n",
      "====================Exiting SelfAttention.flash_attention====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -0.147/0.106\n",
      "Dict 'output[1]':\n",
      "    Tensor 'output[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'output[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.forward====================\n",
      "mask:\n",
      " tensor([[ True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True]], device='mps:0')\n",
      "cache_len:\n",
      " tensor([3, 4, 5], device='mps:0') torch.Size([3])\n",
      "\n",
      "====================Entering SelfAttention.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -0.147/0.106\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 5]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 3.000/5.000\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Bool 'training': Value=False\n",
      "\n",
      "====================Entering SelfAttention.splice_specific_frequencies====================\n",
      "Inputs:\n",
      "Integer 'seq_len': Value=1\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Integer 'batch_size': Value=3\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 3.000/5.000\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.757/0.909\n",
      "Tensor 'output[1]' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/-0.416\n",
      "====================Exiting SelfAttention.splice_specific_frequencies====================\n",
      "\n",
      "====================Entering SelfAttention.apply_rotary_pos_emb====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 1, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.034/0.142\n",
      "Tensor 'k' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.039/0.073\n",
      "Tensor 'sin' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.757/0.909\n",
      "Tensor 'cos' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/-0.416\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.034/0.142\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 1, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.064/0.142\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.039/0.073\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.034/0.073\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.148/0.034\n",
      "Tensor 'output[1]' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.052/0.082\n",
      "====================Exiting SelfAttention.apply_rotary_pos_emb====================\n",
      "\n",
      "====================Entering SelfAttention.implement_kv_caching====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.052/0.082\n",
      "Tensor 'v' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.039/0.063\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 3.000/5.000\n",
      "Tensor 'mask' shape: torch.Size([3, 5]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "\n",
      "====================Entering SelfAttention.update_kv_cache====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.052/0.082\n",
      "Tensor 'v' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.039/0.063\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 3.000/5.000\n",
      "Tensor 'mask' shape: torch.Size([3, 5]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'max_new_tokens' shape: torch.Size([]), dtype: torch.int64, device: mps:0, min/max: 5.000/5.000\n",
      "\n",
      "Outputs:\n",
      "Dict 'output':\n",
      "    Tensor 'output[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'output[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.update_kv_cache====================\n",
      "\n",
      "====================Entering SelfAttention.use_kv_cache====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.052/0.082\n",
      "Tensor 'v' shape: torch.Size([3, 1, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.039/0.063\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Tensor 'max_new_tokens' shape: torch.Size([]), dtype: torch.int64, device: mps:0, min/max: 5.000/5.000\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 5, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'output[1]' shape: torch.Size([3, 5, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.use_kv_cache====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 5, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'output[1]' shape: torch.Size([3, 5, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Dict 'output[2]':\n",
      "    Tensor 'output[2][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'output[2][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.implement_kv_caching====================\n",
      "\n",
      "====================Entering SelfAttention.match_headcount====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 5, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'v' shape: torch.Size([3, 5, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 5, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'output[1]' shape: torch.Size([3, 5, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.match_headcount====================\n",
      "\n",
      "====================Entering SelfAttention.flash_attention====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 2, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.148/0.034\n",
      "Tensor 'k' shape: torch.Size([3, 2, 5, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "Tensor 'v' shape: torch.Size([3, 2, 5, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "Tensor 'mask' shape: torch.Size([3, 5]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=False\n",
      "\n",
      "====================Entering SelfAttention.adjust_inference_mask====================\n",
      "Inputs:\n",
      "Tensor 'mask' shape: torch.Size([3, 5]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Integer 'num_heads': Value=2\n",
      "Integer 'q_seq_len': Value=1\n",
      "Integer 'k_seq_len': Value=5\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 2, 1, 5]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "====================Exiting SelfAttention.adjust_inference_mask====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 2, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.067/0.305\n",
      "====================Exiting SelfAttention.flash_attention====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -0.104/0.091\n",
      "Dict 'output[1]':\n",
      "    Tensor 'output[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.135/0.580\n",
      "    Tensor 'output[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.525/1.193\n",
      "====================Exiting SelfAttention.forward====================\n",
      "tensor([[[ 0.0104,  0.0126, -0.0277,  0.0670]],\n",
      "\n",
      "        [[-0.1043,  0.0676, -0.0940,  0.0623]],\n",
      "\n",
      "        [[-0.0479,  0.0423, -0.0689,  0.0907]]], device='mps:0',\n",
      "       grad_fn=<LinearBackward0>)\n",
      "CPU times: user 436 ms, sys: 74.2 ms, total: 510 ms\n",
      "Wall time: 637 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# now let's do it for INFERENCE with the full kv-caching process \n",
    "    # meaning initial variable length prompts AND successive auto-regressive single-token input\n",
    "# here we'll be pretending we're using a model where every single layer is just self-attention, no MLP or residual connection\n",
    "\n",
    "module = SelfAttention(cfg.dim, cfg.head_dim, cfg.num_q_heads, cfg.num_kv_heads, cfg.max_seq_len, cfg.linear_bias, device=cfg.device)\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('splice_specific_frequencies')\n",
    "#module.disable_function_logging('apply_rotary_pos_emb')\n",
    "#module.disable_function_logging('rotate_half')\n",
    "#module.disable_function_logging('implement_kv_caching')\n",
    "#module.disable_function_logging('update_kv_cache')\n",
    "#module.disable_function_logging('use_kv_cache')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('flash_attention')\n",
    "#module.disable_function_logging('regular_attention')\n",
    "#module.disable_function_logging('adjust_inference_mask')\n",
    "#module.disable_function_logging('project_values')\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "# so half the max_seq_len will be the length of our longest prompt in batched inference that needs to be cached\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len // 2,cfg.dim).to(cfg.device) \n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "if cfg.pos_enc_type == 'RoPE':\n",
    "    precompute_freqs = PrecomputeRotaryFrequencies(cfg.head_dim, cfg.max_seq_len, cfg.theta, cfg.device)\n",
    "    freqs = precompute_freqs()\n",
    "else:\n",
    "    precompute_freqs = None\n",
    "    freqs = None\n",
    "    \n",
    "# setting up for kv caching\n",
    "kv_cache = {\n",
    "    'k': torch.zeros((tcfg.micro_batch_size, cfg.max_seq_len, cfg.num_kv_heads, cfg.head_dim), device=cfg.device),\n",
    "    'v': torch.zeros((tcfg.micro_batch_size, cfg.max_seq_len, cfg.num_kv_heads, cfg.head_dim), device=cfg.device)\n",
    "}\n",
    "\n",
    "# mask ignores padding tokens and accounts for variable sequence lengths\n",
    "mask = torch.ones(tcfg.micro_batch_size, cfg.max_seq_len // 2).to(cfg.device).bool() # (True for real tokens, False for padding)\n",
    "# we'll simulate a mask setup for different-length input prompts\n",
    "for s in range(mask.shape[0] - 1): # -1 leaves the last row as the full longest prompt length\n",
    "    r = random.randint(1, cfg.max_seq_len // 2-1)\n",
    "    mask[s, -r:] = False\n",
    "print('mask:\\n', mask)\n",
    "\n",
    "cache_len = mask.sum(1).to(cfg.device).long()\n",
    "print('cache_len:\\n', cache_len, cache_len.shape)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output, kv_cache = module(x, freqs, mask, cache_len, kv_cache)\n",
    "\n",
    "input = output[:,-1:,:]\n",
    "for _ in range(2): # we'll do it twice\n",
    "    mask = torch.nn.functional.pad(mask, (1, 0, 0, 0), value=True)\n",
    "    cache_len += 1\n",
    "    print('mask:\\n', mask)\n",
    "    print('cache_len:\\n', cache_len, cache_len.shape)\n",
    "\n",
    "    output, kv_cache = module(input, freqs, mask, cache_len, kv_cache)\n",
    "    input = output\n",
    "\n",
    "print(output)\n",
    "    \n",
    "# clearing up ram jic we're training later\n",
    "del module, x, precompute_freqs, freqs, kv_cache, mask, cache_len, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb308c5-b578-46f2-86ae-bfa6800be641",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7736b685-f941-4182-a5b7-4731cce706b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c62e49e9-2189-4269-968e-1df99469dc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.06K\n",
      "MLP(\n",
      "  (Wup): Linear(in_features=4, out_features=5, bias=False)\n",
      "  (Wgate): Linear(in_features=4, out_features=5, bias=False)\n",
      "  (Wdown): Linear(in_features=5, out_features=4, bias=False)\n",
      "  (nonlinearity): GELU(approximate='none')\n",
      ")\n",
      "\n",
      "====================Entering MLP.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.376/2.221\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.268/0.310\n",
      "====================Exiting MLP.forward====================\n",
      "CPU times: user 28.2 ms, sys: 4.64 ms, total: 32.8 ms\n",
      "Wall time: 37.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# GeGLU\n",
    "module = MLP(\n",
    "    cfg.dim, \n",
    "    int(cfg.dim * cfg.mlp_hidden_mult * 2/3), \n",
    "    cfg.dim, \n",
    "    'GeLU', \n",
    "    gated=True, \n",
    "    bias=cfg.linear_bias, \n",
    "    dropout_rate = 0.1\n",
    ").to(cfg.device)\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "module.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "output = module(x, training=True)\n",
    "module.disable_logging()\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0748fa3-3230-4dd7-a768-1256ea72e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.08K\n",
      "MLP(\n",
      "  (Wup): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (Wdown): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (nonlinearity): ReLU()\n",
      ")\n",
      "\n",
      "====================Entering MLP.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.692/2.495\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.732/1.236\n",
      "====================Exiting MLP.forward====================\n",
      "CPU times: user 27.6 ms, sys: 4.46 ms, total: 32 ms\n",
      "Wall time: 34.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# not gated and testing a different nonlinearity\n",
    "module = MLP(\n",
    "    cfg.dim, \n",
    "    cfg.dim * cfg.mlp_hidden_mult, \n",
    "    cfg.dim, \n",
    "    'ReLU', \n",
    "    gated=False, \n",
    "    bias=True, \n",
    "    dropout_rate = 0.1\n",
    ").to(cfg.device)\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "module.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "output = module(x, training=True)\n",
    "module.disable_logging()\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a502f-4646-4a02-9412-372482af9fa0",
   "metadata": {},
   "source": [
    "# ResidualLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a21d708-af47-4f32-b111-08efedc584f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.layer import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40995e1a-20d7-445e-9db9-2192cefbe502",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c886661d-5a26-4787-93d1-c3c8c6b1c02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.12K\n",
      "Layer(\n",
      "  (pre_attn_norm): Norm()\n",
      "  (attn): SelfAttention(\n",
      "    (Wq): Linear(in_features=4, out_features=4, bias=False)\n",
      "    (Wk): Linear(in_features=4, out_features=2, bias=False)\n",
      "    (Wv): Linear(in_features=4, out_features=2, bias=False)\n",
      "    (Wo): Linear(in_features=4, out_features=4, bias=False)\n",
      "  )\n",
      "  (pre_mlp_norm): Norm()\n",
      "  (mlp): MLP(\n",
      "    (Wup): Linear(in_features=4, out_features=5, bias=False)\n",
      "    (Wgate): Linear(in_features=4, out_features=5, bias=False)\n",
      "    (Wdown): Linear(in_features=5, out_features=4, bias=False)\n",
      "    (nonlinearity): SiLU()\n",
      "  )\n",
      ")\n",
      "tensor([[ True, False, False, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True]], device='mps:0')\n",
      "\n",
      "====================Entering Layer.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.052/2.422\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Other-type 'kv_cache': Type=NoneType, Value=None\n",
      "Bool 'training': Value=True\n",
      "\n",
      "====================Entering Layer.attn_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.052/2.422\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Other-type 'kv_cache': Type=NoneType, Value=None\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.215/0.706\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "====================Exiting Layer.attn_connect====================\n",
      "\n",
      "====================Entering Layer.mlp_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.461/2.392\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.359/0.181\n",
      "====================Exiting Layer.mlp_connect====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.467/2.372\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "====================Exiting Layer.forward====================\n",
      "CPU times: user 28.3 ms, sys: 8.63 ms, total: 36.9 ms\n",
      "Wall time: 52.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TRAINING\n",
    "module = Layer(cfg).to(cfg.device)\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "### Optionally disabling printing for sub-modules\n",
    "#module.disable_function_logging('attn_connect')\n",
    "#module.disable_function_logging('mlp_connect')\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.pre_attn_norm.enable_logging()\n",
    "#module.attn.enable_logging()\n",
    "#module.post_attn_norm.enable_logging()\n",
    "#module.pre_mlp_norm.enable_logging()\n",
    "#module.mlp.enable_logging()\n",
    "#module.post_mlp_norm.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "if cfg.pos_enc_type == 'RoPE':\n",
    "    precompute_freqs = PrecomputeRotaryFrequencies(cfg.head_dim, cfg.max_seq_len, cfg.theta, cfg.device)\n",
    "    freqs = precompute_freqs()\n",
    "else:\n",
    "    precompute_freqs = None\n",
    "    freqs = None\n",
    "mask = torch.ones(cfg.max_seq_len, cfg.max_seq_len, dtype=torch.bool, device=cfg.device).tril()\n",
    "print(mask)\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "output = module(x, freqs, mask, training=True)\n",
    "module.disable_logging()\n",
    "del module,freqs, mask, x, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dd91d-a84c-43a3-8dd7-34f43b0a7c9a",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f534ab4-a150-42db-8c89-5e8d3d0c06a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.12K\n",
      "Layer(\n",
      "  (pre_attn_norm): Norm()\n",
      "  (attn): SelfAttention(\n",
      "    (Wq): Linear(in_features=4, out_features=4, bias=False)\n",
      "    (Wk): Linear(in_features=4, out_features=2, bias=False)\n",
      "    (Wv): Linear(in_features=4, out_features=2, bias=False)\n",
      "    (Wo): Linear(in_features=4, out_features=4, bias=False)\n",
      "  )\n",
      "  (pre_mlp_norm): Norm()\n",
      "  (mlp): MLP(\n",
      "    (Wup): Linear(in_features=4, out_features=5, bias=False)\n",
      "    (Wgate): Linear(in_features=4, out_features=5, bias=False)\n",
      "    (Wdown): Linear(in_features=5, out_features=4, bias=False)\n",
      "    (nonlinearity): SiLU()\n",
      "  )\n",
      ")\n",
      "mask:\n",
      " tensor([[ True,  True, False],\n",
      "        [ True,  True, False],\n",
      "        [ True,  True,  True]], device='mps:0')\n",
      "cache_len:\n",
      " tensor([2, 2, 3], device='mps:0') torch.Size([3])\n",
      "\n",
      "====================Entering Layer.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -1.424/2.057\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 2.000/3.000\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "Bool 'training': Value=False\n",
      "\n",
      "====================Entering Layer.attn_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -1.424/2.057\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 2.000/3.000\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "Bool 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -0.206/0.822\n",
      "Dict 'output[1]':\n",
      "    Tensor 'output[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.831/0.654\n",
      "    Tensor 'output[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.137/0.342\n",
      "====================Exiting Layer.attn_connect====================\n",
      "\n",
      "====================Entering Layer.mlp_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -0.878/2.121\n",
      "Bool 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -0.234/0.096\n",
      "====================Exiting Layer.mlp_connect====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -1.072/2.216\n",
      "Dict 'output[1]':\n",
      "    Tensor 'output[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.831/0.654\n",
      "    Tensor 'output[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.137/0.342\n",
      "====================Exiting Layer.forward====================\n",
      "mask:\n",
      " tensor([[ True,  True,  True, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [ True,  True,  True,  True]], device='mps:0')\n",
      "cache_len:\n",
      " tensor([3, 3, 4], device='mps:0') torch.Size([3])\n",
      "\n",
      "====================Entering Layer.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -1.072/1.115\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 4]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 3.000/4.000\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.831/0.654\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.137/0.342\n",
      "Bool 'training': Value=False\n",
      "\n",
      "====================Entering Layer.attn_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -1.072/1.115\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 4]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 3.000/4.000\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.831/0.654\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.137/0.342\n",
      "Bool 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -0.308/0.539\n",
      "Dict 'output[1]':\n",
      "    Tensor 'output[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.219/0.778\n",
      "    Tensor 'output[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.137/0.932\n",
      "====================Exiting Layer.attn_connect====================\n",
      "\n",
      "====================Entering Layer.mlp_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -0.938/0.969\n",
      "Bool 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -0.260/0.020\n",
      "====================Exiting Layer.mlp_connect====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -1.198/0.989\n",
      "Dict 'output[1]':\n",
      "    Tensor 'output[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.219/0.778\n",
      "    Tensor 'output[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.137/0.932\n",
      "====================Exiting Layer.forward====================\n",
      "mask:\n",
      " tensor([[ True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True]], device='mps:0')\n",
      "cache_len:\n",
      " tensor([4, 4, 5], device='mps:0') torch.Size([3])\n",
      "\n",
      "====================Entering Layer.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -1.198/0.989\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 5]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 4.000/5.000\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.219/0.778\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.137/0.932\n",
      "Bool 'training': Value=False\n",
      "\n",
      "====================Entering Layer.attn_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -1.198/0.989\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 5]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 4.000/5.000\n",
      "Dict 'kv_cache':\n",
      "    Tensor 'kv_cache[k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.219/0.778\n",
      "    Tensor 'kv_cache[v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.137/0.932\n",
      "Bool 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -0.386/0.443\n",
      "Dict 'output[1]':\n",
      "    Tensor 'output[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.219/0.892\n",
      "    Tensor 'output[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.137/1.149\n",
      "====================Exiting Layer.attn_connect====================\n",
      "\n",
      "====================Entering Layer.mlp_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -1.019/1.215\n",
      "Bool 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -0.251/-0.020\n",
      "====================Exiting Layer.mlp_connect====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 4]), dtype: torch.float32, device: mps:0, min/max: -1.270/1.134\n",
      "Dict 'output[1]':\n",
      "    Tensor 'output[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.219/0.892\n",
      "    Tensor 'output[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.137/1.149\n",
      "====================Exiting Layer.forward====================\n",
      "tensor([[[ 0.5489,  1.1343, -0.2354,  0.3412]],\n",
      "\n",
      "        [[-0.2682, -1.2700, -0.0244, -0.8084]],\n",
      "\n",
      "        [[ 0.6216,  1.0254,  0.7872, -0.1752]]], device='mps:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "CPU times: user 126 ms, sys: 29.1 ms, total: 155 ms\n",
      "Wall time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# now let's do it for INFERENCE with the full kv-caching process \n",
    "    # meaning initial variable length prompts AND successive auto-regressive single-token input\n",
    "# here we'll be pretending we're using a model that's just a single transformer block (resid, attn, mlp) called recurrently\n",
    "\n",
    "module = Layer(cfg).to(cfg.device)\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-modules\n",
    "#module.disable_function_logging('attn_connect')\n",
    "#module.disable_function_logging('mlp_connect')\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.pre_attn_norm.enable_logging()\n",
    "#module.attn.enable_logging()\n",
    "#module.post_attn_norm.enable_logging()\n",
    "#module.pre_mlp_norm.enable_logging()\n",
    "#module.mlp.enable_logging()\n",
    "#module.post_mlp_norm.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "# so half the max_seq_len will be the length of our longest prompt in batched inference that needs to be cached\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len // 2,cfg.dim).to(cfg.device)\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "if cfg.pos_enc_type == 'RoPE':\n",
    "    precompute_freqs = PrecomputeRotaryFrequencies(cfg.head_dim, cfg.max_seq_len, cfg.theta, cfg.device)\n",
    "    freqs = precompute_freqs()\n",
    "else:\n",
    "    precompute_freqs = None\n",
    "    freqs = None\n",
    "\n",
    "# setting up for kv caching\n",
    "kv_cache = {\n",
    "    'k': torch.zeros((tcfg.micro_batch_size, cfg.max_seq_len, cfg.num_kv_heads, cfg.head_dim), device=cfg.device),\n",
    "    'v': torch.zeros((tcfg.micro_batch_size, cfg.max_seq_len, cfg.num_kv_heads, cfg.head_dim), device=cfg.device)\n",
    "}\n",
    "\n",
    "# mask ignores padding tokens and accounts for variable sequence lengths\n",
    "mask = torch.ones(tcfg.micro_batch_size, cfg.max_seq_len // 2).to(cfg.device).bool() # (True for real tokens, False for padding)\n",
    "# we'll simulate a mask setup for different-length input prompts\n",
    "for s in range(mask.shape[0] - 1): # -1 leaves the last row as the full longest prompt length\n",
    "    r = random.randint(1, cfg.max_seq_len // 2-1)\n",
    "    mask[s, -r:] = False\n",
    "print('mask:\\n', mask)\n",
    "\n",
    "cache_len = mask.sum(1).to(cfg.device).long()\n",
    "print('cache_len:\\n', cache_len, cache_len.shape)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output, kv_cache = module(x, freqs, mask, cache_len, kv_cache)\n",
    "\n",
    "input = output[:,-1:,:]\n",
    "for _ in range(2): # we'll do it twice\n",
    "    mask = torch.nn.functional.pad(mask, (1, 0, 0, 0), value=True)\n",
    "    cache_len += 1\n",
    "    print('mask:\\n', mask)\n",
    "    print('cache_len:\\n', cache_len, cache_len.shape)\n",
    "\n",
    "    output, kv_cache = module(input, freqs, mask, cache_len, kv_cache)\n",
    "    input = output\n",
    "\n",
    "print(output)\n",
    "\n",
    "del module, x, precompute_freqs, freqs, kv_cache, mask, cache_len, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677ac2b-06d0-4895-b718-2bc664613c98",
   "metadata": {},
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "655a1fec-4e32-4c7a-86e0-1390a03e88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.model import Model\n",
    "from inference import sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81b48e-ea2b-447f-bbea-4589419cc003",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ccc88d4-c650-43d3-85ee-e68152cb2e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.01M\n",
      "Model(\n",
      "  (precompute_freqs): PrecomputeRotaryFrequencies()\n",
      "  (token_embedder): Embedding(2048, 4)\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x Layer(\n",
      "      (pre_attn_norm): Norm()\n",
      "      (attn): SelfAttention(\n",
      "        (Wq): Linear(in_features=4, out_features=4, bias=False)\n",
      "        (Wk): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (Wv): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (Wo): Linear(in_features=4, out_features=4, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=4, out_features=5, bias=False)\n",
      "        (Wgate): Linear(in_features=4, out_features=5, bias=False)\n",
      "        (Wdown): Linear(in_features=5, out_features=4, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_norm): Norm()\n",
      "  (output): Linear(in_features=4, out_features=2048, bias=False)\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "====================Entering Model.forward====================\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([3, 7]), dtype: torch.int64, device: mps:0, min/max: 25.000/505.000\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Other-type 'kv_cache': Type=NoneType, Value=None\n",
      "Other-type 'mask': Type=NoneType, Value=None\n",
      "Tensor 'target_token_ids' shape: torch.Size([3, 7]), dtype: torch.int64, device: mps:0, min/max: 9.000/465.000\n",
      "\n",
      "====================Entering Layer.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.132/0.143\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Other-type 'kv_cache': Type=NoneType, Value=None\n",
      "Bool 'training': Value=True\n",
      "\n",
      "====================Entering Layer.attn_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.132/0.143\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Other-type 'kv_cache': Type=NoneType, Value=None\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.001/0.002\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "====================Exiting Layer.attn_connect====================\n",
      "\n",
      "====================Entering Layer.mlp_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.133/0.143\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.000/0.000\n",
      "====================Exiting Layer.mlp_connect====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.133/0.143\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "====================Exiting Layer.forward====================\n",
      "\n",
      "====================Entering Layer.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.133/0.143\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Other-type 'kv_cache': Type=NoneType, Value=None\n",
      "Bool 'training': Value=True\n",
      "\n",
      "====================Entering Layer.attn_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.133/0.143\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Other-type 'kv_cache': Type=NoneType, Value=None\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.002/0.003\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "====================Exiting Layer.attn_connect====================\n",
      "\n",
      "====================Entering Layer.mlp_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.133/0.143\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.000/0.000\n",
      "====================Exiting Layer.mlp_connect====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.133/0.143\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "====================Exiting Layer.forward====================\n",
      "\n",
      "====================Entering Norm.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.133/0.143\n",
      "\n",
      "====================Entering Norm.RMSNorm====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.133/0.143\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.915/1.803\n",
      "====================Exiting Norm.RMSNorm====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.915/1.803\n",
      "====================Exiting Norm.forward====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 2048]), dtype: torch.float32, device: mps:0, min/max: -0.161/0.174\n",
      "Tensor 'output[1]' shape: torch.Size([]), dtype: torch.float32, device: mps:0, min/max: 7.629/7.629\n",
      "====================Exiting Model.forward====================\n",
      "tensor([[[-1.9628e-02,  6.3587e-02, -6.0544e-03,  ..., -2.5472e-02,\n",
      "           3.8377e-02, -1.1948e-02],\n",
      "         [ 3.8946e-02,  6.0086e-02, -5.6767e-02,  ..., -2.5137e-02,\n",
      "          -3.4413e-02,  3.1394e-03],\n",
      "         [ 1.1897e-02,  5.2045e-02, -7.9649e-03,  ...,  1.8470e-02,\n",
      "          -1.1320e-02, -4.9147e-03],\n",
      "         ...,\n",
      "         [ 5.9188e-03, -7.8699e-03, -5.1693e-02,  ..., -2.9525e-02,\n",
      "          -1.8680e-03,  2.0346e-02],\n",
      "         [-3.2095e-02, -4.3670e-02,  1.1377e-03,  ...,  3.5310e-02,\n",
      "           2.6662e-02,  2.3055e-02],\n",
      "         [ 3.6601e-02, -5.2141e-02,  2.6278e-02,  ...,  3.9577e-02,\n",
      "          -6.0982e-02, -1.0751e-03]],\n",
      "\n",
      "        [[-3.0228e-02, -6.4553e-06, -2.7028e-02,  ..., -4.8464e-02,\n",
      "           4.7726e-02,  8.9915e-03],\n",
      "         [ 1.6076e-02,  1.7118e-02, -4.1859e-02,  ...,  2.2782e-02,\n",
      "          -2.1833e-02,  1.9961e-02],\n",
      "         [-2.8170e-02, -2.8001e-02,  5.5763e-02,  ...,  7.7371e-02,\n",
      "           1.4783e-02,  4.4333e-04],\n",
      "         ...,\n",
      "         [ 3.6516e-03,  4.3819e-02,  9.8173e-03,  ...,  2.8401e-02,\n",
      "          -4.4184e-03, -8.4336e-03],\n",
      "         [ 4.0311e-03, -2.5455e-02,  5.8534e-02,  ...,  4.3615e-02,\n",
      "          -1.8016e-02, -1.5738e-02],\n",
      "         [ 4.4069e-04,  3.3584e-02, -2.8335e-02,  ...,  2.8639e-02,\n",
      "          -1.4832e-03,  1.4066e-02]],\n",
      "\n",
      "        [[-8.1071e-02, -3.4644e-03,  3.3498e-02,  ...,  3.6149e-02,\n",
      "           9.2519e-02,  8.1166e-03],\n",
      "         [ 1.8120e-02, -5.9176e-02, -5.6630e-03,  ...,  7.5956e-03,\n",
      "          -3.2127e-02,  1.3295e-02],\n",
      "         [ 2.1238e-02,  1.8622e-02, -5.9533e-02,  ..., -6.8640e-02,\n",
      "          -9.1995e-03,  6.8471e-03],\n",
      "         ...,\n",
      "         [ 4.9320e-03,  2.3867e-02,  4.4362e-03,  ...,  5.1633e-02,\n",
      "          -1.3432e-02,  3.5340e-03],\n",
      "         [ 4.8509e-02, -1.0438e-02, -3.1645e-02,  ..., -6.0550e-02,\n",
      "          -4.9015e-02, -5.1567e-03],\n",
      "         [ 3.0624e-02,  6.5381e-02, -3.2883e-02,  ..., -1.7163e-02,\n",
      "          -2.5224e-02, -6.7685e-03]]], device='mps:0',\n",
      "       grad_fn=<LinearBackward0>) \n",
      " tensor(7.6292, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "CPU times: user 196 ms, sys: 34.7 ms, total: 231 ms\n",
      "Wall time: 356 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TRAINING\n",
    "module = Model(cfg).to(cfg.device)\n",
    "print(\"number of parameters: %.2fM\" % (module.get_num_params()/1e6,))\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "### enabling printing for sub-modules\n",
    "#module.precompute_freqs.enable_logging() # only un-comment this line if using RoPE\n",
    "#module.layers[0].enable_logging()\n",
    "for i in range(cfg.num_layers):\n",
    "    module.layers[i].enable_logging()\n",
    "module.final_norm.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "input_token_ids = torch.randint(tokenizer.vocab_len, (tcfg.micro_batch_size, cfg.max_seq_len)).to(cfg.device)\n",
    "target_token_ids = torch.randint(tokenizer.vocab_len, (tcfg.micro_batch_size, cfg.max_seq_len)).to(cfg.device)\n",
    "\n",
    "output, loss = module(input_token_ids, target_token_ids=target_token_ids)\n",
    "print(output, '\\n', loss)\n",
    "del module, input_token_ids, target_token_ids, output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f0cb1-81a9-4cca-983c-e871734c9f0f",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "316598a6-1ba9-4a26-962f-16c0802a698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.01M\n",
      "Model(\n",
      "  (precompute_freqs): PrecomputeRotaryFrequencies()\n",
      "  (token_embedder): Embedding(2048, 4)\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x Layer(\n",
      "      (pre_attn_norm): Norm()\n",
      "      (attn): SelfAttention(\n",
      "        (Wq): Linear(in_features=4, out_features=4, bias=False)\n",
      "        (Wk): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (Wv): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (Wo): Linear(in_features=4, out_features=4, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=4, out_features=5, bias=False)\n",
      "        (Wgate): Linear(in_features=4, out_features=5, bias=False)\n",
      "        (Wdown): Linear(in_features=5, out_features=4, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_norm): Norm()\n",
      "  (output): Linear(in_features=4, out_features=2048, bias=False)\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "mask:\n",
      " tensor([[ True, False, False],\n",
      "        [ True, False, False],\n",
      "        [ True,  True,  True]], device='mps:0')\n",
      "cache_len:\n",
      " tensor([1, 1, 3], device='mps:0') torch.Size([3])\n",
      "\n",
      "====================Entering Model.forward====================\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([3, 3]), dtype: torch.int64, device: mps:0, min/max: 48.000/493.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 1.000/3.000\n",
      "List 'kv_cache':\n",
      "    Dict 'kv_cache[0]':\n",
      "        Tensor 'kv_cache[0][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "        Tensor 'kv_cache[0][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "    Dict 'kv_cache[1]':\n",
      "        Tensor 'kv_cache[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "        Tensor 'kv_cache[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.000\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Other-type 'target_token_ids': Type=NoneType, Value=None\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 2048]), dtype: torch.float32, device: mps:0, min/max: -0.158/0.154\n",
      "List 'output[1]':\n",
      "    Dict 'output[1][0]':\n",
      "        Tensor 'output[1][0][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.078/0.022\n",
      "        Tensor 'output[1][0][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.074/0.076\n",
      "    Dict 'output[1][1]':\n",
      "        Tensor 'output[1][1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.095/0.060\n",
      "        Tensor 'output[1][1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.043/0.046\n",
      "====================Exiting Model.forward====================\n",
      "logits: torch.Size([3, 3, 2048])\n",
      "next_token_batch: tensor([[ 780],\n",
      "        [1366],\n",
      "        [1841]], device='mps:0')\n",
      "mask:\n",
      " tensor([[ True,  True, False, False],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True,  True,  True]], device='mps:0')\n",
      "cache_len:\n",
      " tensor([2, 2, 4], device='mps:0') torch.Size([3])\n",
      "\n",
      "====================Entering Model.forward====================\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([3, 1]), dtype: torch.int64, device: mps:0, min/max: 780.000/1841.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 2.000/4.000\n",
      "List 'kv_cache':\n",
      "    Dict 'kv_cache[0]':\n",
      "        Tensor 'kv_cache[0][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.078/0.022\n",
      "        Tensor 'kv_cache[0][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.074/0.076\n",
      "    Dict 'kv_cache[1]':\n",
      "        Tensor 'kv_cache[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.095/0.060\n",
      "        Tensor 'kv_cache[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.043/0.046\n",
      "Tensor 'mask' shape: torch.Size([3, 4]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Other-type 'target_token_ids': Type=NoneType, Value=None\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 2048]), dtype: torch.float32, device: mps:0, min/max: -0.162/0.167\n",
      "List 'output[1]':\n",
      "    Dict 'output[1][0]':\n",
      "        Tensor 'output[1][0][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.088/0.098\n",
      "        Tensor 'output[1][0][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.074/0.076\n",
      "    Dict 'output[1][1]':\n",
      "        Tensor 'output[1][1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.096/0.083\n",
      "        Tensor 'output[1][1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.043/0.046\n",
      "====================Exiting Model.forward====================\n",
      "logits: torch.Size([3, 1, 2048])\n",
      "next_token_batch: tensor([[ 521],\n",
      "        [ 529],\n",
      "        [1934]], device='mps:0')\n",
      "mask:\n",
      " tensor([[ True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True]], device='mps:0')\n",
      "cache_len:\n",
      " tensor([3, 3, 5], device='mps:0') torch.Size([3])\n",
      "\n",
      "====================Entering Model.forward====================\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([3, 1]), dtype: torch.int64, device: mps:0, min/max: 521.000/1934.000\n",
      "Tensor 'cache_len' shape: torch.Size([3]), dtype: torch.int64, device: mps:0, min/max: 3.000/5.000\n",
      "List 'kv_cache':\n",
      "    Dict 'kv_cache[0]':\n",
      "        Tensor 'kv_cache[0][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.088/0.098\n",
      "        Tensor 'kv_cache[0][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.074/0.076\n",
      "    Dict 'kv_cache[1]':\n",
      "        Tensor 'kv_cache[1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.096/0.083\n",
      "        Tensor 'kv_cache[1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.043/0.046\n",
      "Tensor 'mask' shape: torch.Size([3, 5]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Other-type 'target_token_ids': Type=NoneType, Value=None\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 1, 2048]), dtype: torch.float32, device: mps:0, min/max: -0.163/0.189\n",
      "List 'output[1]':\n",
      "    Dict 'output[1][0]':\n",
      "        Tensor 'output[1][0][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.132/0.113\n",
      "        Tensor 'output[1][0][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.074/0.076\n",
      "    Dict 'output[1][1]':\n",
      "        Tensor 'output[1][1][k]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.096/0.085\n",
      "        Tensor 'output[1][1][v]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.044/0.046\n",
      "====================Exiting Model.forward====================\n",
      "logits: torch.Size([3, 1, 2048])\n",
      "next_token_batch: tensor([[1794],\n",
      "        [1238],\n",
      "        [1664]], device='mps:0')\n",
      "CPU times: user 57.5 ms, sys: 87.1 ms, total: 145 ms\n",
      "Wall time: 337 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Inference\n",
    "module = Model(cfg).to(cfg.device)\n",
    "print(\"number of parameters: %.2fM\" % (module.get_num_params()/1e6,))\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "### enabling printing for sub-modules\n",
    "#for i in range(cfg.num_layers):\n",
    "    #module.layers[i].enable_logging()\n",
    "#module.final_norm.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "# so half the max_seq_len will be the length of our longest prompt in batched inference that needs to be cached\n",
    "input_token_ids = torch.randint(tokenizer.vocab_len, (tcfg.micro_batch_size, cfg.max_seq_len // 2)).to(cfg.device)\n",
    "\n",
    "kv_cache = [{ # Initialize kv caches for each layer\n",
    "                \"k\": torch.zeros((tcfg.micro_batch_size, cfg.max_seq_len, cfg.num_kv_heads, cfg.head_dim), device=cfg.device),\n",
    "                \"v\": torch.zeros((tcfg.micro_batch_size, cfg.max_seq_len, cfg.num_kv_heads, cfg.head_dim), device=cfg.device),\n",
    "            } for _ in range(cfg.num_layers)]\n",
    "\n",
    "# mask ignores padding tokens and accounts for variable sequence lengths\n",
    "mask = torch.ones(tcfg.micro_batch_size, cfg.max_seq_len // 2).to(cfg.device).bool() \n",
    "    # (True for real tokens, False for padding)\n",
    "# we'll simulate a mask setup for different-length input prompts\n",
    "for s in range(mask.shape[0] - 1): # -1 leaves the last row as the full longest prompt length\n",
    "    r = random.randint(1, cfg.max_seq_len // 2-1)\n",
    "    mask[s, -r:] = False\n",
    "print('mask:\\n', mask)\n",
    "\n",
    "cache_len = mask.sum(1).to(cfg.device).long()\n",
    "print('cache_len:\\n', cache_len, cache_len.shape)\n",
    "\n",
    "logits, kv_cache = module(input_token_ids, mask = mask, cache_len = cache_len, kv_cache = kv_cache)\n",
    "print(f'logits: {logits.shape}')\n",
    "next_token_batch = sampler(logits, cache_len=cache_len-1) # -1 ????\n",
    "print(f'next_token_batch: {next_token_batch}')\n",
    "\n",
    "for _ in range(2): # we'll do the single-input-vector autoregressive inference twice\n",
    "    mask = torch.nn.functional.pad(mask, (1, 0, 0, 0), value=True)\n",
    "    cache_len += 1\n",
    "    print('mask:\\n', mask)\n",
    "    print('cache_len:\\n', cache_len, cache_len.shape)\n",
    "\n",
    "    logits, kv_cache = module(next_token_batch, mask = mask, cache_len = cache_len, kv_cache = kv_cache)\n",
    "    \n",
    "    next_token_batch = sampler(logits)\n",
    "    print(f'logits: {logits.shape}\\nnext_token_batch: {next_token_batch}')\n",
    "\n",
    "del module, input_token_ids, kv_cache, mask, cache_len, logits, next_token_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f272a-9e60-4d41-9fe4-01a97099a4c9",
   "metadata": {},
   "source": [
    "# Other fun stuff\n",
    "\n",
    "### Learning Rate Schedule Display\n",
    "thought i'd make somewhere to help you visualize what the learning rate schedule settings you've got look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08801c2c-6f0f-4f41-a4de-25d8b10e2ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from train import scheduler_lambda\n",
    "from config import TrainConfig\n",
    "tcfg = TrainConfig()\n",
    "    \n",
    "# Generate learning rate values\n",
    "lrs = [scheduler_lambda(i) for i in range(tcfg.max_iters)]\n",
    "    \n",
    "# Plot the learning rates\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(lrs, label='Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b314d-4538-4192-b063-356bd3407fe5",
   "metadata": {},
   "source": [
    "### visualizing our tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d86faad0-346f-4ebb-927a-a093b217f5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once', ' upon', ' a', ' time']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools import import_from_nested_path\n",
    "imported_objects = import_from_nested_path(['tokenizers', cfg.tokenizer], 'tokenizer', ['get_tokenizer'])\n",
    "get_tokenizer = imported_objects.get('get_tokenizer')\n",
    "tokenizer = get_tokenizer(size = cfg.vocab_len)\n",
    "prompt = \"Once upon a time\"#'Once upon a time, there was a boy named Tim.'\n",
    "tokenizer.display(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04bc7f-a633-4bc6-8189-364a1a643844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
