{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea126987-59aa-4f76-b926-6d632887c30b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# This notebook is designed for teaching/testing purposes to help you visualize the tensor shapes that go through each module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f833b1f8-ea91-4ae5-b3a3-73e08e4c8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you prolly won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c2c04f-2dbd-4020-8d91-cc0e4e8511b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConfig(dim=4, device='mps', linear_bias=False, out_weight_share=True, max_seq_len=7, pos_enc_type='RoPE', theta=10000, tokenizer='bpe_tinyStories', vocab_len=2048, num_layers=2, second_resid_norm=False, mlp_hidden_mult=2, mlp_nonlinearity='SiLU', mlp_gated=True, num_q_heads=2, num_kv_heads=1, head_dim=2, scale_first_resid=True, norm_type='RMSNorm', norm_affine=True, norm_bias=True, eps=1e-06)\n",
      "TrainConfig(model_name='2024-10-08|23-33-49', dataset_name='noanabeshima/TinyStoriesV2', data_subset=None, streaming=False, micro_batch_size=3, grad_accum_steps=2, max_iters=20, eval_interval=2, eval_samples=1, checkpoint_interval=None, beta1=0.9, beta2=0.95, epsilon=1e-08, weight_decay=0.05, grad_clip=1.0, lr_init=1e-06, lr_max=0.01, lr_min=0.0001, warmup_iters=2, final_flat_iters=1, anneal_type='cos', num_restarts=0, T_mult=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evintunador/Documents/repos/templateGPT/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# config file\n",
    "from config import ModelConfig, TrainConfig\n",
    "cfg = ModelConfig()\n",
    "tcfg = TrainConfig()\n",
    "print(cfg)\n",
    "print(tcfg)\n",
    "\n",
    "# import the tokenizer specified by cfg\n",
    "from tools import import_from_nested_path\n",
    "imported_objects = import_from_nested_path(['tokenizers', cfg.tokenizer], 'tokenizer', ['get_tokenizer'])\n",
    "get_tokenizer = imported_objects.get('get_tokenizer')\n",
    "tokenizer = get_tokenizer(size = 512) # assuming 'bpe_tinyStories', size options are 512, 1024 and 2048\n",
    "\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c12e3b-dc63-4479-ad55-b05d96364d1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627969e9-9017-43f3-90ec-9a485abef26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.00K\n",
      "Norm()\n",
      "\n",
      "====================Entering Norm.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.961/2.597\n",
      "Full tensor content:\n",
      "tensor([[[ 0.2459, -1.1636, -1.5237, -0.0737],\n",
      "         [-0.0474, -0.6543, -1.2353,  0.2606],\n",
      "         [ 0.0069, -0.5266, -0.1695,  1.8770],\n",
      "         [-0.4793, -0.0390,  0.5932, -1.4256],\n",
      "         [-0.3897, -1.4554,  0.3027, -0.6638],\n",
      "         [ 1.9692,  0.6627, -1.6528,  0.1878],\n",
      "         [ 2.5975, -0.3696, -1.2976,  0.8763]],\n",
      "\n",
      "        [[-0.3245,  1.5467, -0.8764, -0.1252],\n",
      "         [-1.9105,  1.6103, -0.9344,  1.4153],\n",
      "         [-0.6104,  0.7250, -0.7719, -0.5431],\n",
      "         [-0.3343, -1.6637,  0.5672,  1.1532],\n",
      "         [ 0.3524, -0.9687, -0.7320,  0.1167],\n",
      "         [-0.0590,  0.1654,  0.5599,  2.2032],\n",
      "         [ 0.5050, -0.2919,  1.8451,  0.2176]],\n",
      "\n",
      "        [[-0.1951, -1.8131, -0.9637,  0.2789],\n",
      "         [ 1.0429, -0.3519,  0.2467, -0.0979],\n",
      "         [ 1.4257,  0.8795, -1.9606,  0.1615],\n",
      "         [-0.8760, -1.0121,  0.9742,  1.1106],\n",
      "         [ 0.0397,  1.8279, -0.8904, -1.5941],\n",
      "         [ 0.9376, -0.6255, -0.6133,  1.0420],\n",
      "         [ 0.4515,  0.0926, -0.1248,  0.4076]]], device='mps:0')\n",
      "\n",
      "====================Entering Norm.rms_norm====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.961/2.597\n",
      "Full tensor content:\n",
      "tensor([[[ 0.2459, -1.1636, -1.5237, -0.0737],\n",
      "         [-0.0474, -0.6543, -1.2353,  0.2606],\n",
      "         [ 0.0069, -0.5266, -0.1695,  1.8770],\n",
      "         [-0.4793, -0.0390,  0.5932, -1.4256],\n",
      "         [-0.3897, -1.4554,  0.3027, -0.6638],\n",
      "         [ 1.9692,  0.6627, -1.6528,  0.1878],\n",
      "         [ 2.5975, -0.3696, -1.2976,  0.8763]],\n",
      "\n",
      "        [[-0.3245,  1.5467, -0.8764, -0.1252],\n",
      "         [-1.9105,  1.6103, -0.9344,  1.4153],\n",
      "         [-0.6104,  0.7250, -0.7719, -0.5431],\n",
      "         [-0.3343, -1.6637,  0.5672,  1.1532],\n",
      "         [ 0.3524, -0.9687, -0.7320,  0.1167],\n",
      "         [-0.0590,  0.1654,  0.5599,  2.2032],\n",
      "         [ 0.5050, -0.2919,  1.8451,  0.2176]],\n",
      "\n",
      "        [[-0.1951, -1.8131, -0.9637,  0.2789],\n",
      "         [ 1.0429, -0.3519,  0.2467, -0.0979],\n",
      "         [ 1.4257,  0.8795, -1.9606,  0.1615],\n",
      "         [-0.8760, -1.0121,  0.9742,  1.1106],\n",
      "         [ 0.0397,  1.8279, -0.8904, -1.5941],\n",
      "         [ 0.9376, -0.6255, -0.6133,  1.0420],\n",
      "         [ 0.4515,  0.0926, -0.1248,  0.4076]]], device='mps:0')\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.763/1.933\n",
      "Full tensor content:\n",
      "tensor([[[ 0.2542, -1.2031, -1.5755, -0.0762],\n",
      "         [-0.0666, -0.9198, -1.7365,  0.3664],\n",
      "         [ 0.0071, -0.5382, -0.1733,  1.9184],\n",
      "         [-0.5928, -0.0482,  0.7336, -1.7630],\n",
      "         [-0.4656, -1.7388,  0.3616, -0.7931],\n",
      "         [ 1.4797,  0.4980, -1.2420,  0.1411],\n",
      "         [ 1.7003, -0.2419, -0.8494,  0.5736]],\n",
      "\n",
      "        [[-0.3583,  1.7077, -0.9677, -0.1382],\n",
      "         [-1.2653,  1.0665, -0.6189,  0.9373],\n",
      "         [-0.9127,  1.0840, -1.1543, -0.8121],\n",
      "         [-0.3141, -1.5632,  0.5329,  1.0835],\n",
      "         [ 0.5552, -1.5260, -1.1530,  0.1838],\n",
      "         [-0.0518,  0.1451,  0.4911,  1.9326],\n",
      "         [ 0.5187, -0.2998,  1.8950,  0.2235]],\n",
      "\n",
      "        [[-0.1875, -1.7423, -0.9261,  0.2680],\n",
      "         [ 1.8422, -0.6216,  0.4357, -0.1730],\n",
      "         [ 1.1036,  0.6808, -1.5176,  0.1250],\n",
      "         [-0.8788, -1.0154,  0.9773,  1.1142],\n",
      "         [ 0.0308,  1.4148, -0.6892, -1.2339],\n",
      "         [ 1.1344, -0.7568, -0.7421,  1.2608],\n",
      "         [ 1.4383,  0.2949, -0.3976,  1.2986]]], device='mps:0')\n",
      "====================Exiting Norm.rms_norm====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.763/1.933\n",
      "Full tensor content:\n",
      "tensor([[[ 0.2542, -1.2031, -1.5755, -0.0762],\n",
      "         [-0.0666, -0.9198, -1.7365,  0.3664],\n",
      "         [ 0.0071, -0.5382, -0.1733,  1.9184],\n",
      "         [-0.5928, -0.0482,  0.7336, -1.7630],\n",
      "         [-0.4656, -1.7388,  0.3616, -0.7931],\n",
      "         [ 1.4797,  0.4980, -1.2420,  0.1411],\n",
      "         [ 1.7003, -0.2419, -0.8494,  0.5736]],\n",
      "\n",
      "        [[-0.3583,  1.7077, -0.9677, -0.1382],\n",
      "         [-1.2653,  1.0665, -0.6189,  0.9373],\n",
      "         [-0.9127,  1.0840, -1.1543, -0.8121],\n",
      "         [-0.3141, -1.5632,  0.5329,  1.0835],\n",
      "         [ 0.5552, -1.5260, -1.1530,  0.1838],\n",
      "         [-0.0518,  0.1451,  0.4911,  1.9326],\n",
      "         [ 0.5187, -0.2998,  1.8950,  0.2235]],\n",
      "\n",
      "        [[-0.1875, -1.7423, -0.9261,  0.2680],\n",
      "         [ 1.8422, -0.6216,  0.4357, -0.1730],\n",
      "         [ 1.1036,  0.6808, -1.5176,  0.1250],\n",
      "         [-0.8788, -1.0154,  0.9773,  1.1142],\n",
      "         [ 0.0308,  1.4148, -0.6892, -1.2339],\n",
      "         [ 1.1344, -0.7568, -0.7421,  1.2608],\n",
      "         [ 1.4383,  0.2949, -0.3976,  1.2986]]], device='mps:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "====================Exiting Norm.forward====================\n"
     ]
    }
   ],
   "source": [
    "from modules.norm import Norm\n",
    "\n",
    "# Create an instance of RMSNorm\n",
    "module = Norm(cfg.dim, 'RMSNorm', device=cfg.device)\n",
    "\n",
    "# let's take a look\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "\n",
    "# Initially, logging is disabled by default\n",
    "module.enable_logging()\n",
    "\n",
    "# you can also have it optionally print out all tensors in full\n",
    "module.enable_full_tensor_printing()\n",
    "# i recommend only doing this when you have very small toy values for your hyperparameters, \n",
    "# otherwise the tensors are too big to view & the logs will take up too much space\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('CosineNorm')\n",
    "#module.disable_function_logging('LayerNorm')\n",
    "#module.disable_function_logging('RMSNorm')\n",
    "\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(x)\n",
    "\n",
    "# Disable logging. \n",
    "# This isn't actually necessary since we won't be using this object again but that's how you'd do it\n",
    "module.disable_logging()\n",
    "\n",
    "# clearing up ram jic we're training later\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e190f3de-37fd-442b-bfb1-6a090115fc75",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89e1e8f-cedd-4885-ad50-934827ed045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.attention import SelfAttention, PrecomputeRotaryFrequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d71c1-288f-4859-8a88-8063c9b16b5e",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8f27b4-6d1f-4fcd-99b0-2284e65d6b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.05K\n",
      "SelfAttention(\n",
      "  (Wq): Linear(in_features=4, out_features=4, bias=False)\n",
      "  (Wk): Linear(in_features=4, out_features=2, bias=False)\n",
      "  (Wv): Linear(in_features=4, out_features=2, bias=False)\n",
      "  (Wo): Linear(in_features=4, out_features=4, bias=False)\n",
      ")\n",
      "\n",
      "====================Entering SelfAttention.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.368/2.264\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "bool 'training': Value=True\n",
      "\n",
      "====================Entering SelfAttention.apply_rotary_pos_emb====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.577/1.499\n",
      "Tensor 'k' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.559/1.818\n",
      "Tensor 'sin' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'cos' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.577/1.499\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.577/1.328\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.559/1.818\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.818/1.559\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.299/1.499\n",
      "Tensor 'output[1]' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.814/1.490\n",
      "====================Exiting SelfAttention.apply_rotary_pos_emb====================\n",
      "\n",
      "====================Entering SelfAttention.match_headcount====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.814/1.490\n",
      "Tensor 'v' shape: torch.Size([3, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.890/1.686\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.814/1.490\n",
      "Tensor 'output[1]' shape: torch.Size([3, 7, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.890/1.686\n",
      "====================Exiting SelfAttention.match_headcount====================\n",
      "\n",
      "====================Entering SelfAttention.flash_attention====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 2, 7, 2]), dtype: torch.float32, device: mps:0, min/max: -1.299/1.499\n",
      "Tensor 'k' shape: torch.Size([3, 2, 7, 2]), dtype: torch.float32, device: mps:0, min/max: -1.814/1.490\n",
      "Tensor 'v' shape: torch.Size([3, 2, 7, 2]), dtype: torch.float32, device: mps:0, min/max: -1.890/1.686\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 2, 7, 2]), dtype: torch.float32, device: mps:0, min/max: -1.393/1.388\n",
      "====================Exiting SelfAttention.flash_attention====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.917/0.824\n",
      "====================Exiting SelfAttention.forward====================\n",
      "CPU times: user 131 ms, sys: 23.2 ms, total: 154 ms\n",
      "Wall time: 186 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# first up let's look at training\n",
    "\n",
    "# Create an instance of multi-head self-attention\n",
    "module = SelfAttention(cfg.dim, cfg.head_dim, cfg.num_q_heads, cfg.num_kv_heads, cfg.max_seq_len, cfg.linear_bias, device=cfg.device)\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "\n",
    "# Initially, logging is disabled by default\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('splice_specific_frequencies')\n",
    "#module.disable_function_logging('apply_rotary_pos_emb')\n",
    "#module.disable_function_logging('rotate_half')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('flash_attention')\n",
    "#module.disable_function_logging('regular_attention')\n",
    "#module.disable_function_logging('adjust_inference_mask')\n",
    "#module.disable_function_logging('project_values')\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "if cfg.pos_enc_type == 'RoPE':\n",
    "    precompute_freqs = PrecomputeRotaryFrequencies(cfg.head_dim, cfg.max_seq_len, cfg.theta, cfg.device)\n",
    "    freqs = precompute_freqs()\n",
    "else:\n",
    "    precompute_freqs = None\n",
    "    freqs = None\n",
    "mask = torch.ones(cfg.max_seq_len, cfg.max_seq_len, dtype=torch.bool, device=cfg.device).tril()\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(x, freqs, mask, training=True)\n",
    "\n",
    "# clearing up ram jic we're training later\n",
    "del module, precompute_freqs, freqs, mask, x, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82707fa2-4af3-4a71-a664-80fdbe82c919",
   "metadata": {},
   "source": [
    "## inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e23306f-de70-448a-80f9-75c200a804ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask:\n",
      " tensor([[ True, False, False],\n",
      "        [ True,  True, False],\n",
      "        [ True,  True,  True]], device='mps:0')\n",
      "\n",
      "====================Entering SelfAttention.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -2.409/2.992\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "bool 'training': Value=False\n",
      "\n",
      "====================Entering SelfAttention.apply_rotary_pos_emb====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.443/1.428\n",
      "Tensor 'k' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.044/1.459\n",
      "Tensor 'sin' shape: torch.Size([1, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: 0.000/0.909\n",
      "Tensor 'cos' shape: torch.Size([1, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.416/1.000\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.443/1.428\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.428/1.443\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "====================Entering SelfAttention.rotate_half====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -1.044/1.459\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.729/1.459\n",
      "====================Exiting SelfAttention.rotate_half====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -1.575/1.268\n",
      "Tensor 'output[1]' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.667/1.574\n",
      "====================Exiting SelfAttention.apply_rotary_pos_emb====================\n",
      "\n",
      "====================Entering SelfAttention.match_headcount====================\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.667/1.574\n",
      "Tensor 'v' shape: torch.Size([3, 3, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -2.146/0.961\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -0.667/1.574\n",
      "Tensor 'output[1]' shape: torch.Size([3, 3, 2, 2]), dtype: torch.float32, device: mps:0, min/max: -2.146/0.961\n",
      "====================Exiting SelfAttention.match_headcount====================\n",
      "\n",
      "====================Entering SelfAttention.flash_attention====================\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([3, 2, 3, 2]), dtype: torch.float32, device: mps:0, min/max: -1.575/1.268\n",
      "Tensor 'k' shape: torch.Size([3, 2, 3, 2]), dtype: torch.float32, device: mps:0, min/max: -0.667/1.574\n",
      "Tensor 'v' shape: torch.Size([3, 2, 3, 2]), dtype: torch.float32, device: mps:0, min/max: -2.146/0.961\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "bool 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 2, 3, 2]), dtype: torch.float32, device: mps:0, min/max: -2.146/0.361\n",
      "====================Exiting SelfAttention.flash_attention====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -1.077/0.615\n",
      "====================Exiting SelfAttention.forward====================\n",
      "tensor([[[ 1.3338e-01,  1.4006e-01,  2.7484e-01, -2.5441e-01],\n",
      "         [-7.5152e-04,  3.2554e-02,  2.9721e-01, -1.2971e-01],\n",
      "         [-2.0296e-01, -3.2702e-01,  1.9573e-01,  2.9119e-01]],\n",
      "\n",
      "        [[-2.0659e-02, -2.2013e-02, -1.0589e-01,  4.3670e-02],\n",
      "         [ 2.6241e-02,  1.9291e-02, -5.7683e-02, -4.4330e-02],\n",
      "         [-7.4936e-03, -8.2230e-02, -6.6649e-02,  2.7176e-02]],\n",
      "\n",
      "        [[ 5.8861e-01,  6.1468e-01,  5.3885e-01, -1.0773e+00],\n",
      "         [-1.0188e-02, -1.2643e-01,  3.0727e-01,  4.4442e-02],\n",
      "         [-8.6149e-02, -2.4107e-02,  1.4689e-01,  9.5795e-02]]],\n",
      "       device='mps:0', grad_fn=<LinearBackward0>)\n",
      "CPU times: user 93.9 ms, sys: 16.9 ms, total: 111 ms\n",
      "Wall time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "module = SelfAttention(cfg.dim, cfg.head_dim, cfg.num_q_heads, cfg.num_kv_heads, cfg.max_seq_len, cfg.linear_bias, device=cfg.device)\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('splice_specific_frequencies')\n",
    "#module.disable_function_logging('apply_rotary_pos_emb')\n",
    "#module.disable_function_logging('rotate_half')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('flash_attention')\n",
    "#module.disable_function_logging('regular_attention')\n",
    "#module.disable_function_logging('adjust_inference_mask')\n",
    "#module.disable_function_logging('project_values')\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "# so half the max_seq_len will be the length of our longest prompt in batched inference that needs to be cached\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len // 2,cfg.dim).to(cfg.device) \n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "if cfg.pos_enc_type == 'RoPE':\n",
    "    precompute_freqs = PrecomputeRotaryFrequencies(cfg.head_dim, cfg.max_seq_len, cfg.theta, cfg.device)\n",
    "    freqs = precompute_freqs()\n",
    "else:\n",
    "    precompute_freqs = None\n",
    "    freqs = None\n",
    "\n",
    "mask = torch.ones(cfg.max_seq_len, cfg.max_seq_len, dtype=torch.bool, device=cfg.device).tril()\n",
    "mask = mask[:cfg.max_seq_len//2, :cfg.max_seq_len//2]\n",
    "print('mask:\\n', mask)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(x, freqs, mask)\n",
    "print(output)\n",
    "    \n",
    "# clearing up ram jic we're training later\n",
    "del module, x, precompute_freqs, freqs, mask, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb308c5-b578-46f2-86ae-bfa6800be641",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7736b685-f941-4182-a5b7-4731cce706b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62e49e9-2189-4269-968e-1df99469dc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.06K\n",
      "MLP(\n",
      "  (Wup): Linear(in_features=4, out_features=5, bias=False)\n",
      "  (Wgate): Linear(in_features=4, out_features=5, bias=False)\n",
      "  (Wdown): Linear(in_features=5, out_features=4, bias=False)\n",
      "  (nonlinearity): GELU(approximate='none')\n",
      ")\n",
      "\n",
      "====================Entering MLP.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.464/2.680\n",
      "bool 'training': Value=True\n",
      "\n",
      "====================Entering MLP.up_proj====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.464/2.680\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 5]), dtype: torch.float32, device: mps:0, min/max: -1.722/2.098\n",
      "====================Exiting MLP.up_proj====================\n",
      "\n",
      "====================Entering MLP.gate_proj====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.464/2.680\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 5]), dtype: torch.float32, device: mps:0, min/max: -0.170/1.186\n",
      "====================Exiting MLP.gate_proj====================\n",
      "\n",
      "====================Entering MLP.down_proj====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 5]), dtype: torch.float32, device: mps:0, min/max: -0.946/1.358\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.358/0.319\n",
      "====================Exiting MLP.down_proj====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.358/0.319\n",
      "====================Exiting MLP.forward====================\n",
      "CPU times: user 36 ms, sys: 7.23 ms, total: 43.3 ms\n",
      "Wall time: 45.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# GeGLU\n",
    "module = MLP(\n",
    "    cfg.dim, \n",
    "    int(cfg.dim * cfg.mlp_hidden_mult * 2/3), \n",
    "    cfg.dim, \n",
    "    'GeLU', \n",
    "    gated=True, \n",
    "    bias=cfg.linear_bias, \n",
    "    dropout_rate = 0.1\n",
    ").to(cfg.device)\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "module.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "output = module(x, training=True)\n",
    "module.disable_logging()\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0748fa3-3230-4dd7-a768-1256ea72e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.08K\n",
      "MLP(\n",
      "  (Wup): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (Wdown): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (nonlinearity): ReLU()\n",
      ")\n",
      "\n",
      "====================Entering MLP.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.988/2.564\n",
      "bool 'training': Value=True\n",
      "\n",
      "====================Entering MLP.up_proj====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.988/2.564\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 8]), dtype: torch.float32, device: mps:0, min/max: -1.527/1.996\n",
      "====================Exiting MLP.up_proj====================\n",
      "\n",
      "====================Entering MLP.down_proj====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 8]), dtype: torch.float32, device: mps:0, min/max: -1.696/2.217\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.047/1.743\n",
      "====================Exiting MLP.down_proj====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.047/1.743\n",
      "====================Exiting MLP.forward====================\n",
      "CPU times: user 39 ms, sys: 9.15 ms, total: 48.1 ms\n",
      "Wall time: 87 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# not gated and testing a different nonlinearity\n",
    "module = MLP(\n",
    "    cfg.dim, \n",
    "    cfg.dim * cfg.mlp_hidden_mult, \n",
    "    cfg.dim, \n",
    "    'ReLU', \n",
    "    gated=False, \n",
    "    bias=True, \n",
    "    dropout_rate = 0.1\n",
    ").to(cfg.device)\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "module.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "output = module(x, training=True)\n",
    "module.disable_logging()\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a502f-4646-4a02-9412-372482af9fa0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ResidualLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a21d708-af47-4f32-b111-08efedc584f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.layer import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40995e1a-20d7-445e-9db9-2192cefbe502",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c886661d-5a26-4787-93d1-c3c8c6b1c02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.12K\n",
      "Layer(\n",
      "  (pre_attn_norm): Norm()\n",
      "  (attn): SelfAttention(\n",
      "    (Wq): Linear(in_features=4, out_features=4, bias=False)\n",
      "    (Wk): Linear(in_features=4, out_features=2, bias=False)\n",
      "    (Wv): Linear(in_features=4, out_features=2, bias=False)\n",
      "    (Wo): Linear(in_features=4, out_features=4, bias=False)\n",
      "  )\n",
      "  (pre_mlp_norm): Norm()\n",
      "  (mlp): MLP(\n",
      "    (Wup): Linear(in_features=4, out_features=5, bias=False)\n",
      "    (Wgate): Linear(in_features=4, out_features=5, bias=False)\n",
      "    (Wdown): Linear(in_features=5, out_features=4, bias=False)\n",
      "    (nonlinearity): SiLU()\n",
      "  )\n",
      ")\n",
      "tensor([[ True, False, False, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True]], device='mps:0')\n",
      "\n",
      "====================Entering Layer.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.198/2.277\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=True\n",
      "\n",
      "====================Entering Layer.attn_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.198/2.277\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.607/0.785\n",
      "====================Exiting Layer.attn_connect====================\n",
      "\n",
      "====================Entering Layer.mlp_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.139/2.096\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.340/0.228\n",
      "====================Exiting Layer.mlp_connect====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -2.122/2.096\n",
      "====================Exiting Layer.forward====================\n",
      "CPU times: user 28 ms, sys: 11.5 ms, total: 39.5 ms\n",
      "Wall time: 76.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TRAINING\n",
    "module = Layer(cfg).to(cfg.device)\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "### Optionally disabling printing for sub-modules\n",
    "#module.disable_function_logging('attn_connect')\n",
    "#module.disable_function_logging('mlp_connect')\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.pre_attn_norm.enable_logging()\n",
    "#module.attn.enable_logging()\n",
    "#module.post_attn_norm.enable_logging()\n",
    "#module.pre_mlp_norm.enable_logging()\n",
    "#module.mlp.enable_logging()\n",
    "#module.post_mlp_norm.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "if cfg.pos_enc_type == 'RoPE':\n",
    "    precompute_freqs = PrecomputeRotaryFrequencies(cfg.head_dim, cfg.max_seq_len, cfg.theta, cfg.device)\n",
    "    freqs = precompute_freqs()\n",
    "else:\n",
    "    precompute_freqs = None\n",
    "    freqs = None\n",
    "mask = torch.ones(cfg.max_seq_len, cfg.max_seq_len, dtype=torch.bool, device=cfg.device).tril()\n",
    "print(mask)\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "output = module(x, freqs, mask, training=True)\n",
    "module.disable_logging()\n",
    "del module,freqs, mask, x, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dd91d-a84c-43a3-8dd7-34f43b0a7c9a",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f534ab4-a150-42db-8c89-5e8d3d0c06a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.12K\n",
      "Layer(\n",
      "  (pre_attn_norm): Norm()\n",
      "  (attn): SelfAttention(\n",
      "    (Wq): Linear(in_features=4, out_features=4, bias=False)\n",
      "    (Wk): Linear(in_features=4, out_features=2, bias=False)\n",
      "    (Wv): Linear(in_features=4, out_features=2, bias=False)\n",
      "    (Wo): Linear(in_features=4, out_features=4, bias=False)\n",
      "  )\n",
      "  (pre_mlp_norm): Norm()\n",
      "  (mlp): MLP(\n",
      "    (Wup): Linear(in_features=4, out_features=5, bias=False)\n",
      "    (Wgate): Linear(in_features=4, out_features=5, bias=False)\n",
      "    (Wdown): Linear(in_features=5, out_features=4, bias=False)\n",
      "    (nonlinearity): SiLU()\n",
      "  )\n",
      ")\n",
      "mask:\n",
      " tensor([[ True, False, False],\n",
      "        [ True,  True, False],\n",
      "        [ True,  True,  True]], device='mps:0')\n",
      "\n",
      "====================Entering Layer.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -2.394/2.568\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=False\n",
      "\n",
      "====================Entering Layer.attn_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -2.394/2.568\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([3, 3]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -0.182/0.058\n",
      "====================Exiting Layer.attn_connect====================\n",
      "\n",
      "====================Entering Layer.mlp_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -2.421/2.491\n",
      "Bool 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -0.280/0.278\n",
      "====================Exiting Layer.mlp_connect====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 3, 4]), dtype: torch.float32, device: mps:0, min/max: -2.143/2.397\n",
      "====================Exiting Layer.forward====================\n",
      "tensor([[[ 1.3895,  0.1157,  0.5777,  1.3092],\n",
      "         [ 0.2304, -0.0439, -0.2407,  2.3970],\n",
      "         [-0.3427, -1.6707, -0.5809,  0.3654]],\n",
      "\n",
      "        [[-0.3560, -0.3472, -0.0746,  1.1304],\n",
      "         [-0.5401, -0.1229,  0.5131, -0.2374],\n",
      "         [-0.4394, -1.0417,  0.9858, -1.5303]],\n",
      "\n",
      "        [[-0.1513, -0.1967, -0.6823,  0.8920],\n",
      "         [-2.1425, -1.4079,  0.3758, -0.7015],\n",
      "         [ 0.6322, -0.3028,  0.7026, -0.4916]]], device='mps:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "CPU times: user 33.5 ms, sys: 10.8 ms, total: 44.3 ms\n",
      "Wall time: 67.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# now let's do it for INFERENCE with the full kv-caching process \n",
    "    # meaning initial variable length prompts AND successive auto-regressive single-token input\n",
    "# here we'll be pretending we're using a model that's just a single transformer block (resid, attn, mlp) called recurrently\n",
    "\n",
    "module = Layer(cfg).to(cfg.device)\n",
    "print(\"number of parameters: %.2fK\" % (module.get_num_params()/1e3,))\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-modules\n",
    "#module.disable_function_logging('attn_connect')\n",
    "#module.disable_function_logging('mlp_connect')\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.pre_attn_norm.enable_logging()\n",
    "#module.attn.enable_logging()\n",
    "#module.post_attn_norm.enable_logging()\n",
    "#module.pre_mlp_norm.enable_logging()\n",
    "#module.mlp.enable_logging()\n",
    "#module.post_mlp_norm.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "# so half the max_seq_len will be the length of our longest prompt in batched inference that needs to be cached\n",
    "x = torch.randn(tcfg.micro_batch_size,cfg.max_seq_len // 2,cfg.dim).to(cfg.device)\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "if cfg.pos_enc_type == 'RoPE':\n",
    "    precompute_freqs = PrecomputeRotaryFrequencies(cfg.head_dim, cfg.max_seq_len, cfg.theta, cfg.device)\n",
    "    freqs = precompute_freqs()\n",
    "else:\n",
    "    precompute_freqs = None\n",
    "    freqs = None\n",
    "\n",
    "mask = torch.ones(cfg.max_seq_len, cfg.max_seq_len, dtype=torch.bool, device=cfg.device).tril()\n",
    "mask = mask[:cfg.max_seq_len//2, :cfg.max_seq_len//2]\n",
    "print('mask:\\n', mask)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(x, freqs, mask)\n",
    "print(output)\n",
    "\n",
    "del module, x, precompute_freqs, freqs, mask, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677ac2b-06d0-4895-b718-2bc664613c98",
   "metadata": {},
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "655a1fec-4e32-4c7a-86e0-1390a03e88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.model import Model\n",
    "from inference import sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81b48e-ea2b-447f-bbea-4589419cc003",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ccc88d4-c650-43d3-85ee-e68152cb2e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.01M\n",
      "Model(\n",
      "  (precompute_freqs): PrecomputeRotaryFrequencies()\n",
      "  (token_embedder): Embedding(2048, 4)\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x Layer(\n",
      "      (pre_attn_norm): Norm()\n",
      "      (attn): SelfAttention(\n",
      "        (Wq): Linear(in_features=4, out_features=4, bias=False)\n",
      "        (Wk): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (Wv): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (Wo): Linear(in_features=4, out_features=4, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=4, out_features=5, bias=False)\n",
      "        (Wgate): Linear(in_features=4, out_features=5, bias=False)\n",
      "        (Wdown): Linear(in_features=5, out_features=4, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_norm): Norm()\n",
      "  (output): Linear(in_features=4, out_features=2048, bias=False)\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "====================Entering Model.forward====================\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([3, 7]), dtype: torch.int64, device: mps:0, min/max: 14.000/509.000\n",
      "Tensor 'target_token_ids' shape: torch.Size([3, 7]), dtype: torch.int64, device: mps:0, min/max: 78.000/509.000\n",
      "\n",
      "====================Entering Layer.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.089/0.093\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=True\n",
      "\n",
      "====================Entering Layer.attn_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.089/0.093\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.002/0.002\n",
      "====================Exiting Layer.attn_connect====================\n",
      "\n",
      "====================Entering Layer.mlp_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.088/0.093\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.000/0.000\n",
      "====================Exiting Layer.mlp_connect====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.088/0.093\n",
      "====================Exiting Layer.forward====================\n",
      "\n",
      "====================Entering Layer.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.088/0.093\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=True\n",
      "\n",
      "====================Entering Layer.attn_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.088/0.093\n",
      "Dict 'freqs':\n",
      "    Tensor 'freqs[cos]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.990/1.000\n",
      "    Tensor 'freqs[sin]' shape: torch.Size([1, 7, 1, 2]), dtype: torch.float32, device: mps:0, min/max: -0.959/0.909\n",
      "Tensor 'mask' shape: torch.Size([7, 7]), dtype: torch.bool, device: mps:0, min/max: 0.000/1.000\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.001/0.002\n",
      "====================Exiting Layer.attn_connect====================\n",
      "\n",
      "====================Entering Layer.mlp_connect====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.087/0.093\n",
      "Bool 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.000/0.000\n",
      "====================Exiting Layer.mlp_connect====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.087/0.093\n",
      "====================Exiting Layer.forward====================\n",
      "\n",
      "====================Entering Norm.forward====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.087/0.093\n",
      "\n",
      "====================Entering Norm.RMSNorm====================\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -0.087/0.093\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.983/1.925\n",
      "====================Exiting Norm.RMSNorm====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([3, 7, 4]), dtype: torch.float32, device: mps:0, min/max: -1.983/1.925\n",
      "====================Exiting Norm.forward====================\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 7, 2048]), dtype: torch.float32, device: mps:0, min/max: -0.169/0.159\n",
      "Tensor 'output[1]' shape: torch.Size([]), dtype: torch.float32, device: mps:0, min/max: 7.640/7.640\n",
      "====================Exiting Model.forward====================\n",
      "tensor([[[-0.0285,  0.0017, -0.0037,  ..., -0.0831, -0.0090,  0.0131],\n",
      "         [ 0.0346, -0.0927,  0.0398,  ..., -0.0180, -0.0333,  0.0073],\n",
      "         [-0.0109, -0.0157,  0.0514,  ...,  0.0242,  0.0218,  0.0404],\n",
      "         ...,\n",
      "         [-0.0746,  0.0537, -0.0207,  ..., -0.0339,  0.0204, -0.0238],\n",
      "         [ 0.0288, -0.0187, -0.0376,  ..., -0.0591, -0.0390, -0.0213],\n",
      "         [-0.0289,  0.0804,  0.0040,  ...,  0.0425,  0.0514,  0.0386]],\n",
      "\n",
      "        [[ 0.0833, -0.1140,  0.0344,  ..., -0.0403, -0.0550,  0.0294],\n",
      "         [ 0.0527, -0.0534,  0.0489,  ...,  0.0093, -0.0072,  0.0599],\n",
      "         [-0.0238,  0.0678, -0.0345,  ...,  0.0825,  0.0308, -0.0456],\n",
      "         ...,\n",
      "         [ 0.0866, -0.0831,  0.0097,  ..., -0.0161, -0.0487,  0.0135],\n",
      "         [-0.0192, -0.0123, -0.0213,  ..., -0.0940, -0.0272, -0.0135],\n",
      "         [ 0.0319,  0.0178,  0.0172,  ...,  0.0547,  0.0214,  0.0422]],\n",
      "\n",
      "        [[-0.0101,  0.0216, -0.0442,  ...,  0.0255, -0.0064, -0.0652],\n",
      "         [-0.0184, -0.0145, -0.0194,  ..., -0.0952, -0.0277, -0.0116],\n",
      "         [-0.0680,  0.0809, -0.0144,  ..., -0.0205,  0.0383,  0.0105],\n",
      "         ...,\n",
      "         [-0.0317,  0.0654, -0.0577,  ...,  0.0166,  0.0101, -0.0569],\n",
      "         [ 0.0009, -0.0381,  0.0090,  ..., -0.0977, -0.0280,  0.0247],\n",
      "         [-0.0660,  0.0619, -0.0406,  ..., -0.0340,  0.0137, -0.0386]]],\n",
      "       device='mps:0', grad_fn=<LinearBackward0>) \n",
      " tensor(7.6402, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "CPU times: user 153 ms, sys: 57 ms, total: 210 ms\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TRAINING\n",
    "module = Model(cfg).to(cfg.device)\n",
    "print(\"number of parameters: %.2fM\" % (module.get_num_params()/1e6,))\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "### enabling printing for sub-modules\n",
    "#module.precompute_freqs.enable_logging() # only un-comment this line if using RoPE\n",
    "#module.layers[0].enable_logging()\n",
    "for i in range(cfg.num_layers):\n",
    "    module.layers[i].enable_logging()\n",
    "module.final_norm.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "input_token_ids = torch.randint(tokenizer.vocab_len, (tcfg.micro_batch_size, cfg.max_seq_len)).to(cfg.device)\n",
    "target_token_ids = torch.randint(tokenizer.vocab_len, (tcfg.micro_batch_size, cfg.max_seq_len)).to(cfg.device)\n",
    "\n",
    "output, loss = module(input_token_ids, target_token_ids)\n",
    "print(output, '\\n', loss)\n",
    "del module, input_token_ids, target_token_ids, output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f0cb1-81a9-4cca-983c-e871734c9f0f",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "316598a6-1ba9-4a26-962f-16c0802a698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.01M\n",
      "Model(\n",
      "  (precompute_freqs): PrecomputeRotaryFrequencies()\n",
      "  (token_embedder): Embedding(2048, 4)\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x Layer(\n",
      "      (pre_attn_norm): Norm()\n",
      "      (attn): SelfAttention(\n",
      "        (Wq): Linear(in_features=4, out_features=4, bias=False)\n",
      "        (Wk): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (Wv): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (Wo): Linear(in_features=4, out_features=4, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=4, out_features=5, bias=False)\n",
      "        (Wgate): Linear(in_features=4, out_features=5, bias=False)\n",
      "        (Wdown): Linear(in_features=5, out_features=4, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_norm): Norm()\n",
      "  (output): Linear(in_features=4, out_features=2048, bias=False)\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "====================Entering Model.forward====================\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([3, 3]), dtype: torch.int64, device: mps:0, min/max: 18.000/386.000\n",
      "Other-type 'target_token_ids': Type=NoneType, Value=None\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([3, 3, 2048]), dtype: torch.float32, device: mps:0, min/max: -0.151/0.165\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "====================Exiting Model.forward====================\n",
      "logits: torch.Size([3, 3, 2048])\n",
      "next_token_batch: tensor([[1884],\n",
      "        [1137],\n",
      "        [ 795]], device='mps:0')\n",
      "input_token_ids: tensor([[ 386,   59,   29, 1884],\n",
      "        [ 326,  356,  340, 1137],\n",
      "        [ 276,   87,   18,  795]], device='mps:0')\n",
      "CPU times: user 114 ms, sys: 50.3 ms, total: 164 ms\n",
      "Wall time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Inference\n",
    "module = Model(cfg).to(cfg.device)\n",
    "print(\"number of parameters: %.2fM\" % (module.get_num_params()/1e6,))\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "### enabling printing for sub-modules\n",
    "#for i in range(cfg.num_layers):\n",
    "    #module.layers[i].enable_logging()\n",
    "#module.final_norm.enable_logging()\n",
    "\n",
    "# optionally enabling printing of every single input/output tensor\n",
    "#module.enable_full_tensor_printing()\n",
    "\n",
    "# so half the max_seq_len will be the length of our longest prompt in batched inference that needs to be cached\n",
    "input_token_ids = torch.randint(tokenizer.vocab_len, (tcfg.micro_batch_size, cfg.max_seq_len // 2)).to(cfg.device)\n",
    "\n",
    "logits, _ = module(input_token_ids)\n",
    "print(f'logits: {logits.shape}')\n",
    "next_token_batch = sampler(logits)\n",
    "print(f'next_token_batch: {next_token_batch}')\n",
    "input_token_ids = torch.concat([input_token_ids, next_token_batch], dim=1)\n",
    "print(f'input_token_ids: {input_token_ids}')\n",
    "\n",
    "del module, input_token_ids, logits, next_token_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f272a-9e60-4d41-9fe4-01a97099a4c9",
   "metadata": {},
   "source": [
    "# Other fun stuff\n",
    "\n",
    "### Learning Rate Schedule Display\n",
    "thought i'd make somewhere to help you visualize what the learning rate schedule settings you've got look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08801c2c-6f0f-4f41-a4de-25d8b10e2ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA18AAAHWCAYAAACIZjNQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACSzElEQVR4nOzdd3hU1drG4d/MZNI7IQkl9N5L6CCiQBBEigJWigiioHjwgKIIiu0TFAFBARvoORwVCzZAEUHpnVAk9BYggRBSSEid+f4IGY2EEiSzU577urgwe/bseWZl1LxZe73LZLfb7YiIiIiIiEihMhsdQEREREREpDRQ8SUiIiIiIuIEKr5EREREREScQMWXiIiIiIiIE6j4EhERERERcQIVXyIiIiIiIk6g4ktERERERMQJVHyJiIiIiIg4gYovERERERERJ1DxJSIihqhSpQqDBw82OkapcvToUUwmE2+++Wahv9b8+fMxmUwcPXq0wM9dtWoVJpOJVatW3fRcIiJGUvElIlKM5f6Au2XLFqOjFCsmkynPH19fXzp27MiPP/54w9dcuHAh06dPv3kh/+L777+nY8eOBAcH4+npSbVq1ejfvz/Lli0rlNcTEZHC4WJ0ABERKZ327duH2Wzc7wC7dOnCwIEDsdvtHDt2jPfee4+ePXuydOlSIiIiCny9hQsXsnv3bp566qmbmvPNN99k7NixdOzYkfHjx+Pp6cnBgwf55Zdf+Oyzz+jWrdtNfT0RESk8Kr5EROQfy8rKwmaz4erqet3PcXNzK8RE11arVi0efPBBx9d333039erVY8aMGTdUfBWGrKwsXn75Zbp06cLPP/982eNnzpwxIJWIiNwo3XYoIlIKnDx5kocffpiQkBDc3NyoX78+H330UZ5zMjIymDhxIs2bN8fPzw8vLy86dOjAypUr85z313VD06dPp3r16ri5ufHHH3/w4osvYjKZOHjwIIMHD8bf3x8/Pz+GDBlCampqnuv8fc1X7i2Ua9euZcyYMZQtWxYvLy/69OnD2bNn8zzXZrPx4osvUr58eTw9PenUqRN//PHHP1pHVrduXYKCgjh06FCe499++y09evSgfPnyuLm5Ub16dV5++WWys7Md59x66638+OOPHDt2zHErY5UqVRyPp6enM2nSJGrUqIGbmxthYWGMGzeO9PT0q2aKi4sjKSmJdu3a5ft4cHBwnq/T0tJ48cUXqVWrFu7u7pQrV46+ffte9p4A5s2b5/jetWjRgs2bN192TlRUFPfccw+BgYG4u7sTHh7Od999d9l5e/bs4bbbbsPDw4OKFSvyyiuvYLPZLjvPZDLx4osvXnb8er9vGzdupFu3bvj5+eHp6UnHjh1Zu3btNZ8nIlJUaOZLRKSEi42NpXXr1phMJkaNGkXZsmVZunQpQ4cOJSkpyXGbXFJSEh988AH33Xcfw4YNIzk5mQ8//JCIiAg2bdpEkyZN8lz3448/Ji0tjeHDh+Pm5kZgYKDjsf79+1O1alVef/11tm3bxgcffEBwcDBvvPHGNfM+8cQTBAQEMGnSJI4ePcr06dMZNWoUn3/+ueOc8ePHM2XKFHr27ElERASRkZFERESQlpZ2w+OUmJjI+fPnqV69ep7j8+fPx9vbmzFjxuDt7c2vv/7KxIkTSUpKYurUqQA8//zzJCYmEh0dzdtvvw2At7c3kFMo3nXXXaxZs4bhw4dTt25ddu3axdtvv83+/ftZvHjxFTMFBwfj4eHB999/zxNPPJFnjP8uOzubO++8kxUrVnDvvfcyevRokpOTWb58Obt3787zvhYuXEhycjKPPvooJpOJKVOm0LdvXw4fPozVagVyCqp27dpRoUIFnn32Wby8vPjiiy/o3bs3X331FX369AEgJiaGTp06kZWV5Thv3rx5eHh4FPybcBW//vord9xxB82bN2fSpEmYzWY+/vhjbrvtNlavXk3Lli1v6uuJiBQKu4iIFFsff/yxHbBv3rz5iucMHTrUXq5cOXtcXFye4/fee6/dz8/Pnpqaarfb7fasrCx7enp6nnPOnz9vDwkJsT/88MOOY0eOHLEDdl9fX/uZM2fynD9p0iQ7kOd8u91u79Onj71MmTJ5jlWuXNk+aNCgy95L586d7TabzXH8X//6l91isdgTEhLsdrvdHhMTY3dxcbH37t07z/VefPFFO5DnmlcC2IcOHWo/e/as/cyZM/YtW7bYu3XrZgfsU6dOzXNu7vj81aOPPmr39PS0p6WlOY716NHDXrly5cvO/fTTT+1ms9m+evXqPMfnzJljB+xr1669ataJEyfaAbuXl5f9jjvusL/66qv2rVu3XnbeRx99ZAfs06ZNu+yx3PHM/d6VKVPGHh8f73j822+/tQP277//3nHs9ttvtzds2DDPe7TZbPa2bdvaa9as6Tj21FNP2QH7xo0bHcfOnDlj9/PzswP2I0eOOI4D9kmTJl2W7++fhZUrV9oB+8qVKx2vW7NmTXtERESez0Zqaqq9atWq9i5duuQzciIiRY9uOxQRKcHsdjtfffUVPXv2xG63ExcX5/gTERFBYmIi27ZtA8BisTjWbNlsNuLj48nKyiI8PNxxzl/dfffdlC1bNt/XHTFiRJ6vO3TowLlz50hKSrpm5uHDh2MymfI8Nzs7m2PHjgGwYsUKsrKyePzxx/M874knnrjmtf/qww8/pGzZsgQHBxMeHs6KFSsYN24cY8aMyXPeX2dwkpOTiYuLo0OHDqSmphIVFXXN11m0aBF169alTp06ecb/tttuA7jsts6/e+mll1i4cCFNmzblp59+4vnnn6d58+Y0a9aMvXv3Os776quvCAoKyncc/jqeAAMGDCAgIMDxdYcOHQA4fPgwAPHx8fz666/079/f8Z7j4uI4d+4cERERHDhwgJMnTwKwZMkSWrdunWfmqWzZsjzwwAPXHJvrtWPHDg4cOMD999/PuXPnHHlSUlK4/fbb+f333/O9zVFEpKjRbYciIiXY2bNnSUhIYN68ecybNy/fc/7atGHBggW89dZbREVFkZmZ6ThetWrVy56X37FclSpVyvN17g/658+fx9fX96qZr/ZcwFGE1ahRI895gYGBeQqKa+nVqxejRo0iIyODzZs389prr5GamnpZB8Y9e/YwYcIEfv3118uKx8TExGu+zoEDB9i7d+8VC9XraZpx3333cd9995GUlMTGjRuZP38+CxcupGfPnuzevRt3d3cOHTpE7dq1cXG59v/arzXGBw8exG6388ILL/DCCy9cMXeFChU4duwYrVq1uuzx2rVrXzPH9Tpw4AAAgwYNuuI5iYmJBfr+i4gYQcWXiEgJljsb8OCDD17xB9dGjRoB8J///IfBgwfTu3dvxo4dS3BwMBaLhddffz3fhg1XW9NjsVjyPW6326+Z+Z88tyAqVqxI586dAejevTtBQUGMGjWKTp060bdvXwASEhLo2LEjvr6+TJ48merVq+Pu7s62bdt45plnrmu2xWaz0bBhQ6ZNm5bv42FhYded2dfXly5dutClSxesVisLFixg48aNdOzY8bqvAdce49z39e9///uKnR//Xvz+E39tXpKf3DxTp069bO1hrtw1diIiRZmKLxGREqxs2bL4+PiQnZ3tKDSu5Msvv6RatWp8/fXXeW5TmzRpUmHHLJDKlSsDObMzf519O3funGPm5kY8+uijvP3220yYMIE+ffpgMplYtWoV586d4+uvv+aWW25xnHvkyJHLnv/3W/tyVa9encjISG6//fYrnnMjwsPDWbBgAadPn3a8zsaNG8nMzHQ0zbhR1apVA8BqtV7zc1O5cmXHzNRf7du377JjAQEBJCQk5DmWkZHheA9XktssxNfX95p5RESKMq35EhEpwSwWC3fffTdfffUVu3fvvuzxv7Zwz50N+esM08aNG1m/fn3hBy2A22+/HRcXF9577708x2fNmvWPruvi4sLTTz/N3r17+fbbb4H8xyQjI4N33333sud7eXnlexti//79OXnyJO+///5lj128eJGUlJQrZkpNTb3i+C9duhT48/a+u+++m7i4uHzHoaCzhsHBwdx6663MnTs338Lor5+b7t27s2HDBjZt2pTn8f/+97+XPa969er8/vvveY7NmzfvmjNfzZs3p3r16rz55ptcuHDhqnlERIoyzXyJiJQAH330EcuWLbvs+OjRo/m///s/Vq5cSatWrRg2bBj16tUjPj6ebdu28csvvxAfHw/AnXfeyddff02fPn3o0aMHR44cYc6cOdSrVy/fH3iNEhISwujRo3nrrbe466676NatG5GRkSxdupSgoKB/NLs0ePBgJk6cyBtvvEHv3r1p27YtAQEBDBo0iCeffBKTycSnn36abzHTvHlzPv/8c8aMGUOLFi3w9vamZ8+ePPTQQ3zxxReMGDGClStX0q5dO7Kzs4mKiuKLL77gp59+Ijw8PN88qamptG3bltatW9OtWzfCwsJISEhg8eLFrF69mt69e9O0aVMABg4cyCeffMKYMWPYtGkTHTp0ICUlhV9++YXHH3+cXr16FWgsZs+eTfv27WnYsCHDhg2jWrVqxMbGsn79eqKjo4mMjARg3LhxfPrpp3Tr1o3Ro0c7Ws1XrlyZnTt35rnmI488wogRI7j77rvp0qULkZGR/PTTTwQFBV01i9ls5oMPPuCOO+6gfv36DBkyhAoVKnDy5ElWrlyJr68v33//fYHen4iIIYxqsygiIv9cbnv2K/05ceKE3W6322NjY+0jR460h4WF2a1Wqz00NNR+++232+fNm+e4ls1ms7/22mv2ypUr293c3OxNmza1//DDD/ZBgwblaaGe26787y3Z7fY/W82fPXs235x/bTt+pVbzf2+b//e243Z7Tlv8F154wR4aGmr38PCw33bbbfa9e/fay5QpYx8xYsQ1xw2wjxw5Mt/HclvW577e2rVr7a1bt7Z7eHjYy5cvbx83bpz9p59+uizThQsX7Pfff7/d39/fDuQZs4yMDPsbb7xhr1+/vt3Nzc0eEBBgb968uf2ll16yJyYmXjFnZmam/f3337f37t3b8X3x9PS0N23a1D516tTLtgZITU21P//88/aqVas6vs/33HOP/dChQ3a7/erfO/JpA3/o0CH7wIED7aGhoXar1WqvUKGC/c4777R/+eWXec7buXOnvWPHjnZ3d3d7hQoV7C+//LL9ww8/vOx7np2dbX/mmWfsQUFBdk9PT3tERIT94MGD12w1n2v79u32vn372suUKWN3c3OzV65c2d6/f3/7ihUrrjiGIiJFicluv8krmEVERAyQkJBAQEAAr7zyCs8//7zRcURERC6jNV8iIlLsXLx48bJj06dPB+DWW291bhgREZHrpDVfIiJS7Hz++efMnz+f7t274+3tzZo1a/jf//5H165dadeundHxRERE8qXiS0REip1GjRrh4uLClClTSEpKcjTheOWVV4yOJiIickVa8yUiIiIiIuIEWvMlIiIiIiLiBCq+REREREREnEBrvm6QzWbj1KlT+Pj4/KMNPUVEREREpHiz2+0kJydTvnx5zOYrz2+p+LpBp06dIiwszOgYIiIiIiJSRJw4cYKKFSte8XEVXzfIx8cHyBlgX19fQ7NkZmby888/07VrV6xWq6FZSguNuXNpvJ1PY+58GnPn05g7l8bb+TTmzpOUlERYWJijRrgSFV83KPdWQ19f3yJRfHl6euLr66t/sZxEY+5cGm/n05g7n8bc+TTmzqXxdj6NufNdazmSGm6IiIiIiIg4gYovERERERERJ1DxJSIiIiIi4gRa8yUiIiIiJZ7dbicrK4vs7GyjozhNZmYmLi4upKWllar3XRgsFgsuLi7/eIspFV8iIiIiUqJlZGRw+vRpUlNTjY7iVHa7ndDQUE6cOKF9aW8CT09PypUrh6ur6w1fQ8WXiIiIiJRYNpuNI0eOYLFYKF++PK6urqWmELHZbFy4cAFvb++rbvwrV2e328nIyODs2bMcOXKEmjVr3vB4qvgSERERkRIrIyMDm81GWFgYnp6eRsdxKpvNRkZGBu7u7iq+/iEPDw+sVivHjh1zjOmN0HdBREREREo8FR/yT92Mz5A+hSIiIiIiIk6g4ktERERERMQJDC++Zs+eTZUqVXB3d6dVq1Zs2rTpqucvWrSIOnXq4O7uTsOGDVmyZEmex7/++mu6du1KmTJlMJlM7Nix47JrpKWlMXLkSMqUKYO3tzd33303sbGxN/NtiYiIiIiUWFWqVGH69OlGxyh2DC2+Pv/8c8aMGcOkSZPYtm0bjRs3JiIigjNnzuR7/rp167jvvvsYOnQo27dvp3fv3vTu3Zvdu3c7zklJSaF9+/a88cYbV3zdf/3rX3z//fcsWrSI3377jVOnTtG3b9+b/v5ERERERG7U4MGD6d27t9Ex8rV582aGDx9e6K9TpUoVTCYTJpMJT09PGjZsyAcffFDg65hMJhYvXnzzAxaQocXXtGnTGDZsGEOGDKFevXrMmTMHT09PPvroo3zPnzFjBt26dWPs2LHUrVuXl19+mWbNmjFr1izHOQ899BATJ06kc+fO+V4jMTGRDz/8kGnTpnHbbbfRvHlzPv74Y9atW8eGDRsK5X2KiIiIiBQHmZmZ13Ve2bJlndY9cvLkyZw+fZrdu3fz4IMPMmzYMJYuXeqU177ZDGs1n5GRwdatWxk/frzjmNlspnPnzqxfvz7f56xfv54xY8bkORYREVGgKnbr1q1kZmbmKc7q1KlDpUqVWL9+Pa1bt873eenp6aSnpzu+TkpKAnI+oNf7IS0sua9vdI6ibv76Y3wfeRo/DysBnq4EeuX8HeBlJfDS3znHXfH3sGIxX3kPEI25c2m8nU9j7nwac+fTmDuXUeOdmZmJ3W7HZrNhs9mAnH2bLmZmOzUHgIfVUqA9xux2uyN7fnbv3s24ceNYs2YNXl5edOnShWnTphEUFATA0qVLefnll4mKisJisdC6dWumT59O9erVATh69CjVq1dn4cKFzJkzh40bN/Luu+/y22+/kZCQQPv27Zk2bRoZGRkMGDCAt99+G6vVCkC1atUYPXo0o0ePBsBisTB37lyWLFnCzz//TIUKFZg6dSp33XWXI+93333H2LFjOXHiBG3atGHgwIE8/PDDnDt3Dn9//yuOg7e3N8HBwQCMHTuWKVOm8PPPPxMREQHkzMI9//zz7Nixg8zMTJo0acJbb71Fs2bNHFkB+vTpA0DlypU5fPgwAN9++y0vv/wyf/zxB+XLl2fgwIE899xzuLhcXibZbDbsdjuZmZlYLJY8j13v59qw4isuLo7s7GxCQkLyHA8JCSEqKirf58TExOR7fkxMzHW/bkxMDK6urpd9g691nddff52XXnrpsuM///xzkdkzYvny5UZHKLJsdnhzk4V02/X9B8+EHQ8X8HYBLyt4u9jxtoKXC3hb7XhZwcvFxLFvljvOcTNDKdmz0TD6jDufxtz5NObOpzF3LmePt4uLC6GhoVy4cIGMjAwALmZk02aa8+94Wj+mNR6ulmufeElmZiZZWVmOX/r/VWJiIrfffjsPPfQQkydPJi0tjRdffJF77rmH7777DoBz584xcuRI6tevT0pKCq+99hq9e/dm9erVmM1mLly4AMCzzz7LK6+8wsyZM3Fzc+OXX35h5cqVlClThm+//ZbDhw8zdOhQateuzaBBg4CcQiQtLS1PtpdeeomXXnqJiRMnMm/ePB566CF27txJQEAAx44do3///jz66KMMHDiQnTt3MmHCBACSk5Ov2Mb9r69js9n44YcfOH/+PHa73fHasbGx9OvXj9deew273c7s2bPp0aMHW7ZswcfHh19++YWaNWsye/Zsbr/9diwWC0lJSaxbt45Bgwbxxhtv0KZNG44cOcJTTz1Feno6zzzzzGVZMjIyuHjxIr///jtZWVl5HktNTb2u76k2Wb5O48ePzzPrlpSURFhYGF27dsXX19fAZDn/Yi5fvpwuXbo4fhshee2PTSZ9w3q8XC1MvLMO51MziU/J4HxqJudTMoh3/J1B4sUs7JhIzYLULCAN4NpVlauLmQDPvLNqgV6uBHhaCfS0XvrnS197ueLvacVqMbznTbGgz7jzacydT2PufBpz5zJqvNPS0jhx4gTe3t6OjXFdMrKu8azC4ePrg6fr9f/4bbVacXFxyfdnzXfeeYemTZvy5ptvOo7Nnz+fypUrExMTQ61atXjggQdITk7Gx8cHk8nEggULCAkJITo6mgYNGuDt7Q3k9EN44IEH8rxuYGAgc+fOxWKxEB4ezldffcW6det44okngJw71tzd3fNkGzJkCA8//DAAU6dOZe7cuezdu5du3bqxcOFCateuzYwZMwBo3rw5hw8f5rXXXsPHx+eKP0+bzWZefPFFXn31VdLT08nKyiIwMJDHH3/c8Zw777wzz3M++ugjAgMD2b59O3feeafjvNDQUGrWrOk4b9q0aTz77LM8+uijADRq1Ijk5GSeffZZXn311cuypKWl4eHhwS233HLZJsv5Fcj5Maz4CgoKwmKxXNZlMDY2ltDQ0HyfExoaWqDzr3SNjIwMEhIS8sx+Xes6bm5uuLm5XXbcarUWmf9gF6UsRc2e0ykANKzox4CWVa56bla2jYSLOcVZfEoG51MyOHfp7/jUnGPnLqRz9HQc2S4exKdkkJ5lIyPLRmxSOrFJ6Ve9/l/5uLtQzs+dZpUCaFElkBZVAgkL9CjQLQmliT7jzqcxdz6NufNpzJ3L2eOdnZ2NyWTCbDY7Zle83Kz8MTnCaRlyFfS2w9xGE/nNCu3cuZNVq1blW7QcOXKEOnXqsG/fPp577jm2b99OXFyc4/bF6OhoGjVq5LhuixYt8ryGyWSifv36eb5P5cuXZ9euXZed99evGzdu7Pg6t6CKi4vDbDazf//+y16nVatWAHm+N/kZO3YsgwcP5vTp04wdO5bHH3+cWrVqOR6PjY1lwoQJrFq1ijNnzpCdnU1qairR0dF5rvv314mMjGTt2rW89tprjmPZ2dmkpaWRlpZ22d1tZrMZk8mU72f4ej/ThhVfrq6uNG/enBUrVji6uNhsNlasWMGoUaPyfU6bNm1YsWIFTz31lOPY8uXLadOmzXW/bvPmzbFaraxYsYK7774bgH379nH8+PECXUeKlx3RCQA0DvO/5rkuFjNB3m4EeV9ebOfKzMxkyZIldO9+C1arldSMrEuFWibnUtI5n5pBfEom8Snpjr/Pp2Q6irfzqRnY7ZCclkVy2gX2x17gs80nAAjxdSO8SiAtKgfQomogdUJ9r7r+TERERArGZDIVaAaqKLpw4QI9e/bMt8N3uXLlAOjVqxcVKlRg7ty5VKxYEZvNRoMGDRy3X+by8vK67Bp/LyZMJtMV1579k+dcj6CgIGrUqEGNGjVYtGgRDRs2JDw8nHr16gEwaNAgzp07x4wZM6hcuTJubm60adPmsvf5dxcuXOCll17Kt+v532e2bhZDP3Vjxoxh0KBBhIeH07JlS6ZPn05KSgpDhgwBYODAgVSoUIHXX38dgNGjR9OxY0feeustevTowWeffcaWLVuYN2+e45rx8fEcP36cU6dOATmFFeTMeIWGhuLn58fQoUMZM2YMgYGB+Pr68sQTT9CmTZsrNtuQ4i/yRAIATSr6F8r1PV1d8HR1oWLA9Z2fbbOTdDGTcykZHIlLYcuxeDYfiWfXyURik9L5cedpftx5GgAfNxeaVQ6gRZWc2bHGYf64W6//fnEREREpeZo1a8ZXX31FlSpV8m0Oce7cOfbt28e0adO4/fbbMZvNrFmzxoCkOWrXrn3Z/rybN28u8HXCwsIYMGAA48eP59tvvwVg7dq1vPvuu3Tv3h2AEydOEBcXl+d5VquV7Oy8TVaaNWvGvn37qFGjRoFz3ChDi68BAwZw9uxZJk6cSExMDE2aNGHZsmWOphrHjx/PMzXYtm1bFi5cyIQJE3juueeoWbMmixcvpkGDBo5zvvvuO0fxBnDvvfcCMGnSJF588UUA3n77bcxmM3fffTfp6elERETw7rvvOuEdixEuZmQTFZMMXN/MlzNYzCYCvFwJ8HKlRrA3XerlfObTMrPZcSKBLUfj2Xz0PFuPnSc5PYvf9p/lt/1nAbBaTDSq6E94lQBaVA4kvEoA/p6uRr4dERERKSSJiYns2LEjz7EyZcowcuRI3n//fe677z7GjRtHYGAgBw8e5LPPPuODDz4gICCAMmXKsGDBAmrUqEF0dDTPPvusMW8CePTRR5k2bRrPPPMMQ4cOZceOHcyfPx+gwMstRo8eTYMGDdiyZQvh4eHUrFmTTz/9lPDwcJKSkhg7diweHh55nlOlShVWrFhBu3btcHNzIyAggIkTJ3LnnXdSqVIl7rnnHsxmM5GRkezevZtXXnnlZr31PAyfbx01atQVbzNctWrVZcf69etHv379rni9wYMHM3jw4Ku+pru7O7Nnz2b27NkFiSrF1J5TiWTb7AT7uFHOr3CmkG8Wd6uF1tXK0LpaGSBnhiwqJonNR+LZfOw8m4/EcyY5na3HcgqzueS0Sa0V4u1YMxZeJYCKAUWjA6eIiIj8M6tWraJp06Z5jg0dOpQPPviAtWvX8swzz9C1a1fS09OpXLky3bp1c6xNWrhwIU8++SSNGjWidu3azJw5k1tvvdWQ91G1alW+/PJLnn76aWbMmEGbNm14/vnneeyxx/Ltq3A19erVo2vXrkycOJElS5bw4YcfMnz4cJo1a0ZYWBivvfYa//73v/M856233mLMmDG8//77VKhQgaNHjxIREcEPP/zA5MmTeeONN7BardSpU4dHHnnkZr71PAwvvkQK245Ltxw2DvMvdo0sLGYT9cv7Ub+8H4PbVcVut3Mi/iKbj8Y7/hw6m8L+2Jx1Y//deByA8n7uOevGqgbSokoAtYJ9MGvdmIiISLEyf/58x+xQfmrWrMnXX399xcc7d+7Mhg0b8PX1ddxNZrfbHY9XqVIlz9d/fd2/mz59ep6vjx49mufr/K6TkJCQ5+u77rorz75fr776KhUrVrzq+qq/v06uZcuWOf65adOml93CeM899+T5umfPnvTs2fOy60RERDj2C3MGFV9S4kVGJwLQpIjccvhPmEwmKpXxpFIZT+5uXhGAcxfS2XJpVmzzsfPsOZnIqcQ0vos8xXeROWsffd1dCL80K9aySiANK/rh5qJ1YyIiIuI87777Li1atKBMmTKsXbuWqVOnXvEOuJJKxZeUeDtOnAegcSE12zBaGW83IuqHElE/Z6uE1IwsdhxPYPPR82w+Gs+24+dJSsvi16gz/Bp1BsjZk6xxRT/HrYrNKgfg56E2yyIiIlJ4Dhw4wCuvvEJ8fDyVKlXi6aefZvz48UbHcioVX1KinbuQzon4iwA0CvMzOI1zeLq60LZGEG1rBAE5+5btPZ3MpqPxlxp5xBN3IeNScXYeOITJBLVDfHKKsaqBtKwSSGgRXx8nIiIixcvbb7/N22+/bXQMQ6n4khJt56VbDquX9cLXvXTO7LhYzDSs6EfDin4MbZ+zbuzoudSc2xSPxrPl2HmOxKUQFZNMVEwyn244BkDraoH0Dw/jjgbl8HDVLYoiIiIi/5SKLynR/tpsQ3KYTCaqBnlRNciL/i3CADiTnMbWo+cvzY6dZ/epRDYcjmfD4XgmfbuHnk3KMyA8jEYV/Ypd0xIRERHIvyGESEHcjM+Qii8p0XKLr5LQbKMwBfu4c0fDctzRsBwAJxMu8tXWaL7YcoLo8xdZuPE4Czcep3aID/3CK9KnaQXKeBesLayIiIgRrNacO19SU1Mv2/tJpCBSU1OBPz9TN0LFl5RYdrudyOgEQMVXQVXw9+DJ22syqlMNNhw+xxdbTrB0dwz7YpN55ce9vLEsis51Q+jfIoxbapbFojb2IiJSRFksFvz9/TlzJqfplKenZ6m5i8Nms5GRkUFaWpqj1bwUnN1uJzU1lTNnzuDv74/FcuPLMVR8SYl1PD6VhNRMXC1m6oT6Gh2nWDKbTY7mHS9dzOS7yFMs2nKCndGJLN0dw9LdMYT6unN38wr0Dw+jchkvoyOLiIhcJjQ0pyNwbgFWWtjtdi5evIiHh0epKTgLk7+/v+OzdKNUfEmJlXvLYb3yvri66Lc9/5Sfh5WHWlfmodaV+eNUEou2nuCb7SeJSUpj9spDzF55iFZVAxnQQk06RESkaDGZTJQrV47g4GAyMzONjuM0mZmZ/P7779xyyy3/6FY5ybnV8J/MeOVS8SUlVuSJkrO5clFTr7wvk8rX59k76vDLH2f4YssJfj9wlo1H4tl4JKdJx52NyzOgRRiN1aRDRESKCIvFclN+gC4uLBYLWVlZuLu7q/gqIlR8SYmVu7myiq/C4+ZioUejcvRoVI5TuU06tp7gRPxF/rfpOP/bdJxaId70Dw9Tkw4REREp9VR8SYmUmW1j96kkQG3mnaW8vwdP3F6TkZ1qsOHIORZtiWbJrtPsj73gaNJxe50QBrQIo0PNIFwsuhVUREREShcVX1Ii7YtJJiPLhq+7C1XKeBodp1Qxm020rR5E2+pBvHhXfb6/1KQjMjqRZXtiWLYnhhBfN+5pXpF+zcOoEqQmHSIiIlI6qPiSEumvmytrvZFx/DysPNi6Mg+2rkxUTBJfbI7mm+3RxCalO5p0tKwayIDwMO5oGIqnq/6TJCIiIiWXftKREim3+GqqWw6LjDqhvkzsWY9n7qjNir2XmnTsP8umI/FsOhLPpO/20LNxefqHV6SJimYREREpgVR8SYkU+ZeZLyla3FwsdG9Yju4Ny3E68VKTji3RHI9PvaxJR++mFQhSkw4REREpIVR8SYmTnJbJwbMXAGhU0d/YMHJV5fw8GHVbTR6/tQYbj8SzaMsJluz+s0nH/y2NonPdEPo2LUe23ei0IiIiIv+Mii8pcXadTMRuhwr+HpT10axJcWA2m2hTvQxtqpfhxV45TTq+2BJN5IkER5MOP6uFuIBjDGxbFXdr6dmjRUREREoO9XqWEid3vVeTSv6G5pAb4+tu5YFWlfl2ZDt+euoWhravSoCnlcRME68t3UenN1excONxMrNtRkcVERERKRAVX1Li5K73aqJbDou92qE+vHBnPdaM7ciAatmE+rpxOjGN577ZRedpv7F4+0mybbofUURERIoHFV9S4kSeSATUbKMkcXUx0zbEzi9PtWfinfUI8nbl2LlUnvp8B3fM+J1lu2Ow21WEiYiISNGm4ktKlJjENGKS0rCYTTSo4Gt0HLnJ3KwWHm5fld/GdmJsRG183V3YH3uBEf/Zyl2z1rJq3xkVYSIiIlJkqfiSEiV3vVetEB9t2FuCebm5MLJTDVY/cxtP3FYDT1cLu04mMvjjzQyYu4GNh88ZHVFERETkMiq+pESJjE4AoEmYn7FBxCn8PKw83bU2q8d14pH2VXF1MbPpaDwD5m3goQ83svPS50FERESkKFDxJSWKY3NlNdsoVcp4uzHhznr8PrYTD7SqhIvZxOoDcdw1ay2PfrqFfTHJRkcUERERUfElJYfNZmdntJptlGahfu682qchvz59K32bVcBsgp/2xNJtxu+M/mw7R+NSjI4oIiIipZiKLykxDp29wIX0LDxdLdQK8TE6jhioUhlPpvVvwk9P3UL3hqHY7fDtjlPcPu03xn+9k1MJF42OKCIiIqWQii8pMXKbbTSo4IfFbDI2jBQJNUN8ePeB5vzwRHs61S5Lts3O/zad4Napq3jp+z2cTU43OqKIiIiUIiq+pMT4s9mGv6E5pOhpUMGPj4e05MsRbWhVNZCMbBsfrz3KLVNWMmVZFImpmUZHFBERkVJAxZeUGI7NldVsQ64gvEognw1vzadDW9K4oh8XM7N5d9Uh2k/5lZkrDnAhPcvoiCIiIlKCqfiSEiEtM5u9p5MAaKw283IVJpOJDjXLsnhkO+Y91Jw6oT4kp2Uxbfl+bpmykg9WHyYtM9vomCIiIlICqfiSEmHPqSSybHaCvN2o4O9hdBwpBkwmE13rh7LkyQ7MuLcJVYO8iE/J4JUf99Jx6kr+s+EYGVk2o2OKiIhICaLiS0qE3P29moT5YTKp2YZcP7PZRK8mFVj+r1t44+6GlPdzJzYpnQmLd3P7tFV8tTWabJvd6JgiIiJSAqj4khIht9mG1nvJjXKxmBnQohIrx97Kiz3rEeTtxon4izy9KJKI6b+zZNdpbCrCRERE5B9Q8SUlQm6beW2uLP+Um4uFwe2q8vu4W3mmWx38PKwcPHOBx/+7jZ6z1rAy6gx2u4owERERKTgVX1LsnU/J4Ni5VEAzX3LzeLq68Nit1Vn9TCeevL0mXq4W9pxKYsj8zdwzZz3rD50zOqKIiIgUMyq+pNjLveWwWpAXfp5WY8NIiePrbmVMl1qsfuY2ht9SDTcXM1uPnee+9zfw4AcbiYpJMjqiiIiIFBMqvqTYc+zvpVsOpRAFernyXPe6/D6uEw+1rozVYmLNwTjunLmGN3/ap/b0IiIick0qvqTY23HiPACNK2p/Lyl8Ib7uvNy7Ab8+fStd64WQZbMza+VBus9YzYbDuhVRRERErkzFlxRrdrudyOicma8mlQIMTiOlSVigJ/MGhjPnwWaU9XHjcFwK987bwLNf7SQxNdPoeCIiIlIEqfiSYi36/EXiUzKwWkzULedjdBwphbo1KMcvYzpyX8tKAHy2+QS3T/uNH3eeVldEERERyUPFlxRruS3m65Xzxc3FYmwYKbX8PKy83rchnw9vTbWyXsRdSGfkwm0M+2QLpxMvGh1PREREiggVX1KsaX8vKUpaVSvDkic78ORtNbBaTPyy9wxdpv3OJ+uPaoNmERERUfElxVvkpeKriYovKSLcrRbGdK3ND090oGklfy6kZzHx2z3cM2cd+2OTjY4nIiIiBlLxJcVWZraN3afUZl6KptqhPnw5oi0v3VUfL1cL244n0GPmaqb9rLb0IiIipZWKLym29scmk5Zpw8fdhaplvIyOI3IZi9nEoLZVWD6mI53rBpOZbWfmrwfpPnM1m47EGx1PREREnEzFlxRbjvVeFf0xm03GhhG5ivL+Hrw/MJzZ9zcjyNuNw2dT6D93PeO/3kXiRbWlFxERKS1UfEmxpfVeUpyYTCZ6NCrHijEdubdFGAD/23ScLtN+Y9nu0wanExEREWdQ8SXFVuQJrfeS4sfP08r/3d2I/w1rTdUgL84kpzPiP9sY/skWYhLTjI4nIiIihUjFlxRLF9Kz2H8mp3Nc44p+BqcRKbg21cuwdHQHRnWqgYvZxM9/xNJl2m98uuGY2tKLiIiUUCq+pFjaFZ2I3Q7l/dwJ9nU3Oo7IDXG3Wvh3RG1+eLI9jcP8SU7P4oXFu+k/dz0H1JZeRESkxFHxJcVSZHQCAE0q+RuaQ+RmqBPqy9ePtWVSz3p4ulrYcuw83Weu5u3l+0nPUlt6ERGRkkLFlxRLkX/pdChSEljMJoa0q8ryMR25rU5OW/oZKw7QY+YathxVW3oREZGSQMWXFEuO4kvNNqSEqeDvwYeDwnnnvqYEebty8MwF7pmzngmLd5GUprb0IiIixZmKLyl2ziSlcSoxDbMJGlZQsw0peUwmEz0bl+eXMR3p17wiAP/ZkNOW/qc9MQanExERkRul4kuKndzNlWuF+ODl5mJsGJFC5O/pytR+jVn4SCsql/EkNimdRz/dyohPtxKbpLb0IiIixY2KLyl2cpttaL2XlBZtawTx01O38Nit1bGYTSzbE0Pnab/x341qSy8iIlKcqPiSYkebK0tp5G618Ey3Onw/qj2NKvqRnJbF89/s5t55Gzh45oLR8UREROQ6GF58zZ49mypVquDu7k6rVq3YtGnTVc9ftGgRderUwd3dnYYNG7JkyZI8j9vtdiZOnEi5cuXw8PCgc+fOHDhwIM85+/fvp1evXgQFBeHr60v79u1ZuXLlTX9vcvPZbPa/NNvQei8pfeqV9+Wbx9sxoUddPKwWNh2Np/uM1cxccYCMLJvR8UREROQqDC2+Pv/8c8aMGcOkSZPYtm0bjRs3JiIigjNnzuR7/rp167jvvvsYOnQo27dvp3fv3vTu3Zvdu3c7zpkyZQozZ85kzpw5bNy4ES8vLyIiIkhL+3N9xJ133klWVha//vorW7dupXHjxtx5553ExGghe1F3OC6F5PQs3K1maof4GB1HxBAWs4lHOlTj53/dQsdaZcnItjFt+X7ufGc1W4+dNzqeiIiIXIGhxde0adMYNmwYQ4YMoV69esyZMwdPT08++uijfM+fMWMG3bp1Y+zYsdStW5eXX36ZZs2aMWvWLCBn1mv69OlMmDCBXr160ahRIz755BNOnTrF4sWLAYiLi+PAgQM8++yzNGrUiJo1a/J///d/pKam5inipGjKnfVqWMEPF4vhE7cihgoL9GT+kBbMuLcJgV6u7I+9wD1z1vHakr2aBRMRESmCDGsVl5GRwdatWxk/frzjmNlspnPnzqxfvz7f56xfv54xY8bkORYREeEorI4cOUJMTAydO3d2PO7n50erVq1Yv3499957L2XKlKF27dp88sknNGvWDDc3N+bOnUtwcDDNmze/Yt709HTS09MdXyclJQGQmZlJZqaxe+/kvr7ROZxh+/GczWYblvc19P2WpjEvCjTeV9e9fjBtqvrz+rL9fLP9FPN+P8yGQ3G83b8RlQI9b+iaGnPn05g7n8bcuTTezqcxd57rHWPDiq+4uDiys7MJCQnJczwkJISoqKh8nxMTE5Pv+bm3C+b+fbVzTCYTv/zyC71798bHxwez2UxwcDDLli0jICDginlff/11XnrppcuO//zzz3h63tgPNzfb8uXLjY5Q6H7bbQFMZJ89zJIlh4yOUyrGvCjReF/dre4QUMvEZ4fM7DyZRPeZq7m3mo1mQTfeEVFj7nwac+fTmDuXxtv5NOaFLzU19brOK3WbJNntdkaOHElwcDCrV6/Gw8ODDz74gJ49e7J582bKlSuX7/PGjx+fZ9YtKSmJsLAwunbtiq+vr7Pi5yszM5Ply5fTpUsXrFaroVkKU3pmNv/e9CtgZ1DPjoQFGFf0lpYxLyo03tevOzAo4SJjFu1i6/EEFhywkOJTgRd61MbT9fr/k68xdz6NufNpzJ1L4+18GnPnyb0r7loMK76CgoKwWCzExsbmOR4bG0toaGi+zwkNDb3q+bl/x8bG5imiYmNjadKkCQC//vorP/zwA+fPn3cUTe+++y7Lly9nwYIFPPvss/m+tpubG25ubpcdt1qtRebDXJSyFIbdpy+QmW2njJcrVcv6YjKZjI5U4se8qNF4X5/KZa18/mgbZqw4wKyVB/ly20m2n0hg1v3NqFuuYL8s0pg7n8bc+TTmzqXxdj6NeeG73vE1rGOBq6srzZs3Z8WKFY5jNpuNFStW0KZNm3yf06ZNmzznQ840au75VatWJTQ0NM85SUlJbNy40XFO7pSg2Zz3rZvNZmw2LVAvyv5sMe9fJAovkaLMxWLm6a61+e/QVgT7uHHobAq9Zq/l0/VHsdu1MbOIiIgRDG0XN2bMGN5//30WLFjA3r17eeyxx0hJSWHIkCEADBw4ME9DjtGjR7Ns2TLeeustoqKiePHFF9myZQujRo0CctZzPfXUU7zyyit899137Nq1i4EDB1K+fHl69+4N5BRwAQEBDBo0iMjISPbv38/YsWM5cuQIPXr0cPoYyPXbkVt8VfQ3NIdIcdK2RhBLR3egU+2yZGTZeOHbPYz4z1YSU7X4WkRExNkMXfM1YMAAzp49y8SJE4mJiaFJkyYsW7bM0TDj+PHjeWao2rZty8KFC5kwYQLPPfccNWvWZPHixTRo0MBxzrhx40hJSWH48OEkJCTQvn17li1bhru7O5Bzu+OyZct4/vnnue2228jMzKR+/fp8++23NG7c2LkDIAUSGZ0IaHNlkYIq4+3Gh4Na8NHaI7yxLIqf9sSy++RqZtzbhPAqgUbHExERKTUMb7gxatQox8zV361ateqyY/369aNfv35XvJ7JZGLy5MlMnjz5iueEh4fz008/FTirGCchNYMjcSkANAnzNzaMSDFkvrQxc8uqgTzxv+0cO5fKgHkbGNOlFiM6Vsdi1q28IiIihU271EqxsPPSrFeVMp74e7oanEak+GpU0Z8fnmhPryblybbZmfrTPh76cCOxSWlGRxMRESnxVHxJsfDXZhsi8s/4uFuZPqAJU+9phIfVwrpD57hjxmpW7jtjdDQREZESTcWXFAtqtiFyc5lMJvqFh/H9E+2pE+pDfEoGQz7ezKs//kFGljq/ioiIFAYVX1Lk2e12IqMTAGhSyd/QLCIlTY1gbxaPbMfANpUBeH/1Ee6Zs45j8akGJxMRESl5VHxJkXcy4SJxFzJwMZuoV8ANYkXk2tytFib3asDch5rj52FlZ3Qivd5dz9Y4NeEQERG5mVR8SZEXeSKn2Ubdcr64Wy0GpxEpuSLqh7JkdAdaVAkgJT2bTw5YGP/NHlIzsoyOJiIiUiKo+JIib8eJ84D29xJxhgr+HvxvWGtG3loNE3a+3HaSnu+sYe/pJKOjiYiIFHsqvqTIy535ahIWYHASkdLBxWLmqdtrMLKejWAfNw6dTaHX7LV8uv4odrvd6HgiIiLFloovKdKysm3sOplbfGnmS8SZavrZ+W5kGzrVLktGlo0Xvt3DiP9sJSE1w+hoIiIixZKKLynSDpy5wMXMbLzdXKgW5G10HJFSp4yXKx8NbsGEHnWxWkz8tCeW7jNWs+VovNHRREREih0VX1Kk5e7v1aiiH2azOq+JGMFkMvFIh2p8/Vg7Kpfx5FRiGgPmbWDWrwfItuk2RBERkeul4kuKtMhLxVeTMH9Dc4gINKzoxw9PtKdXk/Jk2+y8+fN+HvpwI7FJaUZHExERKRZUfEmRljvz1VjFl0iR4ONuZfqAJky9pxEeVgvrDp3jjhmrWRl1xuhoIiIiRZ6KLymyUjOy2B+bDGjmS6QoMZlM9AsP4/sn2lO3nC/xKRkMmb+ZV374g4wsm9HxREREiiwVX1Jk7YpOxGaHUF93QnzdjY4jIn9TI9ibbx5vy6A2lQH4YM0R7pmzjqNxKQYnExERKZpUfEmRFRmdAGjWS6Qoc7daeKlXA+Y91Bw/Dys7oxO58501fLvjpNHRREREihwVX1Jk5W6urPVeIkVf1/qhLB3dgRZVAriQnsXoz3YwdlEkqRlZRkcTEREpMlR8SZH1Z7MNba4sUhyU9/fgf8Na8+TtNTGZYNHWaHq+s4Y/TiUZHU1ERKRIUPElRdLZ5HROJlzEZIKGFVR8iRQXLhYzY7rU4r+PtCLE141DZ1Po/e5aFm48bnQ0ERERw6n4kiIpd3+vmsHe+LhbjQ0jIgXWtnoQS57sQKfaZcnIsvHcN7sY//UudUMUEZFSTcWXFEm5zTYaV/Q3NIeI3Lgy3m58NLgFYyNqYzLB/zYd5773N3BGmzKLiEgppeJLiiRtrixSMphMJkZ2qsFHg1vg4+7C1mPn6TlrDduPnzc6moiIiNOp+JIix2azO247VJt5kZKhU+1gvhvVnhrB3sQmpTNg7ga+2HzC6FgiIiJOpeJLipyj51JISsvCzcVM7VAfo+OIyE1SNciLbx5vS9d6IWRk2xj31U4mfrubzGytAxMRkdJBxZcUObnrvRpU8MNq0UdUpCTxcbcy58Hm/KtzLQA+WX+MBz7YSNyFdIOTiYiIFD79ZCtFjmNzZTXbECmRzGYTozvX5P2B4Xi7ubDpSDx3vbOGXdGJRkcTEREpVCq+pMjZrs2VRUqFLvVCWDyyHdWCvDiVmMY9c9bx9bZoo2OJiIgUGhVfUqSkZ2Wz91QSAE3DAgxOIyKFrUawN4tHteO2OsGkZ9kY80UkL//wB1laByYiIiWQii8pUqJOJ5ORbSPA00pYoIfRcUTECXzdrXwwMJwnbqsBwIdrjjDwo03Ep2QYnExEROTmUvElRYpjc+Uwf0wmk7FhRMRpzGYTT3etzZwHm+HpamHdoXP0fGcNe05pHZiIiJQcKr6kSNlxPAFQsw2R0qpbg3J883g7Kpfx5GTCRe5+bx3fRZ4yOpaIiMhNoeJLipQdl2a+tLmySOlVO9SH70a255ZaZUnLtPHk/7bz+tK9ZNvsRkcTERH5R1R8SZGReDGTw2dTgJzbDkWk9PLztPLx4BaM6FgdgLm/HWbwx5tISNU6MBERKb5UfEmRkbvHT6VATwK9XA1OIyJGs5hNPHtHHd65rynuVjOrD8Rx16y1RMUkGR1NRETkhqj4kiJjx4nzgGa9RCSvno3L8/Vj7agY4MHx+FT6vruOpbtOGx1LRESkwFR8SZGx40TOzFfjitpcWUTyqlfel+9HtaddjTKkZmTz2H+38eZP+7BpHZiIiBQjKr6kSLDb7ew4kQBA00r+hmYRkaIpwMuVBUNa8kj7qgDMWnmQRz7ZQuLFTIOTiYiIXB8VX1IknE5MI+5COhazifrlNfMlIvlzsZiZcGc93h7QGDcXM79GnaHP7LUcPJNsdDQREZFrUvElRULurFedUB/crRZjw4hIkdenaUW+HNGW8n7uHI5LoffsdSz/I9boWCIiIlel4kuKhMhLxZeabYjI9WpY0Y/vnmhPq6qBXEjPYtgnW5j+y36tAxMRkSJLxZcUCbkzX9pcWUQKIsjbjf880orBbasAMP2XAzz6n60kp2kdmIiIFD0qvsRw2TY7u07mdDpU8SUiBWW1mHnxrvpMuacRrhYzy/+Ipc+76zh89oLR0URERPJQ8SWGO3AmmdSMbLxcLVQv6210HBEppvqHh/HFiDaE+rpz8MwFes1ey8qoM0bHEhERcVDxJYbLXe/VsKIfFrPJ2DAiUqw1CfPnuyfaEV45gOS0LB5esJnZKw9it2sdmIiIGE/Flxgud3PlJmEBBicRkZIg2MedhcNa80CrStjtMPWnfYxcuI2U9Cyjo4mISCmn4ksMF+lotqH9vUTk5nB1MfNqn4a83rchVouJJbti6PvuOo6dSzE6moiIlGIqvsRQFzOy2Rebszmq2syLyM12X8tKfDa8NWV93NgXm8xds9ay+sBZo2OJiEgppeJLDLX7VCLZNjvBPm6E+robHUdESqDmlQP54Yn2NAnzJ/FiJoM+2sS83w9pHZiIiDidii8xVORf9vcymdRsQ0QKR4ivO58/2pr+4RWx2eG1JVH86/MdpGVmGx1NRERKERVfYqjczZV1y6GIFDY3Fwtv3N2Il3vVx8VsYvGOUzzwwUbOXUg3OpqIiJQSKr7EUDv+MvMlIlLYTCYTD7WpwoKHW+Lr7sLWY+fp/e5aDlxaeyoiIlKY/lHxlZaWdrNySCkUdyGd6PMXMZly9vgSEXGWdjWC+PrxdlQu48mJ+Iv0fXedGnGIiEihK3DxZbPZePnll6lQoQLe3t4cPnwYgBdeeIEPP/zwpgeUkmtndAIA1ct64+tuNTaMiJQ6NYK9+ebxdrSsEkhyehaDP97MfzYcMzqWiIiUYAUuvl555RXmz5/PlClTcHV1dRxv0KABH3zwwU0NJyVb7ubKjSv6GxtEREqtQC9XPn2kJX2bVSDbZmfC4t1M/v4Psm3qhCgiIjdfgYuvTz75hHnz5vHAAw9gsVgcxxs3bkxUVNRNDScl2w5triwiRYCbi4W3+jVmbERtAD5ae4Thn2zhQnqWwclERKSkKXDxdfLkSWrUqHHZcZvNRmZm5k0JJSWf3W53tJlXp0MRMZrJZGJkpxrMvr8Zbi5mVkSd4Z731nEy4aLR0UREpAQpcPFVr149Vq9efdnxL7/8kqZNm96UUFLyHTuXSuLFTFxdzNQJ9TU6jogIAD0alePzR9sQ5O1GVEwyvWatdczSi4iI/FMuBX3CxIkTGTRoECdPnsRms/H111+zb98+PvnkE3744YfCyCglUOSlZhv1y/vi6qIdD0Sk6GgS5s+3o9oxdP5momKSGTB3PW8PaEL3huWMjiYiIsVcgX/q7dWrF99//z2//PILXl5eTJw4kb179/L999/TpUuXwsgoJZBjc2U12xCRIqiCvwdfPtaW2+oEk55l4/H/bmP2yoPY7WrEISIiN+6Gphw6dOjA8uXLOXPmDKmpqaxZs4auXbveUIDZs2dTpUoV3N3dadWqFZs2bbrq+YsWLaJOnTq4u7vTsGFDlixZkudxu93OxIkTKVeuHB4eHnTu3JkDBw5cdp0ff/yRVq1a4eHhQUBAAL17976h/HJjtLmyiBR13m4uvD8wnCHtqgAw9ad9/HvRTtKzso0NJiIixVaBi69q1apx7ty5y44nJCRQrVq1Al3r888/Z8yYMUyaNIlt27bRuHFjIiIiOHPmTL7nr1u3jvvuu4+hQ4eyfft2evfuTe/evdm9e7fjnClTpjBz5kzmzJnDxo0b8fLyIiIiIs+G0F999RUPPfQQQ4YMITIykrVr13L//fcXKLvcuIwsG3tOJQEqvkSkaLOYTUzqWZ+XezfAYjbx1bZoHvpgE/EpGUZHExGRYqjAxdfRo0fJzr78t37p6emcPHmyQNeaNm0aw4YNY8iQIdSrV485c+bg6enJRx99lO/5M2bMoFu3bowdO5a6devy8ssv06xZM2bNmgXkzHpNnz6dCRMm0KtXLxo1asQnn3zCqVOnWLx4MQBZWVmMHj2aqVOnMmLECGrVqkW9evXo379/wQZCbti+mGQysmz4eVipXMbT6DgiItf0UOvKfDy4BT5uLmw6Gk+fd9dy6OwFo2OJiEgxc90NN7777jvHP//000/4+f25N1N2djYrVqygSpUq1/3CGRkZbN26lfHjxzuOmc1mOnfuzPr16/N9zvr16xkzZkyeYxEREY7C6siRI8TExNC5c2fH435+frRq1Yr169dz7733sm3bNk6ePInZbKZp06bExMTQpEkTpk6dSoMGDa6YNz09nfT0dMfXSUk5MzeZmZmGt9jPfX2jc1yvrcdyZk4bVfAlK6t47qNT3Ma8uNN4O5/G/HJtqvrz+fCWDP/Pdo6dS6XP7LXMuq8xbaqVuSnX15g7n8bcuTTezqcxd57rHePrLr5y10SZTCYGDRqU5zGr1UqVKlV46623rjtgXFwc2dnZhISE5DkeEhJyxc2aY2Ji8j0/JibG8XjusSudc/jwYQBefPFFpk2b5sh96623sn//fgIDA/N97ddff52XXnrpsuM///wznp5FY/Zm+fLlRke4LksOmgEznhfPXrZmr7gpLmNeUmi8nU9jfrnHqsMH+ywcSc5i8Pwt9K9qo03IzWvEoTF3Po25c2m8nU9jXvhSU1Ov67zrLr5sNhsAVatWZfPmzQQFBd1YMoPlvo/nn3+eu+++G4CPP/6YihUrsmjRIh599NF8nzd+/Pg8s25JSUmEhYXRtWtXfH2N3acqMzOT5cuX06VLF6xWq6FZrsfMmWuBFO7u1JxOtcsaHeeGFLcxL+403s6nMb+6XpnZjF+8h+93xvDZYQte5SoztmstLGbTDV9TY+58GnPn0ng7n8bceXLviruWAu/zdeTIkQKHyU9QUBAWi4XY2Ng8x2NjYwkNDc33OaGhoVc9P/fv2NhYypUrl+ecJk2aADiO16tXz/G4m5sb1apV4/jx41fM6+bmhpub22XHrVZrkfkwF6UsV5KUlsnhuBQAmlUpU+TzXktxGPOSROPtfBrz/FmtVmbe14wawQd5+5f9fLj2GMfPpzHj3iZ4uhb4f62XXVtj7lwac+fSeDufxrzwXe/43lCr+ZSUFJYsWcKcOXOYOXNmnj/Xy9XVlebNm7NixQrHMZvNxooVK2jTpk2+z2nTpk2e8yFnGjX3/KpVqxIaGprnnKSkJDZu3Og4p3nz5ri5ubFv3z7HOZmZmRw9epTKlStfd365MbujE7HboWKAB0HelxezIiLFhclkYnTnmsy8rymuLmaW/xFLvznriUlMu/aTRUSkVCrwr+e2b99O9+7dSU1NJSUlhcDAQOLi4vD09CQ4OJgnn3zyuq81ZswYBg0aRHh4OC1btmT69OmkpKQwZMgQAAYOHEiFChV4/fXXARg9ejQdO3bkrbfeokePHnz22Wds2bKFefPmATn/I3zqqad45ZVXqFmzJlWrVuWFF16gfPnyjjVrvr6+jBgxgkmTJhEWFkblypWZOnUqAP369SvocEgBbc/dXFkt5kWkhLircXkq+Hsw/JMt7DmVRK/Za/hwUAsaVPC79pNFRKRUKXDx9a9//YuePXsyZ84c/Pz82LBhA1arlQcffJDRo0cX6FoDBgzg7NmzTJw40dF1cNmyZY6GGcePH8ds/nNyrm3btixcuJAJEybw3HPPUbNmTRYvXpynS+G4ceNISUlh+PDhJCQk0L59e5YtW4a7u7vjnKlTp+Li4sJDDz3ExYsXadWqFb/++isBAQEFHQ4poMjczZUr+huaQ0TkZmpeOYDFI9sxdMFm9sdeoN+c9Uy/twkR9fO/jV5EREqnAhdfO3bsYO7cuZjNZiwWC+np6VSrVo0pU6YwaNAg+vbtW6DrjRo1ilGjRuX72KpVqy471q9fv6vOUJlMJiZPnszkyZOveI7VauXNN9/kzTffLFBW+ecioxMAaFLJ39AcIiI3W1igJ18+1pZRC7fz+/6zjPjPVp7tVofht1TDZLrxRhwiIlJyFHjNl9VqdcxGBQcHO5pU+Pn5ceLEiZubTkqUmMQ0YpPSsZhN1C9vbIdIEZHC4Otu5aNB4QxsUxm7HV5fGsWzX+0iI8tmdDQRESkCCjzz1bRpUzZv3kzNmjXp2LEjEydOJC4ujk8//fSqmxSL7DhxHoBaIT7/uBuYiEhR5WIxM7lXA6oFeTH5hz/4fMsJjsenMufB5vh5qtuYiEhpVuCZr9dee83Rrv3VV18lICCAxx57jLNnzzJ37tybHlBKjh0nEgFoEqZF6CJS8g1uV5UPB7XAy9XC+sPn6PPuWo5e2mpDRERKpwJPP4SHhzv+OTg4mGXLlt3UQFJyOZptqNOhiJQSneoE89XjbRk6fwuH41Lo/e5a5j7YnFbVyhgdTUREDHBD+3zlZ9u2bdx5550363JSwmTb7Ow6mTPzpTbzIlKa1An15ZuRbWkc5k9CaiYPfriRRVu0RlpEpDQqUPH1008/8e9//5vnnnuOw4cPAxAVFUXv3r1p0aIFNpsWFEv+Dp29wIX0LDxdLdQM9jE6joiIUwX7uPP58Nb0aFSOzGw7Y7/cyRvLorDZ7EZHExERJ7ru4uvDDz/kjjvuYP78+bzxxhu0bt2a//znP7Rp04bQ0FB2797NkiVLCjOrFGM7Lt1y2KCCHxazWi6LSOnjbrXwzr1NeeK2GgC8t+oQIxdu42JGtsHJRETEWa67+JoxYwZvvPEGcXFxfPHFF8TFxfHuu++ya9cu5syZQ926dQszpxRzueu9muqWQxEpxcxmE093rc20/o1xtZhZujuGAfPWcyYpzehoIiLiBNddfB06dMixuXHfvn1xcXFh6tSpVKxYsdDCScmRu7my1nuJiEDfZhX5zyOtCPC0sjM6kV6z17L3dLLRsUREpJBdd/F18eJFPD09ATCZTLi5uTlazotcTVpmNlGXfqhQ8SUikqNl1UAWj2xH9bJenE5M494PNrH7vG7LFhEpyQrUav6DDz7A29sbgKysLObPn09QUFCec5588smbl05KhD2nEsmy2QnydqO8n7vRcUREiozKZbz4+rF2PL5wK2sPnuODKDOhG44ztEN1o6OJiEghuO7iq1KlSrz//vuOr0NDQ/n000/znGMymVR8yWX+3FzZH5NJv9UVEfkrP08r84e05Pmvd/LF1pO8/GMU0QlpTOhRTw2KRERKmOsuvo4ePVqIMaQk+3NzZT9jg4iIFFFWi5lXetUj9exxfjhu4eO1RzkRf5GZ9zXB07VAN6mIiEgRdtM2WRa5ktw281rvJSJyZSaTiS4V7Mzo3whXFzO/7I1lwNwN6oQoIlKCqPiSQhWfksHx+FQAGlX0NzaMiEgx0L1hKP8b1opAL1d2nUykz7vr2BejTogiIiWBii8pVLkt5quV9cLPw2psGBGRYqJ55UC+ebwt1YK8OJlwkXveW8fv+88aHUtERP4hFV9SqBzrvTTrJSJSIJXLePH1421pWTWQ5PQshszfzGebjhsdS0RE/gEVX1KotN5LROTG+Xu68unQlvRpWoFsm51nv97FG8uisNnsRkcTEZEbUOAWSklJSfkez9142dXV9R+HkpLBbrc7Zr5UfImI3Bg3FwvT+jemUqAnM1Yc4L1Vhzgen8pb/RrjbrUYHU9ERAqgwDNf/v7+BAQEXPbH398fDw8PKleuzKRJk7DZbIWRV4qRE/EXOZ+aiavFTN1yPkbHEREptkwmE//qUos3+zXGajHx487T3P/+Bs5dSDc6moiIFECBi6/58+dTvnx5nnvuORYvXszixYt57rnnqFChAu+99x7Dhw9n5syZ/N///V9h5JViZMelZht1y/vi5qLfzoqI/FP3NK/Igodb4uvuwrbjCfR9bx2Hzl4wOpaIiFynAt92uGDBAt566y369+/vONazZ08aNmzI3LlzWbFiBZUqVeLVV1/lueeeu6lhpXjZcTwBgCYVtbmyiMjN0rZ6EF8/3pYh8zdz7Fwqfd9dx7yHmtOqWhmjo4mIyDUUeOZr3bp1NG3a9LLjTZs2Zf369QC0b9+e48fVkam0y20zr/VeIiI3V41gH755vB1NwvxJvJjJQx9uYvH2k0bHEhGRayhw8RUWFsaHH3542fEPP/yQsLAwAM6dO0dAQMA/TyfFVma2jd0nEwFoouJLROSmC/J247PhrbmjQSgZ2Tae+nwHM345gN2uTogiIkVVgW87fPPNN+nXrx9Lly6lRYsWAGzZsoWoqCi+/PJLADZv3syAAQNublIpVvbFJJOeZcPX3YUqZbyMjiMiUiK5Wy3Mvr8ZbyyLYu7vh3n7l/0cj0/l9b4NcXXRbjIiIkVNgYuvu+66i6ioKObOncv+/fsBuOOOO1i8eDFVqlQB4LHHHrupIaX4+ev+XmazydgwIiIlmNlsYnz3ulQq48nEb/fw1bZoTiakMvfBcPw8rUbHExGRvyhw8QVQtWpVdTOUq3Ls71XR39AcIiKlxQOtKlPB34NRC7ez4XA8fd9by8eDW1KpjKfR0URE5JIbKr4SEhLYtGkTZ86cuWw/r4EDB96UYFK85Tbb0HovERHnubV2MItGtOHh+Zs5dDaFPu+u5f1B4TSrpHXYIiJFQYGLr++//54HHniACxcu4Ovri8n05y1lJpNJxZdwIT2LA2dy9p1pFKY28yIizlS3nC/fPN6OoQs2s+dUEvfN28DbA5rQvWE5o6OJiJR6BV6N+/TTT/Pwww9z4cIFEhISOH/+vONPfHx8YWSUYmZndAJ2O1Tw9yDYx93oOCIipU6onztfPNqG2+oEk55l4/H/bmPub4fUCVFExGAFLr5OnjzJk08+iaen7iGX/EWeyGkx31izXiIihvFyc2HeQ80Z2KYyAK8vjeL5xbvJyrZd45kiIlJYClx8RUREsGXLlsLIIiVEbrMNrfcSETGWi8XMS3fV54U762EywcKNxxm6YAvJaZlGRxMRKZUKvOarR48ejB07lj/++IOGDRtiteZtY3vXXXfdtHBSPOU221CnQxER45lMJoa2r0rFAA9Gf7ad3/afpd+c9Xw0uAXl/T2MjiciUqoUuPgaNmwYAJMnT77sMZPJRHZ29j9PJcVWbFIapxPTMJugQQXddigiUlRE1A/li0fb8PD8LUTFJNPn3bV8OKiF/lstIuJEBb7t0GazXfGPCi/J3Vy5VogPXm43tJOBiIgUkkYV/Vk8si21QryJTUqn/9z1rNgba3QsEZFSo8DFl8jVaHNlEZGirWKAJ4tGtKV9jSBSM7IZ9skWFqw7anQsEZFS4bqmJmbOnMnw4cNxd3dn5syZVz33ySefvCnBpHhybK5cyd/QHCIicmV+HlY+HtKC57/ZxRdbopn03R6OnUvl+R51sZhN176AiIjckOsqvt5++20eeOAB3N3defvtt694nslkUvFVitlsdnbmtpnXzJeISJFmtZh54+5GVC7jxdSf9vHR2iOcOJ/KjHub4Omq28ZFRArDdf3X9ciRI/n+s8hfHY67QHJ6Fu5WM7VCvI2OIyIi12AymRjZqQZhgZ78e1Eky/+I5d55G/hgUDjBPu5GxxMRKXG05ktumh2XZr0aVvDDxaKPlohIcXFX4/IsfKQVAZ5WdkYn0mf2OvbFJBsdS0SkxCnwfQXZ2dnMnz+fFStWcObMGWw2W57Hf/3115sWTooXba4sIlJ8hVcJ5JvH2zFk/maOxKVwz3vrePfBZnSoWdboaCIiJUaBpydGjx7N6NGjyc7OpkGDBjRu3DjPHym9ctvMN1bxJSJSLFUJ8uLrx9rSskogyelZDPl4M59vPm50LBGREqPAM1+fffYZX3zxBd27dy+MPFJMpWVms/d0EqBmGyIixVmAlyufPtKScV/u5Nsdp3jmq10cjkvhmYg6mNUJUUTkHynwzJerqys1atQojCxSjP1xOoksm50yXq5UDPAwOo6IiPwDbi4Wpg9owpO35fz/fu5vh3nsv1tJzcgyOJmISPFW4OLr6aefZsaMGdjt9sLII8XUX9d7mUz6zaiISHFnMpkY07U2bw9ojKvFzE97Yuk/dz2xSWlGRxMRKbYKfNvhmjVrWLlyJUuXLqV+/fpYrdY8j3/99dc3LZwUH5Fa7yUiUiL1aVqRigGePPrpVnafTKLXrLV8MCicBhX8jI4mIlLsFHjmy9/fnz59+tCxY0eCgoLw8/PL80dKJzXbEBEpuVpUCWTx4+2oXtaLmKQ0+s1Zz/I/Yo2OJSJS7BRo5isrK4tOnTrRtWtXQkNDCyuTFDMJqRkcPZcKQOOKKsBFREqiSmU8+frxdoz87zbWHIxj+KdbeO6OujzSoapuNxcRuU4FmvlycXFhxIgRpKenF1YeKYYio3M2V64a5IW/p6vBaUREpLD4eVj5eEgL7m9VCbsdXl2yl+e+2UVmtu3aTxYRkYLfdtiyZUu2b99eGFmkmHKs99Ksl4hIiWe1mHm1dwMm9KiLyQT/23SCwR9vIjE10+hoIiJFXoEbbjz++OM8/fTTREdH07x5c7y8vPI83qhRo5sWTooHrfcSESldTCYTj3SoRpUyXjz52XbWHjxHn/fW8vHgFlQu43XtC4iIlFIFLr7uvfdeAJ588knHMZPJhN1ux2QykZ2dffPSSZFnt9vV6VBEpJTqXC+ERSPa8MiCLRw+m0Lv2WuZ+1A4LasGGh1NRKRIKnDxdeTIkcLIIcVU9PmLnEvJwGoxUa+cr9FxRETEyeqX9+Pbke145JMt7IxO5IEPNvB/fRtxd/OKRkcTESlyClx8Va5cuTBySDEVGZ0AQN1yvrhbLcaGERERQwT7uvP58Db86/MdLNsTw9OLIjkSl8KYLrUwm9UJUUQkV4GLr1x//PEHx48fJyMjI8/xu+666x+HkuJjx/EEABpX9Dc0h4iIGMvD1cK7DzRj6s/7eG/VIWatPMiRuBTe6t9Yv5wTEbmkwMXX4cOH6dOnD7t27XKs9QIce3xozVfpkjvzpfVeIiJiNpt4plsdqgZ58fw3u/hx12miEy7y/sDmBPu4Gx1PRMRwBW41P3r0aKpWrcqZM2fw9PRkz549/P7774SHh7Nq1apCiChFVVa2jV0nc/b4aqLiS0RELukfHsanQ1vh72kl8kQCfWavY+/pJKNjiYgYrsDF1/r165k8eTJBQUGYzWbMZjPt27fn9ddfz9MBUUq+/bEXSMu04ePmQrUgtRYWEZE/ta5Whm8eb0fVIC9OJlzknvfWsTLqjNGxREQMVeDiKzs7Gx8fHwCCgoI4deoUkNOIY9++fTc3nRRpuft7NQrz04JqERG5TNUgL755vC2tqwWSkpHN0AWb+XjtEceSBRGR0qbAxVeDBg2IjIwEoFWrVkyZMoW1a9cyefJkqlWrdkMhZs+eTZUqVXB3d6dVq1Zs2rTpqucvWrSIOnXq4O7uTsOGDVmyZEmex+12OxMnTqRcuXJ4eHjQuXNnDhw4kO+10tPTadKkCSaTiR07dtxQ/tLKsb+Xmm2IiMgV+Hu68snDregfXhGbHV76/g8mfruHrGyb0dFERJyuwMXXhAkTsNly/oM5efJkjhw5QocOHViyZAkzZ84scIDPP/+cMWPGMGnSJLZt20bjxo2JiIjgzJn8b01Yt24d9913H0OHDmX79u307t2b3r17s3v3bsc5U6ZMYebMmcyZM4eNGzfi5eVFREQEaWlpl11v3LhxlC9fvsC55c9mG1rvJSIiV+PqYuaNuxvx7B11MJng0w3HGDJ/M0lpmUZHExFxqgIXXxEREfTt2xeAGjVqEBUVRVxcHGfOnOG2224rcIBp06YxbNgwhgwZQr169ZgzZw6enp589NFH+Z4/Y8YMunXrxtixY6lbty4vv/wyzZo1Y9asWUDOrNf06dOZMGECvXr1olGjRnzyySecOnWKxYsX57nW0qVL+fnnn3nzzTcLnLu0S0nPYn9sMqDiS0RErs1kMjGiY3Xee6A5HlYLqw/Ecfe76zgRn2p0NBERp7nhfb4OHjzIoUOHuOWWWwgMDLyh+7czMjLYunUr48ePdxwzm8107tyZ9evX5/uc9evXM2bMmDzHIiIiHIXVkSNHiImJoXPnzo7H/fz8aNWqFevXr+fee+8FIDY2lmHDhrF48WI8PT2vmTU9PZ309HTH10lJOV2bMjMzycw09jd3ua/vzBzbj8Vjs0OorxsBHhbDx8DZjBjz0kzj7Xwac+crLWN+e+0y/O+RFjz6n+0cOHOBXrPX8N79TWlWyd/pWUrLmBcVGm/n05g7z/WOcYGLr3PnztG/f39WrlyJyWTiwIEDVKtWjaFDhxIQEMBbb7113deKi4sjOzubkJCQPMdDQkKIiorK9zkxMTH5nh8TE+N4PPfYlc6x2+0MHjyYESNGEB4eztGjR6+Z9fXXX+ell1667PjPP/98XcWbMyxfvtxpr7XipAmwEOxy8bI1d6WJM8dcNN5G0Jg7X2kZ88drwvv7LESnZPLABxu5r7qN8LLGNOIoLWNeVGi8nU9jXvhSU69vFr/Axde//vUvrFYrx48fp27duo7jAwYMYMyYMQUqvozyzjvvkJycnGfG7VrGjx+fZ8YtKSmJsLAwunbtiq+vb2HEvG6ZmZksX76cLl26YLVanfKaSz+LBGKJCK9N9w5VnfKaRYkRY16aabydT2PufKVxzHulZ/HvL3fxS9RZPj1owT+sGk90qo7J5JwOuqVxzI2k8XY+jbnz5N4Vdy0FLr5+/vlnfvrpJypWrJjneM2aNTl27FiBrhUUFITFYiE2NjbP8djYWEJDQ/N9Tmho6FXPz/07NjaWcuXK5TmnSZMmAPz666+sX78eNze3PNcJDw/ngQceYMGCBZe9rpub22XnA1it1iLzYXZmll0ncz5gzSqXKTLv3whF6ftfGmi8nU9j7nylacz9rVbmDmzBG8uimPf7Yd5ZeZhj8WlMuacR7laL03KUpjEvCjTezqcxL3zXO74FbriRkpKS72128fHx+RYnV+Pq6krz5s1ZsWKF45jNZmPFihW0adMm3+e0adMmz/mQM5Wae37VqlUJDQ3Nc05SUhIbN250nDNz5kwiIyPZsWMHO3bscNw29/nnn/Pqq68W6D2URmeS0ziZcBGTCRpW9DM6joiIFGMWs4nnutfl//o2xMVs4rvIU9z//gbiLqRf+8kiIsVMgYuvDh068Mknnzi+NplM2Gw2pkyZQqdOnQocYMyYMbz//vssWLCAvXv38thjj5GSksKQIUMAGDhwYJ7bA0ePHs2yZct46623iIqK4sUXX2TLli2MGjXKkeepp57ilVde4bvvvmPXrl0MHDiQ8uXL07t3bwAqVapEgwYNHH9q1aoFQPXq1S+b0ZPLRZ5IBKBmsDfebjfcs0VERMTh3paVWPBwS3zdXdh2PIHes9c6uuqKiJQUBf7JecqUKdx+++1s2bKFjIwMxo0bx549e4iPj2ft2rUFDjBgwADOnj3LxIkTiYmJoUmTJixbtszRMOP48eOYzX/WiG3btmXhwoVMmDCB5557jpo1a7J48WIaNGjgOGfcuHGkpKQwfPhwEhISaN++PcuWLcPd3b3A+eRyuZsrq8W8iIjcTO1qBPH14+0YumAzx86lcve765j1QDM61iprdDQRkZuiwMVXgwYN2L9/P7NmzcLHx4cLFy7Qt29fRo4cmWeNVUGMGjXKMXP1d6tWrbrsWL9+/ejXr98Vr2cymZg8eTKTJ0++rtevUqXKDbXKL61yN1durOJLRERushrB3nzzeDtGfLqVTUfjeXj+Zl7sWY+H2lQxOpqIyD92Q/eM+fn58fzzz+c5Fh0dzfDhw5k3b95NCSZFk81mZ8elma/GFf0NzSIiIiVToJcrnz7SkvFf7+LrbSd54ds9HDqbwgt31sNidk4nRBGRwlDgNV9Xcu7cOT788MObdTkpoo6cSyE5LQs3FzO1Q32MjiMiIiWUm4uFt/o1ZmxEbQDmrzvKIws2cyE9y+BkIiI37qYVX1I65K73aljBD6tFHx8RESk8JpOJkZ1qMPv+Zri5mFm57yz3vLeOkwkXjY4mInJD9NOzFEhu8aX1XiIi4iw9GpXj80fbEOTtRlRMMr1mrWHz0XijY4mIFJiKLymQHSq+RETEAE3C/Pl2VDvqhPoQdyGD++Zt4D8bjqlhlogUK9fdcKNv375XfTwhIeGfZpEiLj0rmz9OJwHQRM02RETEySr4e/D1420Z++VOftx5mgmLd7PnVCIv3lUfNxeL0fFERK7puosvPz+/az4+cODAfxxIiq69p5PJzLYT6OVKWKCH0XFERKQU8nR1YdZ9TWlQ3o8pP0Xxv00n2BeTzHsPNifEV/t5ikjRdt3F18cff1yYOaQYcKz3quiHyaRWvyIiYgyTycRjt1anTjkfRv9vO9uOJ9DznTXMeag5zSoFGB1PROSKtOZLrpvWe4mISFHSqXYw345qT81gb84kp3Pv3A18vvm40bFERK5IxZdcN3U6FBGRoqZqkBffjGxHRP0QMrJtPPPVLl5YvJuMLJvR0URELqPiS65LYmomh+NSAGisZhsiIlKEeLu58N4DzXm6Sy0APt1wjAc/2MjZ5HSDk4mI5KXiS67LzpMJAFQu40mgl6uxYURERP7GbDbxxO01+WBgOD5uLmw6Gs9ds9awMzrB6GgiIg4qvuS67DieAGjWS0REirbO9UL4ZmQ7qpX14nRiGvfMWc9XW6ONjiUiAqj4kusUeek3h1rvJSIiRV2NYG8Wj2zH7XWCyciy8fSiSF76fg+Z2VoHJiLGUvEl12S329lxIhGAJmFX3+9NRESkKPB1t/L+wHCevL0mAB+vPcrADzdx7oLWgYmIcVR8yTWdSkwj7kI6LmYT9cur+BIRkeLBbDYxpkst5jzYHC9XC+sPn+OuWWvZfTLR6GgiUkqp+JJryl3vVaecD+5Wi7FhRERECqhbg1C+GdmOKmU8OZlwkXvmrOPbHSeNjiUipZCKL7kmx3ovNdsQEZFiqlaID9+ObE/HWmVJy7Qx+rMd/N+yfWTbjU4mIqWJii+5ph3aXFlEREoAP08rHw1uwWO3Vgfgw7XHmLvXTEJqpsHJRKS0UPElV5WVbWNXdM698U1VfImISDFnMZt4plsdZt3fFA+rmX2JZvrO2UBUTJLR0USkFFDxJVd14MwFLmZm4+3mQrWy3kbHERERuSnubFSeL4a3ooybnRPnL9L33XUs2XXa6FgiUsKp+JKrirx0y2HDCn5YzCZjw4iIiNxEdUJ9eLphNm2rB5Kakc3j/93G1J+iyLZpIZiIFA4VX3JV2lxZRERKMi8rfPhQM4Z1qArA7JWHeGTBZhIvah2YiNx8Kr7kqv7cXNnf2CAiIiKFxMVi5vke9ZhxbxPcXMys3HeW3rPXciA22ehoIlLCqPiSK0rNyGLfpQXIKr5ERKSk69WkAl891pYK/h4ciUuh9+y1/LQnxuhYIlKCqPiSK9p9MgmbHUJ83Qj1czc6joiISKFrUMGP70a1o3W1QFIysnn00628vXw/Nq0DE5GbQMWXXFFusw1triwiIqVJGW83Ph3aiiHtqgAwY8UBhn+6leQ0rQMTkX9GxZdc0Y5LzTaaVPI3NIeIiIizWS1mJvWsz5v9GuPqYuaXvbH0nr2Ww2cvGB1NRIoxFV9yRbkzX0008yUiIqXUPc0rsujRNoT6unPobAq9Zq3l16hYo2OJSDGl4kvyFXchnejzFzGZoEFFP6PjiIiIGKZxmD/fP9GeFlUCSE7PYuiCLcz69QB2u9aBiUjBqPiSfOXOelUv642vu9XYMCIiIgYr6+PGfx9pzUOtK2O3w5s/7+fx/24jJT3L6GgiUoyo+JJ8OW45VIt5ERERAFxdzLzcuwH/17chVouJpbtj6PvuOo6dSzE6mogUEyq+JF87onM2V26s4ktERCSPe1tW4rPhbQj2cWNfbDI931nDb/vPGh1LRIoBFV9yGbvdrmYbIiIiV9G8cgDfP9GeppX8SUrLYvDHm5j6UxRZ2Tajo4lIEabiSy5z9FwqiRczcXUxUzvUx+g4IiIiRVKIrzufDW/N/a0qYbfD7JWHGDBvA9HnU42OJiJFlIovuUzurFeD8r64uugjIiIiciVuLhZe69OQ2fc3w8fNha3HztN9xmqW7T5tdDQRKYL0k7VcZsel4kvrvURERK5Pj0blWDK6A03Ccm5DHPGfbUxYvIu0zGyjo4lIEaLiSy6zQ50ORURECiws0JNFI9owomN1AP6z4Ti9Z6/l4Jlkg5OJSFGh4kvyyMiy8cepJAAaq9mGiIhIgVgtZp69ow6fPNySIG9XomKS6fnOWr7YfEKbMouIii/JKyomiYxsG/6eViqX8TQ6joiISLF0S62yLBndgQ41g7iYmc24r3by5Gc7SErLNDqaiBhIxZfkkdtso3FFf0wmk7FhREREirFgH3cWDGnJs3fUwcVs4vvIU9w5c43j/7UiUvqo+JI8tqvZhoiIyE1jNpsY0bE6X4xoQ8UAD47Hp3L3e+uY9/shbDbdhihS2qj4kjwcmyuH+RkbREREpARpVimAH5/sQI+G5ciy2XltSRRD5m8m7kK60dFExIlUfIlDUlomh86mAGq2ISIicrP5eViZdX9TXuvTEDcXM7/tP8sdM1az9mCc0dFExElUfInDruhEAMICPSjj7WZwGhERkZLHZDJxf6tKfDeqPbVCvDmbnM6DH25k6k9RZGXbjI4nIoVMxZc47PhLsw0REREpPLVDffh2ZHvua1kJux1mrzzEgHkbiD6fanQ0ESlEKr7EQZsri4iIOI+Hq4XX+zZk9v3N8HF3Yeux83SfsZqlu04bHU1EComKLwHAbrf/OfOl4ktERMRpejQqx5InO9AkzJ+ktCwe++82JizeRVpmttHRROQmU/ElAMQkpXE2OR2L2USD8up0KCIi4kxhgZ4sGtGGx26tDsB/Nhyn9+y1HDyTbHAyEbmZVHwJADuOJwBQO8QHD1eLsWFERERKIavFzDPd6vDJwy0J8nYlKiaZO99Zw+ebj2O3a08wkZJAxZcAsCM6AdAthyIiIka7pVZZlozuQIeaQaRl2njmq1088b/tJKVlGh1NRP4hFV8CaHNlERGRoiTYx50FQ1ry7B11cDGb+GHnaXrMXO1Yny0ixZOKLyHbZnfs8dUkLMDgNCIiIgJgNpsY0bE6i0a0oWKAByfiL3LPe+uY+9shbDbdhihSHKn4Eg6euUBKRjaerhZqBHsbHUdERET+ommlAH58sgM9GpYjy2bn9aVRDJ6/mbgL6UZHE5ECUvEljlsOG1bww2I2GRtGRERELuPnYWXW/U15vW9D3FzM/L7/LHfMWM2aA3FGRxORAlDxJY5mG9pcWUREpOgymUzc17IS3z/Rnloh3pxNTuehjzYy9acoMrNtRscTkeug4kv+0mzD39AcIiIicm21Qnz4dmR77m9VCbsdZq88xIC56zkRn2p0NBG5BhVfpdzFjGyiYnI2cFSbeRERkeLBw9XCa30aMvv+Zvi4u7DteALdZ65m6a7TRkcTkatQ8VXK7TmVSLbNTlkfN8r5uRsdR0RERAqgR6NyLHmyA00r+ZOclsVj/93G89/sIi0z2+hoIpKPIlF8zZ49mypVquDu7k6rVq3YtGnTVc9ftGgRderUwd3dnYYNG7JkyZI8j9vtdiZOnEi5cuXw8PCgc+fOHDhwwPH40aNHGTp0KFWrVsXDw4Pq1aszadIkMjIyCuX9FWW5+4U0ruiPyaRmGyIiIsVNWKAnXzzahsdurY7JBP/deJxes9ZyIDbZ6Ggi8jeGF1+ff/45Y8aMYdKkSWzbto3GjRsTERHBmTNn8j1/3bp13HfffQwdOpTt27fTu3dvevfuze7dux3nTJkyhZkzZzJnzhw2btyIl5cXERERpKWlARAVFYXNZmPu3Lns2bOHt99+mzlz5vDcc8855T0XJZGX9vdqWsnf2CAiIiJyw6wWM890q8MnD7ckyNuNfbHJ3PnOGt5bdUjNOESKEMOLr2nTpjFs2DCGDBlCvXr1mDNnDp6ennz00Uf5nj9jxgy6devG2LFjqVu3Li+//DLNmjVj1qxZQM6s1/Tp05kwYQK9evWiUaNGfPLJJ5w6dYrFixcD0K1bNz7++GO6du1KtWrVuOuuu/j3v//N119/7ay3XWTsOHEeyJn5EhERkeKtQ82yLB3dgY61ypKeZeONZVHcNWstOy91NhYRY7kY+eIZGRls3bqV8ePHO46ZzWY6d+7M+vXr833O+vXrGTNmTJ5jERERjsLqyJEjxMTE0LlzZ8fjfn5+tGrVivXr13Pvvffme93ExEQCAwOvmDU9PZ309D83M0xKSgIgMzOTzMzMq7/RQpb7+gXNcS4lgxPxFwGoG+Jp+PsoTm50zOXGaLydT2PufBpz5yupY+7vbub9B5uweMdpXlu6j72nk+g9ey2D2lTmqdur4+lqzI9/JXW8izKNufNc7xgbWnzFxcWRnZ1NSEhInuMhISFERUXl+5yYmJh8z4+JiXE8nnvsSuf83cGDB3nnnXd48803r5j19ddf56WXXrrs+M8//4ynp+cVn+dMy5cvL9D5e86bAAvB7nbWrCzYcyVHQcdc/hmNt/NpzJ1PY+58JXXM3YB/14dvjprZGmfm43XH+HbrUfpXtVE3wG5YrpI63kWZxrzwpaZe31YPhhZfRcHJkyfp1q0b/fr1Y9iwYVc8b/z48Xlm3JKSkggLC6Nr1674+vo6I+oVZWZmsnz5crp06YLVar3u5x389SBEHaZdnfJ0796wEBOWPDc65nJjNN7OpzF3Po2585WWMR8A/Lb/LJO+38vJhDTmRFm4q1E5nutemzJerk7LUVrGuyjRmDtP7l1x12Jo8RUUFITFYiE2NjbP8djYWEJDQ/N9Tmho6FXPz/07NjaWcuXK5TmnSZMmeZ536tQpOnXqRNu2bZk3b95Vs7q5ueHm5nbZcavVWmQ+zAXNsvNkThekppUDi8x7KG6K0ve/NNB4O5/G3Pk05s5XGsa8c/3ytKkRzLTl+/l47RG+23ma1QfjmNCjHn2bVXBqx+PSMN5Fjca88F3v+BracMPV1ZXmzZuzYsUKxzGbzcaKFSto06ZNvs9p06ZNnvMhZyo19/yqVasSGhqa55ykpCQ2btyY55onT57k1ltvpXnz5nz88ceYzYb3HnEqu91O5KXFt2q2ISIiUvJ5ubnwwp31+ObxdtQt58v51EyeXhTJwI82cfzc9d0yJSL/jOEVx5gxY3j//fdZsGABe/fu5bHHHiMlJYUhQ4YAMHDgwDwNOUaPHs2yZct46623iIqK4sUXX2TLli2MGjUKAJPJxFNPPcUrr7zCd999x65duxg4cCDly5end+/ewJ+FV6VKlXjzzTc5e/YsMTExV1wTVhIdj08lITUTV4uZOuV8jI4jIiIiTtI4zJ/vRrVjXLfauLmYWX0gjq7Tf2Pub4fIUlt6kUJl+JqvAQMGcPbsWSZOnEhMTAxNmjRh2bJljoYZx48fzzMr1bZtWxYuXMiECRN47rnnqFmzJosXL6ZBgwaOc8aNG0dKSgrDhw8nISGB9u3bs2zZMtzd3YGcmbKDBw9y8OBBKlasmCeP3W7cAlRnyt1cuV55X9xcLMaGEREREaeyWsw8fmsNujcox3Pf7GLdoXO8vjSK7yJP8cbdjWhQwc/oiCIlkuHFF8CoUaMcM1d/t2rVqsuO9evXj379+l3xeiaTicmTJzN58uR8Hx88eDCDBw++kaglRm7x1STM39AcIiIiYpwqQV7895FWLNoazas/7mXPqSTumrWGRzpU41+da+Hhql/QitxMht92KMaIvFR8NQ7Tb7ZERERKM5PJRP/wMH4Z05Gejctjs8O83w/TdfpvrD5w1uh4IiWKiq9SKDPbxu5TOe0w1WxDREREAMr6uPHOfU35aHA45f3cORF/kYc+3MSYz3cQn5JhdDyREkHFVym0LyaZjCwbvu4uVA3yMjqOiIiIFCG31Qnh5zEdGdy2CiYTfL39JJ2n/cY326NLzdp4kcKi4qsU2u645dDfqft6iIiISPHg7ebCi3fV5+vH2lIn1If4lAz+9Xkkgz7ezIl4taUXuVEqvkqhSDXbEBERkevQtFIA3z/RnrERtXF1MfP7/rN0fft3Plh9WG3pRW6Aiq9SyNFsQ+u9RERE5BqsFjMjO9Vg2egOtK4WyMXMbF75cS993l3HnlOJRscTKVZUfJUyyWmZHDx7Aci57VBERETkelQr683/hrXmjbsb4uvuwq6Tidw1ay2vL93LxYxso+OJFAsqvkqZXScTsduhgr8HZX3cjI4jIiIixYjJZGJAi0r88nRHejQqR7bNztzfDhMx/XfWHowzOp5Ikafiq5TR5soiIiLyTwX7uDP7/mZ8MDCccn7uHI9P5YEPNvL0F5GcV1t6kStS8VXKaHNlERERuVk61wvh53/dwqA2lTGZ4Ktt0XSe9hvf7jiptvQi+VDxVcpEnshZGNskLMDgJCIiIlIS+LhbealXA74c0ZZaId6cS8lg9Gc7GDJ/M9Hn1ZZe5K9UfJUiMYlpxCSlYTZBgwq+RscRERGREqR55QB+eKIDT3ephavFzKp9OW3pP1xzhGybZsFEQMVXqZK73qtWiA+eri7GhhEREZESx9XFzBO312TpUx1oWTWQ1IxsXv7hD/q+u5a9p5ONjidiOBVfpUhkdAKgZhsiIiJSuKqX9eazYa15rU9DfNxdiIxOpO+cDXx3zExyWpbR8UQMo+KrFIlUp0MRERFxErPZxP2tKrFiTEfuaBBKls3OilNmbn97NXN/O6S9waRUUvFVSthsdnZG5zTb0ObKIiIi4izBvu6892Bz5tzfhBAPO+dTM3l9aRS3TF3JJ+uPkp6lIkxKDxVfpcShsxe4kJ6Fh9VCzWBvo+OIiIhIKXN73WCeaZzNG33rUzHAg7PJ6Uz8dg+3vfkbX2w5QVa2zeiIIoVOxVcpkdtso2EFP1ws+raLiIiI81lM0LdpBX59+lZe7t2AYB83TiZcZNyXO+k6/Xe+jzyFTZ0RpQTTT+GlRG6zDW2uLCIiIkZzdTHzUOvK/D6uE893r0uAp5XDZ1N44n/b6fHOGn75I1abNEuJpOKrlNDmyiIiIlLUuFstDLulGr+P68S/OtfCx82FvaeTeOSTLfR5dx1rD8YZHVHkplLxVQqkZWaz93QSoJkvERERKXp83K2M7lyT1c904rFbq+NhtbDjRAIPfLCR++ZtYOux80ZHFLkpVHyVAntOJZFlsxPk7UoFfw+j44iIiIjky9/TlWe61eG3cbcyuG0VXC1m1h8+x93vrePh+ZvZcyrR6Igi/4iKr1Igd3+vxhX9MZlMxoYRERERuYZgH3devKs+K8feyoDwMCxmE79GnaHHzDWM/O82Dp65YHREkRui4qsUyG22oc2VRUREpDip4O/BG/c04pcxHbmrcXlMJvhx12m6vv0bT38RyYn4VKMjihSIiq9SILfNvDZXFhERkeKoapAXM+9rytLRHehSLwSbHb7aFs1tb61iwuJdxCalGR1R5Lqo+CrhzqdkcOxczm+FGlVUsw0REREpvuqE+vL+wHAWj2xHh5pBZGbb+c+G49wyZSWv/vgH8SkZRkcUuSoVXyVc7i2HVYO88Pd0NTaMiIiIyE3QJMyfT4e24rPhrQmvHEB6lo33Vx+hwxu/Mu3nfSSlZRodUSRfKr5KuD/39/I3NoiIiIjITda6WhkWjWjDx0Na0KCCLykZ2cz89SAd3ljJu6sOkpqRZXREkTxUfJVwO07k7IvRWLccioiISAlkMpnoVDuY70e1570HmlEj2JvEi5lMWbaPW6as4uO1R0jPyjY6pgig4qtEs9vtREbnzHyp2YaIiIiUZCaTiTsaluOnp25hWv/GVAr0JO5COi99/wedpq7is03Hycy2GR1TSjkVXyVY9PmLxKdkYLWYqFvO1+g4IiIiIoXOYjbRt1lFVjzdkVf7NCDU151TiWk8+/Uuukz7jW93nMRmsxsdU0opFV8lWG6L+XrlfHG3WowNIyIiIuJEVouZB1pVZtXYW5nQoy6BXq4cPZfK6M92cMeM1fy0Jwa7XUWYOJeKrxJM+3uJiIhIaedutfBIh2r8Pq4TT3ephY+7C/tik3n00630nr2W3/afVREmTqPiqwSLzC2+KvobmkNERETEaN5uLjxxe03WjLuNkZ2q4+lqITI6kUEfbaLTm6uYvfKgNmuWQqfiq4TKzLax+5SabYiIiIj8lZ+nlbERdfh9XCceblcVL1cLR8+lMvWnfbR5fQUPz9/Mst0xZGSpOYfcfC5GB5DCsT82mbRMGz7uLlQL8jI6joiIiEiREuTtxsSe9Xi6ay1+3HWaRVtOsPnoeX6NOsOvUWco4+VKn6YVGNAijJohPkbHlRJCxVcJteMvtxyazSZjw4iIiIgUUV5uLvQPD6N/eBiHzl5g0ZZovtoWzdnkdD5Yc4QP1hyhSZg/A1qEcWejcvi4W42OLMWYiq8SyrHeK0ybK4uIiIhcj+plvXn2jjr8u2stVu07yxdbTvBr1Bl2nEhgx4kEXvp+D90blmNAeBgtqwZiMukX3FIwKr5KqMgTl9Z7qdmGiIiISIG4WMx0rhdC53ohnE1O55vt0Xy++QSHzqbw9baTfL3tJFXKeNIvPIy7m1Uk1M/d6MhSTKj4KoEupGex/0wyAE3UbENERETkhpX1cWP4LdUZ1qEa244nsGjLCb6PPOVo0vHWz/voWKssA1qEcVudEFxd1M9OrkzFVwm0KzoRux3K+7kT7KvfxIiIiIj8UyaTieaVA2heOYCJPevx487TLNoSzaaj8azcd5aV+846mnT0bxFGLTXpkHyo+CqBIqMTALWYFxERESkMnq4u9AsPo194GIfPXmDR1mi+2hrNmb806Wgc5s+A8DDubFwOXzXpkEtUfJVAfzbb8Dc0h4iIiEhJV62sN890q8PTXWrx2/6cJh0r9p4h8kQCkScSmPxDTpOO/uFhtFKTjlJPxVcJlFt8ab2XiIiIiHO4WMzcXjeE2+vmNOlYvP0kn285wcEzFxxNOiqX8aS/mnSUaiq+SpgzSWmcSkzDbIKGFdRmXkRERMTZyvq4MeyWajzSoSrbT+Q26TjNsb816egfHsbtddWkozRR8VXC5G6uXDPYBy83fXtFREREjGIymWhWKYBmlQJ44c56LNkVwxdbTrDpyJ9NOgJzm3SEh1E7VE06Sjr9dF7C/NlsQ7NeIiIiIkWFp6sL9zSvyD3NK3IkLoVFW07w5aUmHR+uOcKHl5p09A+vSM/G5dWko4RS8VXC5G6u3CQswOAkIiIiIpKfqkFejOtWhzFdavH7gbN8sTmaX/bGOpp0vPT9HzQJ86dFlQBaVAmkWeUAFWMlhIqvEsRms/+l06FmvkRERESKMheLmdvqhHBbnRDiLlxq0rH5BAfOXGDTkXg2HYkHDmE2QZ1QX1pUCSC8SiAtqwYSor1ciyUVXyXIkXOpJKdn4W41a2M/ERERkWIkyNuNRzpUY2j7qhyOS2HL0Xg2HTnPlmPxHDuXyh+nk/jjdBIL1h8DICzQgxZVAi/9CaB6WW+1sS8GVHyVIDujc245bFDeD6tFXXNEREREihuTyUT1st5UL+vNgBaVAIhNSmPL0fNsPhrP5qPx7D2dxIn4i5yIz2lhDxDgac2ZFasSSHiVABqo63WRpOKrBNl5Mne9l7+xQURERETkpgnxdadHo3L0aFQOgOS0TLYdT7g0OxbPjhMJnE/NZPkfsSz/IxYAd6uZJhX98Msw43vwHC2qBeGtTtiG03egBIm8NPPVWMWXiIiISInl426lY62ydKxVFoCMLBu7TyWy+Ug8m4/m3KqYkJrJhiPnATM/LdiK2QT1yvs6blUMrxJAsI/WjTmbiq8SItMGUTHJgGa+REREREoTVxezYz+xRzvmNGE7dPYCGw7F8e263cRkeRKdkMbuk0nsPpnEx2uPAlCljGeeWxWrBnlp3VghU/FVQpxMgcxsO4FerlQM8DA6joiIiIgYxGw2UTPEhyqB7vie3Un37rcQl5qVMyt26VbFfbHJHD2XytFzqXy5NRqAIG9XwivnFGItqwZSr5wvLuojcFOp+Cohjl/I+S1FkzB//cZCRERERPIo5+fBXY09uKtxeQASL2ay7VhOE48tR8+zIzqBuAsZLNsTw7I9MQB4ulpoVimA8Co5s2rl/d0J8HTF39MVi1k/b94IFV8lxNFLxVfjiv7GBhERERGRIs/Pw0qnOsF0qhMMQFpmNrtPJrLpUjG25Wg8SWlZrDkYx5qDcXmeazKBv4eVQC9XAr1cCfB0pYx3zt+OY16ulPH685inq0UTBKj4KjFyZ760ubKIiIiIFJS71UJ4lUDCqwQCOevG9p9JZvPR82w+Es/uk4mcS8kg8WImdjucT83kfGomh86mXNf13VzM112o5ZxnLZG3PKr4KgESUjM5m6aZLxERERG5OcxmE3VCfakT6stDrSs7jmdm20hIzSQ+JYP4lAzOp2ZwLiWD85e+dhy78OdjGVk20rNsnE5M43Ri2nVn8HV3oYy3GwGeVgK93Aj0sl5WqFUJ8qJ6We/CGIJCUSSKr9mzZzN16lRiYmJo3Lgx77zzDi1btrzi+YsWLeKFF17g6NGj1KxZkzfeeIPu3bs7Hrfb7UyaNIn333+fhIQE2rVrx3vvvUfNmjUd58THx/PEE0/w/fffYzabufvuu5kxYwbe3sXnm5dr16mcFvOVAj0I8HI1OI2IiIiIlFRWi5myPm6U9XG7rvPtdjupGdmOwiw+9eqF2vmUDBIuza4lpWWRlJbFkatcv394Rabc0/jmvDknMLz4+vzzzxkzZgxz5syhVatWTJ8+nYiICPbt20dwcPBl569bt4777ruP119/nTvvvJOFCxfSu3dvtm3bRoMGDQCYMmUKM2fOZMGCBVStWpUXXniBiIgI/vjjD9zdc/YzeOCBBzh9+jTLly8nMzOTIUOGMHz4cBYuXOjU938z7IxOAqBxRd1yKCIiIiJFh8lkwsvNBS83F8ICPa/rOdk2OwmpOQVZfEom8Snpef7+a6FWNah4TZwYXnxNmzaNYcOGMWTIEADmzJnDjz/+yEcffcSzzz572fkzZsygW7dujB07FoCXX36Z5cuXM2vWLObMmYPdbmf69OlMmDCBXr16AfDJJ58QEhLC4sWLuffee9m7dy/Lli1j8+bNhIeHA/DOO+/QvXt33nzzTcqXL++kd39zREYnANBIxZeIiIiIFHMWs4ky3m6U8b6+2bXixNDiKyMjg61btzJ+/HjHMbPZTOfOnVm/fn2+z1m/fj1jxozJcywiIoLFixcDcOTIEWJiYujcubPjcT8/P1q1asX69eu59957Wb9+Pf7+/o7CC6Bz586YzWY2btxInz59Lnvd9PR00tPTHV8nJeXMNmVmZpKZmVnwN3+T2O12dkbn3HZYP8TL0CylSe44a7ydQ+PtfBpz59OYO5/G3Lk03s6nMXee6x1jQ4uvuLg4srOzCQkJyXM8JCSEqKiofJ8TExOT7/kxMTGOx3OPXe2cv9/S6OLiQmBgoOOcv3v99dd56aWXLjv+888/4+l5fVOohSE+Hc6luGA22Tm5ZxNn8x82KSTLly83OkKpovF2Po2582nMnU9j7lwab+fTmBe+1NTU6zrP8NsOi4vx48fnmXFLSkoiLCyMrl274uvra1iubJudpi0S+G7lBnp064LVajUsS2mSmZnJ8uXL6dJFY+4MGm/n05g7n8bc+TTmzqXxdj6NufPk3hV3LYYWX0FBQVgsFmJjY/Mcj42NJTQ0NN/nhIaGXvX83L9jY2MpV65cnnOaNGniOOfMmTN5rpGVlUV8fPwVX9fNzQ03t8vvO7VarYZ+mK1A/YoBHCtjNzxLaaQxdy6Nt/NpzJ1PY+58GnPn0ng7n8a88F3v+Bq6c5mrqyvNmzdnxYoVjmM2m43/b+/eY6qu/ziOvw7KgVQumcpFSdTwGpJZMuhiU+YlK1hN0TkVMy2DLVZOW6uwq9nFecnUNhUvpdlK3LTpEIXKvAVU3mZmeGkBpg4ByWCcz++P5vl1hHMQxS+352M7G+f7fX8/53Pevv189+Z7zpesrCzFxMTUekxMTIxLvPTvpdSr8T169FBwcLBLTGlpqfbv3++MiYmJUUlJiXJzc50xu3btksPhUHR0dIO9PwAAAAC4qtE/dvjiiy9qypQpuu+++zRkyBAtXLhQly9fdt79cPLkyeratavmzZsnSXrhhRc0dOhQffTRRxozZow2btyoH3/8UZ9++qmkf29nmZqaqrffflsRERHOW82HhoYqISFBktSvXz+NGjVK06dP1/Lly1VVVaWUlBSNHz++2d3pEAAAAEDz0OjNV2Jiov766y+9/vrrKioq0j333KPt27c7b5hx5swZeXn9/wJdbGysPv/8c7366qt65ZVXFBERoYyMDOff+JKk2bNn6/Lly5oxY4ZKSkr04IMPavv27c6/8SVJn332mVJSUjR8+HDnH1levHixdW8cAAAAQKvS6M2XJKWkpCglJaXWfdnZ2TW2jR07VmPHjnU7ns1m05tvvqk333zTbUzHjh2b5R9UBgAAANA8Nep3vgAAAACgtaD5AgAAAAAL0HwBAAAAgAVovgAAAADAAjRfAAAAAGABmi8AAAAAsADNFwAAAABYgOYLAAAAACxA8wUAAAAAFqD5AgAAAAALtG3sCTRXxhhJUmlpaSPPRKqqqlJFRYVKS0vl7e3d2NNpFci5tci39ci59ci59ci5tci39ci5da72BFd7BHdovm5QWVmZJCksLKyRZwIAAACgKSgrK1NAQIDb/TZTV3uGWjkcDv3555/y8/OTzWZr1LmUlpYqLCxMZ8+elb+/f6POpbUg59Yi39Yj59Yj59Yj59Yi39Yj59YxxqisrEyhoaHy8nL/zS6ufN0gLy8vdevWrbGn4cLf35//WBYj59Yi39Yj59Yj59Yj59Yi39Yj59bwdMXrKm64AQAAAAAWoPkCAAAAAAvQfLUAPj4+SktLk4+PT2NPpdUg59Yi39Yj59Yj59Yj59Yi39Yj500PN9wAAAAAAAtw5QsAAAAALEDzBQAAAAAWoPkCAAAAAAvQfAEAAACABWi+momlS5cqPDxcvr6+io6O1oEDBzzGf/nll+rbt698fX0VGRmpb775xqKZNn/z5s3T/fffLz8/P3Xp0kUJCQk6fvy4x2PS09Nls9lcHr6+vhbNuPmbO3dujfz17dvX4zHU+I0LDw+vkW+bzabk5ORa46nv+vv222/1+OOPKzQ0VDabTRkZGS77jTF6/fXXFRISottuu01xcXE6ceJEnePW91zQmnjKeVVVlebMmaPIyEi1b99eoaGhmjx5sv7880+PY97I2tRa1FXjSUlJNXI3atSoOselxt2rK+e1res2m00ffPCB2zGpcevRfDUDX3zxhV588UWlpaUpLy9PUVFRGjlypM6dO1dr/A8//KAJEyZo2rRpys/PV0JCghISEnT48GGLZ9485eTkKDk5Wfv27VNmZqaqqqo0YsQIXb582eNx/v7+KiwsdD5Onz5t0YxbhgEDBrjk7/vvv3cbS43fnIMHD7rkOjMzU5I0duxYt8dQ3/Vz+fJlRUVFaenSpbXuf//997V48WItX75c+/fvV/v27TVy5EhduXLF7Zj1PRe0Np5yXlFRoby8PL322mvKy8vT119/rePHj+uJJ56oc9z6rE2tSV01LkmjRo1yyd2GDRs8jkmNe1ZXzv+b68LCQq1atUo2m01PPfWUx3GpcYsZNHlDhgwxycnJzufV1dUmNDTUzJs3r9b4cePGmTFjxrhsi46ONs8+++wtnWdLde7cOSPJ5OTkuI1ZvXq1CQgIsG5SLUxaWpqJioq67nhqvGG98MILplevXsbhcNS6n/q+OZLM5s2bnc8dDocJDg42H3zwgXNbSUmJ8fHxMRs2bHA7Tn3PBa3ZtTmvzYEDB4wkc/r0abcx9V2bWqva8j1lyhQTHx9fr3Go8et3PTUeHx9vhg0b5jGGGrceV76auMrKSuXm5iouLs65zcvLS3Fxcdq7d2+tx+zdu9clXpJGjhzpNh6eXbp0SZLUsWNHj3Hl5eXq3r27wsLCFB8fryNHjlgxvRbjxIkTCg0NVc+ePTVx4kSdOXPGbSw13nAqKyu1fv16Pf3007LZbG7jqO+GU1BQoKKiIpcaDggIUHR0tNsavpFzATy7dOmSbDabAgMDPcbVZ22Cq+zsbHXp0kV9+vTRzJkzdeHCBbex1HjDKi4u1rZt2zRt2rQ6Y6lxa9F8NXHnz59XdXW1goKCXLYHBQWpqKio1mOKiorqFQ/3HA6HUlNT9cADD+juu+92G9enTx+tWrVKW7Zs0fr16+VwOBQbG6s//vjDwtk2X9HR0UpPT9f27du1bNkyFRQU6KGHHlJZWVmt8dR4w8nIyFBJSYmSkpLcxlDfDetqndanhm/kXAD3rly5ojlz5mjChAny9/d3G1fftQn/N2rUKK1du1ZZWVmaP3++cnJyNHr0aFVXV9caT403rDVr1sjPz09PPvmkxzhq3HptG3sCQFOWnJysw4cP1/n555iYGMXExDifx8bGql+/flqxYoXeeuutWz3NZm/06NHOnwcOHKjo6Gh1795dmzZtuq7f2uHGrVy5UqNHj1ZoaKjbGOobLUlVVZXGjRsnY4yWLVvmMZa16caNHz/e+XNkZKQGDhyoXr16KTs7W8OHD2/EmbUOq1at0sSJE+u8ORI1bj2ufDVxnTp1Ups2bVRcXOyyvbi4WMHBwbUeExwcXK941C4lJUVbt27V7t271a1bt3od6+3trUGDBum33367RbNr2QIDA9W7d2+3+aPGG8bp06e1c+dOPfPMM/U6jvq+OVfrtD41fCPnAtR0tfE6ffq0MjMzPV71qk1daxPc69mzpzp16uQ2d9R4w/nuu+90/Pjxeq/tEjVuBZqvJs5ut2vw4MHKyspybnM4HMrKynL5TfR/xcTEuMRLUmZmptt4uDLGKCUlRZs3b9auXbvUo0ePeo9RXV2tQ4cOKSQk5BbMsOUrLy/XyZMn3eaPGm8Yq1evVpcuXTRmzJh6HUd935wePXooODjYpYZLS0u1f/9+tzV8I+cCuLraeJ04cUI7d+7UHXfcUe8x6lqb4N4ff/yhCxcuuM0dNd5wVq5cqcGDBysqKqrex1LjFmjsO36gbhs3bjQ+Pj4mPT3dHD161MyYMcMEBgaaoqIiY4wxkyZNMi+//LIzfs+ePaZt27bmww8/NMeOHTNpaWnG29vbHDp0qLHeQrMyc+ZMExAQYLKzs01hYaHzUVFR4Yy5NudvvPGG2bFjhzl58qTJzc0148ePN76+vubIkSON8RaanZdeeslkZ2ebgoICs2fPHhMXF2c6depkzp07Z4yhxm+F6upqc+edd5o5c+bU2Ed937yysjKTn59v8vPzjSSzYMECk5+f77yz3nvvvWcCAwPNli1bzC+//GLi4+NNjx49zN9//+0cY9iwYWbJkiXO53WdC1o7TzmvrKw0TzzxhOnWrZv56aefXNb2f/75xznGtTmva21qzTzlu6yszMyaNcvs3bvXFBQUmJ07d5p7773XREREmCtXrjjHoMbrp651xRhjLl26ZNq1a2eWLVtW6xjUeOOj+WomlixZYu68805jt9vNkCFDzL59+5z7hg4daqZMmeISv2nTJtO7d29jt9vNgAEDzLZt2yyecfMlqdbH6tWrnTHX5jw1NdX57xMUFGQeffRRk5eXZ/3km6nExEQTEhJi7Ha76dq1q0lMTDS//fabcz813vB27NhhJJnjx4/X2Ed937zdu3fXuo5czavD4TCvvfaaCQoKMj4+Pmb48OE1/i26d+9u0tLSXLZ5Ohe0dp5yXlBQ4HZt3717t3OMa3Ne19rUmnnKd0VFhRkxYoTp3Lmz8fb2Nt27dzfTp0+v0URR4/VT17pijDErVqwwt912mykpKal1DGq88dmMMeaWXloDAAAAAPCdLwAAAACwAs0XAAAAAFiA5gsAAAAALEDzBQAAAAAWoPkCAAAAAAvQfAEAAACABWi+AAAAAMACNF8AAAAAYAGaLwAAbrHw8HAtXLiwsacBAGhkNF8AgBYlKSlJCQkJkqRHHnlEqamplr12enq6AgMDa2w/ePCgZsyYYdk8AABNU9vGngAAAE1dZWWl7Hb7DR/fuXPnBpwNAKC54soXAKBFSkpKUk5OjhYtWiSbzSabzaZTp05Jkg4fPqzRo0erQ4cOCgoK0qRJk3T+/HnnsY888ohSUlKUmpqqTp06aeTIkZKkBQsWKDIyUu3bt1dYWJief/55lZeXS5Kys7M1depUXbp0yfl6c+fOlVTzY4dnzpxRfHy8OnToIH9/f40bN07FxcXO/XPnztU999yjdevWKTw8XAEBARo/frzKyspubdIAALcUzRcAoEVatGiRYmJiNH36dBUWFqqwsFBhYWEqKSnRsGHDNGjQIP3444/avn27iouLNW7cOJfj16xZI7vdrj179mj58uWSJC8vLy1evFhHjhzRmjVrtGvXLs2ePVuSFBsbq4ULF8rf39/5erNmzaoxL4fDofj4eF28eFE5OTnKzMzU77//rsTERJe4kydPKiMjQ1u3btXWrVuVk5Oj99577xZlCwBgBT52CABokQICAmS329WuXTsFBwc7t3/88ccaNGiQ3n33Xee2VatWKSwsTL/++qt69+4tSYqIiND777/vMuZ/vz8WHh6ut99+W88995w++eQT2e12BQQEyGazubzetbKysnTo0CEVFBQoLCxMkrR27VoNGDBABw8e1P333y/p3yYtPT1dfn5+kqRJkyYpKytL77zzzs0lBgDQaLjyBQBoVX7++Wft3r1bHTp0cD769u0r6d+rTVcNHjy4xrE7d+7U8OHD1bVrV/n5+WnSpEm6cOGCKioqrvv1jx07prCwMGfjJUn9+/dXYGCgjh075twWHh7ubLwkKSQkROfOnavXewUANC1c+QIAtCrl5eV6/PHHNX/+/Br7QkJCnD+3b9/eZd+pU6f02GOPaebMmXrnnXfUsWNHff/995o2bZoqKyvVrl27Bp2nt7e3y3ObzSaHw9GgrwEAsBbNFwCgxbLb7aqurnbZdu+99+qrr75SeHi42ra9/tNgbm6uHA6HPvroI3l5/fvBkU2bNtX5etfq16+fzp49q7Nnzzqvfh09elQlJSXq37//dc8HAND88LFDAECLFR4erv379+vUqVM6f/68HA6HkpOTdfHiRU2YMEEHDx7UyZMntWPHDk2dOtVj43TXXXepqqpKS5Ys0e+//65169Y5b8Tx39crLy9XVlaWzp8/X+vHEePi4hQZGamJEycqLy9PBw4c0OTJkzV06FDdd999DZ4DAEDTQfMFAGixZs2apTZt2qh///7q3Lmzzpw5o9DQUO3Zs0fV1dUaMWKEIiMjlZqaqsDAQOcVrdpERUVpwYIFmj9/vu6++2599tlnmjdvnktMbGysnnvuOSUmJqpz5841btgh/fvxwS1btuj222/Xww8/rLi4OPXs2VNffPFFg79/AEDTYjPGmMaeBAAAAAC0dFz5AgAAAAAL0HwBAAAAgAVovgAAAADAAjRfAAAAAGABmi8AAAAAsADNFwAAAABYgOYLAAAAACxA8wUAAAAAFqD5AgAAAAAL0HwBAAAAgAVovgAAAADAAv8D7zGcG7AB75EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from train import scheduler_lambda\n",
    "from config import TrainConfig\n",
    "tcfg = TrainConfig()\n",
    "    \n",
    "# Generate learning rate values\n",
    "lrs = [scheduler_lambda(i) for i in range(tcfg.max_iters)]\n",
    "    \n",
    "# Plot the learning rates\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(lrs, label='Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b314d-4538-4192-b063-356bd3407fe5",
   "metadata": {},
   "source": [
    "### visualizing our tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d86faad0-346f-4ebb-927a-a093b217f5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once',\n",
       " ' upon',\n",
       " ' a',\n",
       " ' time',\n",
       " ',',\n",
       " ' there',\n",
       " ' was',\n",
       " ' a',\n",
       " ' boy',\n",
       " ' named',\n",
       " ' Tim',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools import import_from_nested_path\n",
    "imported_objects = import_from_nested_path(['tokenizers', cfg.tokenizer], 'tokenizer', ['get_tokenizer'])\n",
    "get_tokenizer = imported_objects.get('get_tokenizer')\n",
    "tokenizer = get_tokenizer(size = cfg.vocab_len)\n",
    "prompt = 'Once upon a time, there was a boy named Tim.'\n",
    "tokenizer.display(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04bc7f-a633-4bc6-8189-364a1a643844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
