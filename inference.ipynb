{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8178ba-2ea0-4f4f-b9ca-c3435a83bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you prolly won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918a651-5c6a-4a39-8b3e-a28259e4fd64",
   "metadata": {},
   "source": [
    "# Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c0ba50-83de-4ad7-b262-944e6d547ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4011.456K parameters\n",
      "ModelConfig(dim=192, device='cpu', tokenizer='bpe', vocab_len=8192, num_layers=6, second_resid_norm=False, mlp_hidden_mult=4, mlp_bias=False, mlp_nonlinearity='SiLU', mlp_gated=True, num_q_heads=2, num_kv_heads=1, head_dim=96, theta=10000, max_seq_len=512, scale_first_resid=True, norm_type='RMSNorm', norm_affine=True, norm_bias=True, eps=1e-06, max_batch_size=1)\n",
      "Model(\n",
      "  (token_embedder): Embedding(8195, 192)\n",
      "  (layers): ModuleList(\n",
      "    (0-5): 6 x Layer(\n",
      "      (pre_attn_norm): Norm()\n",
      "      (attn): MQA(\n",
      "        (Wq): Linear(in_features=192, out_features=192, bias=False)\n",
      "        (Wk): Linear(in_features=192, out_features=96, bias=False)\n",
      "        (Wv): Linear(in_features=192, out_features=96, bias=False)\n",
      "        (Wo): Linear(in_features=192, out_features=192, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=192, out_features=512, bias=False)\n",
      "        (Wgate): Linear(in_features=192, out_features=512, bias=False)\n",
      "        (Wdown): Linear(in_features=512, out_features=192, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_norm): Norm()\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## pretrained model options:\n",
    "# a 1m parameter model trained for 2000 iters with many layers, thin MLP hidden dimensions & few attention heads: 'templateGPT_1m_tall_and_skinny'\n",
    "# a 1m parameter model trained for 2000 iters with layers, MLP hidden dimensions, & attention heads bw the other two: 'templateGPT_1m_5ft11_and_skinnyfat'\n",
    "# a 1m parameter model trained for 2000 iters with few layers, thick MLP hidden dimensions & many attention heads: 'templateGPT_1m_short_and_thicc'\n",
    "# a 2m parameter model trained for 4000 iters with CosineNorm: 'templateGPT_2m_CosineNorm'\n",
    "# a 2m parameter model trained for 4000 iters with LayerNorm: 'templateGPT_2m_LayerNorm'\n",
    "# a 2m parameter model trained for 4000 iters with RMSNorm: 'templateGPT_2m_RMSNorm'\n",
    "# a 3m parameter model trained for 5000 iters with a gated MLP: 'templateGPT_3m_GatedMLP'\n",
    "# a 3m parameter model trained for 5000 iters with an old-fashioned MLP: 'templateGPT_3m_GatedMLP'\n",
    "# a 4m parameter model trained for 6000 iters with GeGLU activation: 'templateGPT_4m_GeGLU'\n",
    "# a 4m parameter model trained for 6000 iters with SwiGLU activation: 'templateGPT_4m_SwiGLU'\n",
    "name = 'templateGPT_4m_SwiGLU'\n",
    "\n",
    "from tools import load_model\n",
    "model, tokenizer, cfg = load_model(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971fce-8b3e-4732-bd66-d5d2028025d6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a366b1fc-b620-45a0-8b42-71bdca18906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c202ea0-e64d-4367-a4a6-102756fe63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once| |upon| |a| |ti|me|, |th|er|e| |was| |a| |boy| |na|me|d| |Tim|. \n"
     ]
    }
   ],
   "source": [
    "# take a look at the tokenizer\n",
    "prompt = \"Once upon a time, there was a boy named Tim. \"\n",
    "print(tokenizer.display(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b13a76-50f8-48b6-b7cf-9097d307c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum attention matrix size in memory will be 64x512 rather than 512x512\n",
      "\n",
      "Once upon a time, there was a boy named Tim. Tim was very enthusiastic when he went to the park. He loved to play with his friends in the park. Tim was very good at his birthday part.\n",
      "One day, Tim went to the park with his mom. He saw a big box with many colors. Tim wanted to play with the colors too. He ran to the box and opened it. Inside the box, there was a small box. Tim was very happy and excited.\n",
      "Tim saw his friend, Sam, playing with him at the park. They were all happy and had a great time. Tim was so happy that he could play with the colorful colors and happy. The sun was shining and the sky was not happy. Tim knew he had to share his new toys with his friends.\n"
     ]
    }
   ],
   "source": [
    "output = generate(\n",
    "    prompt, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #max_gen_len = 100,\n",
    "    temperature = 0.7,\n",
    "    memory_saver_div = 8,\n",
    "    top_p = 0.9,\n",
    "    top_k = 32,\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114de8bf-ab76-460d-8c37-ebe368b47e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
